[
    {
        "question": "What criteria does the driver use to update the pose when a bluetooth landmark message is received?",
        "database_value": "the question is asking about the driver, so the answer is `driver`.",
        "related_docs": "/**\n * @file PoseMessage.hpp\n * @author William Parker\n * @brief The representation of a byte message that has data on the current\n * pose of the user or the average pose sent after calibration.\n * The message contains three landmarks which each\n * contain dimensional location and perception data.\n * @date 2024-02-15\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include \"LandmarkMessage.hpp\"\n#include \"Fragments/PoseFragment.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief The representation of a byte message that has data on the current\n     * pose of the user or the calibration pose. The message contains three landmarks\n     * which each contain pose and perception data.\n     */\n    class PoseMessage : public LandmarkMessage\n    {\n    public:\n        /// @brief The flag in the header of the landmark message to\n        /// represent that the landmark message is an average\n        /// value to be used for calibrating the pose in the driver.\n        static constexpr uint_fast8_t averagePoseMessageFlag{0b00001000};\n\n        /**\n         * @brief Converts the message into landmarks to use in a pose.\n         *\n         * @param messageBytes A `std::vector` of `uint_fast8_t`s representing the binary message.\n         * @throws `std::invalid_argument` if `messageBytes`'s length is not 20.\n         */\n        PoseMessage(const std::vector<uint_fast8_t> &messageByt\n\n/**\n * @file LandmarkPose.hpp\n * @author William Parker\n * @brief Describes a single pose frame for all landmarks of the user.\n * Created from a PoseMessage to be sent to calculate the tracker pose.\n * The landmarks of this pose hold positional data for the\n * relevant dimensions of the device, and perception data.\n * @date 2024-02-21\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include <vector>\n#include <unordered_map>\n#include <format>\n#include <string>\n#include <stdexcept>\n\n#include \"../../PosePoint.hpp\"\n#include \"Landmark.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Describes a single pose frame for all landmarks of the user.\n     * Created from a PoseMessage to be sent to calculate the tracker pose.\n     * The landmarks of this pose hold positional data for the\n     * relevant dimensions of the device, and perception data.\n     */\n    class LandmarkPose\n    {\n    public:\n        /**\n         * @brief A default constructor used to populate the Circular buffer\n         * and averagePose before real values are sent by the connection.\n         */\n        LandmarkPose();\n\n        /**\n         * @brief Describes a single pose frame for all landmarks of the user.\n         * Created from a PoseMessage to be sent to calculate the tracker pose.\n         * The landmarks of this pose hold positional data for the\n         * relevant dimensions of the device, a\n\n/**\n * @file PoseFragment.hpp\n * @author William Parker\n * @brief Provides how a single landmark should be interpreted from a fragment of a pose message.\n * @date 2024-02-15\n *\n * @copyright Copyright (c) 2024\n *\n */\n#pragma once\n\n#include <span>\n\n#include \"LandmarkFragment.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Provides how a single landmark should be interpreted from a fragment of a pose message.\n     */\n    class PoseFragment : public LandmarkFragment\n    {\n    public:\n        /// @brief Creates a single landmark representation of a realtime pose.\n        /// Assigns dimension and perception data based off `fragmentBytes`.\n        /// @param fragmentBytes the byte representation of the\n        /// landmark fragment as a span of `uint_fast8_t`s. Must be of size `6`.\n        /// @throws `std::invalid_argument` Thrown if the length of\n        /// `fragmentBytes` is not of size `fragmentLength`.\n        PoseFragment(const std::span<const uint_fast8_t> &fragmentBytes);\n\n        /// @brief Gets the presence of the landmark. Float score of whether landmark\n        /// is present on the scene (located within scene bounds).\n        /// @return `float` the the presence of the landmark.\n        float getPresence() const noexcept;\n\n        /// @brief Gets the visibility of the landmark. Float score of whether landmark is\n        /// visible or occluded by other objects\n\nKNEE, false},\n            {TrackerRole::LEFT_FOOT, false},\n            {TrackerRole::RIGHT_FOOT, false},\n        };\n\n        /// @brief The updated value for if the controllers should be used to check if a landmark pose is accurate.\n        bool controllerCheck{true};\n\n        /// @brief The binary message to send to other connected devices to update their settings.\n        std::vector<uint_fast8_t> outgoingSettingsMessageBytes{};\n\n        /// @brief The time that the message was received.\n        std::chrono::high_resolution_clock::time_point timestamp{std::chrono::high_resolution_clock::now()};\n    };\n}\n\n\n the first in a series.\n        static constexpr uint_fast8_t firstLandmarkMessageNumberValue{0};\n\n        /// @brief The message number representing that this landmark message\n        /// is the last in a series.\n        static constexpr uint_fast8_t lastLandmarkMessageNumberValue{5};\n\n        /// @brief The amount of time that a connection can go without sending a\n        /// recurring message before the connection should be disconnected.\n        static constexpr std::chrono::seconds timeoutDuration{std::chrono::seconds(5)};\n\n        /// @brief A partial Pose. If a PoseMessage is received,\n        /// place it into this map. Once the last message has been sent, the pose should\n        /// be complete so a new LandmarkPose can be made for LandmarkPoseData.\n        std::unordered_map<PoseLandmarkType, Landmark> workingLandmarkPose;\n\n        std::unordered_map<PoseLandmarkType, Landmark> workingAverageLandmarkPose;\n\n        /// @brief The ratio of the device camera's width in pixels over the camera's hight in pixels.\n        float aspectRatio;\n\n        /// @brief The position of the camera around the edge of the\n        /// playspace so that it's rotation is facing the center of the playspace.\n        CameraRotation cameraRotation;\n\n        /**\n         * @brief Sets the timestamp and battery state of the recurring message to the connection.\n         *\n         * @param recurrin",
        "output": "The driver updates the pose when a Bluetooth landmark message is received by placing the partial Pose into the `workingLandmarkPose` map. Once the last message has been sent, the pose should be complete, and a new `LandmarkPose` can be made for `LandmarkPoseData`. The specific criteria for determining when the pose is complete are not provided in the given code snippets."
    },
    {
        "question": "How should the mobile camera be positioned in the play space according to the user instructions?",
        "database_value": "mobile",
        "related_docs": " PageViewModel(\n          title: \"Basic Usage\",\n          body: \"Your computer camera should be aligned with how your headset \"\n              \"is rotated on startup. Place your phone upright so that both \"\n              \"the desktop and mobile camera can see your full body in your \"\n              \"play-space. Your phone should be 90 degrees apart from your \"\n              \"computer camera from the center of your play-space.\",\n          image: Transform.scale(\n            scaleX: -1,\n            child: Transform.translate(\n              offset: const Offset(0, 40),\n              child: Transform.rotate(\n                angle: 225 * math.pi / 180,\n                child: const IconButton(\n                  icon: Icon(\n                    Icons.auto_mode,\n                    color: Colors.black,\n                    size: 175,\n                  ),\n                  onPressed: null,\n                ),\n              ),\n            ),\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Pose Calibration\",\n          body:\n              \"Before entering VR, calibrate both this app and the desktop app \"\n              \"individually by standing still for 10 seconds so the program \"\n              \"can predict where your body is while using VR. I\n\n        subtitle: \"Sets where the phone is relative to the play space.\",\n                settingKey: Global.devicePositionSave,\n                values: const <int, String>{\n                  0: 'Front',\n                  1: 'Right (90\u00b0 Clockwise)',\n                  2: 'Back',\n                  3: 'Left (90\u00b0 Counter Clockwise)',\n                },\n                selected: 0,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Enabled Trackers',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Shoulder\",\n                settingKey: Global.shoulderTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Elbow\",\n                settingKey: Global.elbowTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Hip\",\n                settingKey: Global.hipTrackerEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Knees\",\n                settingKey: Global.kneeTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Feet\",\n                settingKey: Global.footTrackersEnabledSave,\n                defaultValue: true,\n\n),\n                    child: const Text(\n                      'Request Permissions',\n                      style: TextStyle(color: Colors.white),\n                    ),\n                  ),\n                )\n              : null,\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"All Set!\",\n          body: \"Make sure to calibrate your device once it is set up and \"\n              \"review the options menu before starting VR. The app may need \"\n              \"to be re-opened to enable Bluetooth for the first time. \"\n              \"You can view this walkthrough again in the options menu.\",\n          image: const Icon(\n            Icons.thumb_up,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n      ],\n      onDone: () => _onIntroEnd(context),\n      onSkip: () => _onIntroEnd(context),\n      showSkipButton: true,\n      skipOrBackFlex: 0,\n      nextFlex: 0,\n      //rtl: true, // Display as right-to-left\n      back: const Icon(Icons.arrow_back),\n      skip: const Text('Skip', style: TextStyle(fontWeight: FontWeight.w600)),\n      next: const Icon(Icons.arrow_forward),\n      done: con\n\nf the camera \"\n              \"needs to be rotated or moved from the place calibration was \"\n              \"done, calibration should be done again. Make sure to also set \"\n              \"your height in centimeters in the options menu.\",\n          image: const Icon(\n            Icons.settings_accessibility,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Permissions\",\n          bodyWidget: Align(\n            alignment: Alignment.centerLeft,\n            child: displayPermissions(),\n          ),\n          image: const Icon(\n            Icons.https,\n            color: Colors.black,\n            size: 175,\n          ),\n          footer: Platform.isAndroid\n              ? Padding(\n                  padding: const EdgeInsets.symmetric(horizontal: 100.0),\n                  child: ElevatedButton(\n                    onPressed: () {\n                      Future(() => Global.perms.request());\n                    },\n                    style: ElevatedButton.styleFrom(\n                      backgroundColor: Colors.lightBlue,\n                      shape: RoundedRectangleBorder(\n                        borderRadius: BorderRadius.circular(8.0),\n                      ),\n                    \n\nthe camera vertically\n  late int verticalPixelCount;\n\n  SettingsMessage(Size cameraResolution) {\n    // Height\n    height = Settings.getValue(Global.userHeightSave, defaultValue: 69)!;\n\n    height = height.clamp(\n      Global.heightMinimumFeet * 12,\n      Global.heightLimitFeet * 12 - 1,\n    );\n\n    // Trackers\n    shoulderTrackersEnabled = Settings.getValue(\n      Global.shoulderTrackersEnabledSave,\n      defaultValue: true,\n    )!;\n\n    elbowTrackersEnabled = Settings.getValue(\n      Global.elbowTrackersEnabledSave,\n      defaultValue: true,\n    )!;\n\n    hipTrackerEnabled = Settings.getValue(\n      Global.hipTrackerEnabledSave,\n      defaultValue: true,\n    )!;\n\n    kneeTrackersEnabled = Settings.getValue(\n      Global.kneeTrackersEnabledSave,\n      defaultValue: true,\n    )!;\n\n    footTrackersEnabled = Settings.getValue(\n      Global.footTrackersEnabledSave,\n      defaultValue: true,\n    )!;\n\n    controllerCheckEnabled = Settings.getValue(\n      Global.controllerCheckEnabledSave,\n      defaultValue: true,\n    )!;\n\n    // Rotation\n    playspaceRotationCode =\n        Settings.getValue(Global.devicePositionSave, defaultValue: 0)!;\n\n    // Resolution\n    horizontalPixelCount = cameraResolution.width.toInt();\n\n    verticalPixelCount = cameraResolution.height.toInt();\n  }\n\n  /// Outputs the settings data as a [List] of [int]s\n  /// to be sent to the driver in a Bluetooth message\n ",
        "output": "The mobile camera should be positioned upright so that both the desktop and mobile camera can see your full body in your play-space. Your phone should be 90 degrees apart from your computer camera from the center of your play-space. This is indicated by the following code snippet:\n\n```\nPageViewModel(\n          title: \"Basic Usage\",\n          body: \"Your computer camera should be aligned with how your headset \"\n              \"is rotated on startup. Place your phone upright so that both \"\n              \"the desktop and mobile camera can see your full body in your \"\n              \"play-space. Your phone should be 90 degrees apart from your \"\n              \"computer camera from the center of your play-space.\",\n          image: Transform.scale(\n            scaleX: -1,\n            child: Transform.translate(\n              offset: const Offset(0, 40),\n              child: Transform.rotate(\n                angle: 225 * math.pi / 180,\n                child: const IconButton(\n                  icon: Icon(\n                    Icons.auto_mode,\n                    color: Colors.black,\n                    size: 175,\n                  ),\n                  onPressed: null,\n                ),\n              ),\n            ),\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n```"
    },
    {
        "question": "When does the success sound play on desktop?",
        "database_value": "desktop",
        "related_docs": " used for the next time you start VR.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n        self.calibration_poses = []\n        self._notify_calibration_success_observer()\n        audio_manager.play_sound(audio_manager.SUCCESS_SOUND)\n\n    def add_pose(self, pose: List[NormalizedLandmark]) -> None:\n        \"\"\"\n        Adds a pose to the calibration poses list if the pose is complete.\n\n        :param pose: The pose to add.\n        \"\"\"\n        if self.calibrating:\n            for pose_landmark in pose:\n                if pose_landmark.visibility < 0.5:\n                    return\n            self.calibration_poses.append(pose)\n\n    def register_calibration_success_callback(self, callback: Callable) -> None:\n        \"\"\"\n        Registers a callback to be called when the calibration is successful\n\n        :param callback: function to be called when the camera changes\n        \"\"\"\n        self._callback.append(callback)\n\n    def _notify_calibration_success_observer(self) -> None:\n        \"\"\"\n        Notifies the calibration success observer that calibration was successful\n        \"\"\"\n        for callback in self._callback:\n            callback()\n\n\nagebox_helper.OK_OPTION, **messagebox_helper.common_args)\n        if result.get() == messagebox_helper.OK_OPTION:\n            root.after(_CALIBRATION_PREPARATION_DURATION, self.start_calibration)\n            root.after(_CALIBRATION_PREPARATION_DURATION + _CALIBRATION_DURATION, lambda: self.end_calibration(root, interface))\n        else:\n            self.running = False\n\n    def start_calibration(self) -> None:\n        \"\"\"\n        Sets the calibration flag to True and plays a sound to indicate calibration has started.\n        \"\"\"\n        self.calibrating = True\n        audio_manager.play_sound(audio_manager.ACTIVATE_SOUND)\n\n    def end_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n        \"\"\"\n        Calculates the average pose from the calibration poses and sends it to the VR interface.\n\n        :param root: The root Tk instance.\n        :param interface: The BaseInterface instance.\n        \"\"\"\n        self.running = False\n        self.calibrating = False\n        if len(self.calibration_poses) < _MINIMUM_CALIBRATION_POSE_COUNT:\n            audio_manager.play_sound(audio_manager.FAILURE_SOUND)\n            result = CTkMessagebox(title='Calibration Failed', message='Calibration failed. No complete poses were able to be found. Please try again with \"Points\" enabled to find optimal conditions for FreeMove VR with your setup. \\n\\n Common issues in\n\n## Class Main ##\n\nDocstring:\nThe main class of the program.\n\nCode:\nclass Main:\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the main window and starts the main loop\n        \"\"\"\n        if sys.platform != 'darwin':\n            if 'pyi_splash' in sys.modules:\n                pyi_splash.update_text('Almost Done...')\n        self.camera_manager = CameraManager()\n        self.calibration = Calibration(camera_manager=self.camera_manager)\n        self.tracker_manager = TrackerManager()\n        self.interface_manager = InterfaceManager(tracker_manager=self.tracker_manager, camera_manager=self.camera_manager)\n        self.pose_detection = PoseDetection(calibration=self.calibration, interface_manager=self.interface_manager)\n        self.feed_updater = FeedUpdater(camera_manager=self.camera_manager, pose_detection=self.pose_detection)\n        self.main_window = MainWindow(interface_manager=self.interface_manager, calibration=self.calibration, tracker_manager=self.tracker_manager, camera_manager=self.camera_manager, pose_detection=self.pose_detection, feed_updater=self.feed_updater)\n        if sys.platform != 'darwin':\n            if 'pyi_splash' in sys.modules:\n                pyi_splash.close()\n        atexit.register(self.on_close)\n        self.main_window.mainloop()\n\n    def on_close(self) -> None:\n        \"\"\"\n        Preforms cleanup across the application.\n       \n\nmpy_view()\n        self.timestamp_ms = timestamp_ms\n        self.new_image = True\n        self.current_frame_buffer_size -= 1\n\n    def process_detection_result(self) -> Optional[ndarray]:\n        \"\"\"\n        Returns the output image from the pose detection process\n\n        :return: The output image from the pose detection process or None if no new image is available\n        \"\"\"\n        if self.new_image is True and self.output_image is not None:\n            self.new_image = False\n            if self.pose_result is not None:\n                if len(self.pose_result.pose_landmarks) > 0:\n                    landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                    if self.calibration.calibrating:\n                        self.calibration.add_pose(landmarks)\n                    if self.timestamp_ms is not None:\n                        landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                        self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                    if self.display_points:\n                        image = np.copy(self.output_image)\n                        image.setflags(write=True)\n                        self.output_image = pose_drawer.draw_landmarks_on_image(image, land\n\nnd_settings()\n        landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=calibrated_pose_result, timestamp=0, calibration_pose=True)\n        self.write_landmarks(landmark_messages)\n        statistical_messages = message_factory.generate_messages(message_constructor=StatisticalMessage, landmarks=standard_deviation_pose_result)\n        self.write_landmarks(statistical_messages)\n\n    def write_landmarks(self, landmark_messages: List[LandmarkMessageBase]) -> None:\n        \"\"\"\n        Writes the landmarks to the driver interface\n\n        :param landmark_messages: The list of landmark messages to write\n        \"\"\"\n        for message in landmark_messages:\n            byte_array = message.to_byte_array()\n            self.write_data(byte_array)\n\n    def setup(self) -> None:\n        \"\"\"\n        Preforms necessary setup for the interface. Should be called at when the interface is to be used.\n        \"\"\"\n        self.shutdown_requested.clear()\n\n    @abstractmethod\n    def disconnect_request(self) -> None:\n        \"\"\"\n        Sends a request to the interface to disconnect. The interface may close the connection.\n        \"\"\"\n\n    @abstractmethod\n    def write_data(self, byte_sequence: bytes) -> None:\n        \"\"\"\n        Writes data to the interface in the form of a byte array.\n\n        :param byte_sequence: The byte array to write\n        \"\"\"\n",
        "output": "The success sound plays on desktop when the calibration is successful and the user confirms it by clicking the \"OK\" button in the message box. This is indicated by the following lines of code:\n\n```python\nif result.get() == messagebox_helper.OK_OPTION:\n    root.after(_CALIBRATION_PREPARATION_DURATION, self.start_calibration)\n    root.after(_CALIBRATION_PREPARATION_DURATION + _CALIBRATION_DURATION, lambda: self.end_calibration(root, interface))\n```\n\nHere, `result.get()` checks if the user clicked \"OK\" in the message box. If it returns `messagebox_helper.OK_OPTION`, the success sound is played and the calibration process continues."
    },
    {
        "question": "When does the failure sound play on mobile?",
        "database_value": "mobile",
        "related_docs": "  Future(() => _player.play(AssetSource(Global.failureSoundFile)));\n  }\n}\n\n\nestNotification() {\n    NotificationUI.displayNotification(\n      content: 'Disconnection request sent.',\n      backgroundColor: Colors.amber,\n    );\n  }\n\n  /// User side popup notification when there was an unexpected disconnection\n  static void displayBluetoothReconnectingNotification() {\n    NotificationUI.displayNotification(\n      content: 'Connection Lost! Reconnecting...',\n    );\n  }\n\n  /// User side popup notification when Bluetooth could not be enabled\n  static void displayBluetoothErrorNotification() {\n    NotificationUI.displayNotification(\n      content: 'Bluetooth could not be enabled, please give permissions and '\n          'restart the application.',\n    );\n  }\n}\n\n\n// Flutter imports:\nimport 'package:flutter/material.dart';\n\n// Package imports:\nimport 'package:audioplayers/audioplayers.dart';\n\n// Project imports:\nimport 'package:free_move_vr/global.dart';\n\n/// Created for methods to use displayNotification\n/// with a sound to show a result to the user.\nclass NotificationUI {\n  /// Used to play audio\n  static final AudioPlayer _player = AudioPlayer();\n\n  /// Basic structure of a notification to the user.\n  static void displayNotification({\n    required String content,\n    Color backgroundColor = Colors.red,\n  }) {\n    Global.messengerKey.currentState!.clearSnackBars();\n\n    Global.messengerKey.currentState!.showSnackBar(\n      SnackBar(\n        content: Text(content),\n        backgroundColor: backgroundColor,\n        duration: const Duration(seconds: 5),\n      ),\n    );\n  }\n\n  /// Plays a short sound that notifies when the device has\n  /// started recording poses for calibration\n  static void playActivationSound() {\n    Future(() => _player.play(AssetSource(Global.activateSoundFile)));\n  }\n\n  /// Plays a short sound that notifies when the device has\n  /// successfully calibrated the user's pose\n  static void playSuccessSound() {\n    Future(() => _player.play(AssetSource(Global.successSoundFile)));\n  }\n\n  /// Plays a short sound that notifies when the device has\n  /// failed to calibrate the user's pose\n  static void playFailureSound() {\n  \n\n      BluetoothNotificationHandler.sendNotification(\n          landmarkMessage.toByteArray(),\n        );\n      }\n      for (final StatisticalMessage statisticalMessage in statisticalMessages) {\n        BluetoothNotificationHandler.sendNotification(\n          statisticalMessage.toByteArray(),\n        );\n      }\n\n      // Calculations have been completed, saved, and sent to the driver,\n      // so notify that everything was successful.\n      NotificationUI.playSuccessSound();\n      CalibrationUI.displayCalibrationSuccessNotification();\n    } catch (_) {\n      // Something went wrong with the calibration\n      NotificationUI.playFailureSound();\n      CalibrationUI.displayCalibrationFailNotification();\n    }\n  }\n\n  /// Adds the [pose] to the [calibrationPoses] [List] if it is valid\n  static void storeCalibrationData(Pose pose) {\n    if (_posePointAccuracyCheck(pose)) {\n      calibrationPoses.add(pose);\n    }\n  }\n\n  /// Returns true if every landmark in the [pose]\n  /// is accurate enough to be used for calibration\n  static bool _posePointAccuracyCheck(Pose pose) {\n    for (final value in pose.landmarks.values) {\n      if (value.presence < 0.7) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  /// Saves the [message]s as a single string to SharedPreferences at [saveFile]\n  static Future<void> _saveLandmarkPose(\n    List<LandmarkMessageBase> messages,\n    String saveFile,\n\n BluetoothHelper.centralDevice = device;\n        AdvertisingHandler.stop(AdvertisingHandler.advertisings.first);\n\n        BluetoothSettingsUpdateHandler.notifySettings();\n\n        // If calibration data exists, send it to the driver\n        if (prefs.containsKey(Global.averageLandmarkMessageSave) &&\n            prefs.containsKey(Global.statisticalMessageSave)) {\n          BluetoothNotificationHandler.sendCalibrationData(\n            prefs.getStringList(Global.averageLandmarkMessageSave)!,\n          );\n\n          BluetoothNotificationHandler.sendCalibrationData(\n            prefs.getStringList(Global.statisticalMessageSave)!,\n          );\n        }\n\n        bluetoothButtonProvider.bluetoothState = BluetoothState.connected;\n        BluetoothUI.displayDeviceConnectedNotification();\n        NotificationUI.playSuccessSound();\n      } else {\n        BluetoothHelper.centralDevice = null;\n        if (BluetoothHelper.disconnectingRequestSent) {\n          BluetoothHelper.disconnectingRequestSent = false;\n          BluetoothHelper.gattService?.inactivate();\n\n          BluetoothUI.displayBluetoothDisabledWhileConnectedNotification();\n\n          bluetoothButtonProvider.bluetoothState = BluetoothState.disabled;\n        } else {\n          BluetoothUI.displayBluetoothReconnectingNotification();\n          NotificationUI.playFailureSound();\n          BluetoothAdvertisingSetupHandler.createAdvert",
        "output": "The failure sound plays on mobile when there is an unexpected disconnection or Bluetooth could not be enabled. This is indicated by the following methods in the code:\n\n- `displayBluetoothReconnectingNotification()`: This method is called when there was an unexpected disconnection, and it plays the failure sound using `NotificationUI.playFailureSound()`.\n- `displayBluetoothErrorNotification()`: This method is called when Bluetooth could not be enabled, and it also plays the failure sound using `NotificationUI.playFailureSound()`.\n\nSo, in summary, the failure sound plays on mobile when there is a disconnection or an error with Bluetooth."
    },
    {
        "question": "What does the failure sound imply on desktop?",
        "database_value": "desktop",
        "related_docs": "agebox_helper.OK_OPTION, **messagebox_helper.common_args)\n        if result.get() == messagebox_helper.OK_OPTION:\n            root.after(_CALIBRATION_PREPARATION_DURATION, self.start_calibration)\n            root.after(_CALIBRATION_PREPARATION_DURATION + _CALIBRATION_DURATION, lambda: self.end_calibration(root, interface))\n        else:\n            self.running = False\n\n    def start_calibration(self) -> None:\n        \"\"\"\n        Sets the calibration flag to True and plays a sound to indicate calibration has started.\n        \"\"\"\n        self.calibrating = True\n        audio_manager.play_sound(audio_manager.ACTIVATE_SOUND)\n\n    def end_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n        \"\"\"\n        Calculates the average pose from the calibration poses and sends it to the VR interface.\n\n        :param root: The root Tk instance.\n        :param interface: The BaseInterface instance.\n        \"\"\"\n        self.running = False\n        self.calibrating = False\n        if len(self.calibration_poses) < _MINIMUM_CALIBRATION_POSE_COUNT:\n            audio_manager.play_sound(audio_manager.FAILURE_SOUND)\n            result = CTkMessagebox(title='Calibration Failed', message='Calibration failed. No complete poses were able to be found. Please try again with \"Points\" enabled to find optimal conditions for FreeMove VR with your setup. \\n\\n Common issues in\n\n   except ValueError:\n                pass\n            return True\n        except pywintypes.error as error:\n            self.py_handle = None\n            if error.args[0] == ERROR_FILE_NOT_FOUND:\n                self._notify_message_observer('Cannot find a running instance of SteamVR + FreeMoveVR to connect to.')\n            elif error.args[0] == ERROR_BROKEN_PIPE:\n                self._notify_message_observer('Connection to SteamVR + FreeMoveVR has been broken, attempting to reconnect...')\n            elif error.args[0] == ERROR_PIPE_BUSY:\n                self._notify_message_observer('Max number of connections to SteamVR + FreeMoveVR has been reached.')\n            else:\n                self._notify_message_observer(f'Uncaught Error: {error.args[0]}')\n            return False\n\n    def disconnect_request(self) -> None:\n        \"\"\"\n        Sends a disconnect request to the driver\n        \"\"\"\n        disconnect_message: DisconnectMessage = DisconnectMessage()\n        self.write_data(disconnect_message.to_byte_array())\n        try:\n            win32file.CloseHandle(self.py_handle.handle)\n        except AttributeError:\n            pass\n        self.py_handle = None\n\n    def write_data(self, byte_sequence: bytes) -> None:\n        \"\"\"\n        Writes the byte array to the connected pipe\n\n        :param byte_sequence: the array to send to the pipe\n        \"\"\"\n        if self.py_handl\n\nre_index)\n            self.frame_rate = self.image_capture.get(cv2.CAP_PROP_FPS)\n            self.frame_height = self.image_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n            self.frame_width = self.image_capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n            if not self.image_capture.isOpened():\n                self.camera_failsafe += 1\n            else:\n                if self.camera_failsafe > 0 and (not init):\n                    CTkMessagebox(title='Camera Changed', message=f'The camera specified could not be connected to. Automatically switching to the next available camera: {self.camera_enum.get_cameras()[self.active_camera_index]}', **messagebox_helper.common_args)\n                self.camera_failsafe = 0\n                self._notify_camera_change_observer(self.active_camera_index)\n                break\n        self.swapping_source = False\n        save_manager.save_variable(self.active_camera_index, ACTIVE_CAMERA_SAVEFILE)\n\n    def _check_failsafe(self) -> None:\n        if self.camera_failsafe >= len(self.camera_enum.get_cameras()):\n            message = 'FreeMoveVR was unable connect to any cameras.'\n            if sys.platform == 'darwin':\n                message += ' Please enable the application to access cameras and relaunch.'\n            result = CTkMessagebox(title='No Cameras Available', message=message, icon=messagebox_helper.CANCEL_ICON, option_1=messagebox_helper.\n\n used for the next time you start VR.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n        self.calibration_poses = []\n        self._notify_calibration_success_observer()\n        audio_manager.play_sound(audio_manager.SUCCESS_SOUND)\n\n    def add_pose(self, pose: List[NormalizedLandmark]) -> None:\n        \"\"\"\n        Adds a pose to the calibration poses list if the pose is complete.\n\n        :param pose: The pose to add.\n        \"\"\"\n        if self.calibrating:\n            for pose_landmark in pose:\n                if pose_landmark.visibility < 0.5:\n                    return\n            self.calibration_poses.append(pose)\n\n    def register_calibration_success_callback(self, callback: Callable) -> None:\n        \"\"\"\n        Registers a callback to be called when the calibration is successful\n\n        :param callback: function to be called when the camera changes\n        \"\"\"\n        self._callback.append(callback)\n\n    def _notify_calibration_success_observer(self) -> None:\n        \"\"\"\n        Notifies the calibration success observer that calibration was successful\n        \"\"\"\n        for callback in self._callback:\n            callback()\n\n\ncurring_message.to_byte_array())\n\n    def send_settings(self) -> None:\n        \"\"\"\n        Sends the settings to the driver. If the driver is not connected, it will not send the settings\n        \"\"\"\n        settings_message: SettingsMessage = SettingsMessage(list(self.tracker_manager), self.camera_manager.image_capture)\n        self.write_data(settings_message.to_byte_array())\n\n    def send_calibration_data(self) -> None:\n        \"\"\"\n        Sends the calibration data of the pose and settings data to the driver\n\n        :raise ValueError: if there is no calibration data saved\n        \"\"\"\n        camera_name: str = self.camera_manager.camera_enum.get_cameras()[self.camera_manager.active_camera_index]\n        calibration_file: str = camera_name + save_manager.CALIBRATED_POSE_SAVEFILE_SUFFIX\n        calibrated_pose_result: Optional[list[NormalizedLandmark]] = save_manager.load_variable(calibration_file)\n        if calibrated_pose_result is None:\n            raise ValueError('calibration data not found')\n        standard_deviation_pose_file: str = camera_name + save_manager.STANDARD_DEVIATION_SAVEFILE_SUFFIX\n        standard_deviation_pose_result: Optional[list[NormalizedLandmark]] = save_manager.load_variable(standard_deviation_pose_file)\n        if standard_deviation_pose_result is None:\n            raise ValueError('standard deviation calibration data not found')\n        self.se",
        "output": "The failure sound on desktop implies that the calibration failed because no complete poses were able to be found. This could be due to common issues such as points not being enabled or suboptimal conditions for FreeMove VR with the user's setup. The system will play the failure sound and provide a message box with this information."
    },
    {
        "question": "Can I swap the camera between front and back on mobile?",
        "database_value": "mobile",
        "related_docs": " _customPaint = null;\n    }\n  }\n\n  /// Fixes incorrect results from the front camera which will\n  /// mirror the pose in different ways between iOS and Android.\n  Pose _frontCameraCorrection(Pose pose) {\n    if (Platform.isIOS) {\n      final List<MapEntry<PoseLandmarkType, PoseLandmark>> landmarks =\n          pose.landmarks.entries.toList();\n\n      for (int landmarkIndex = 0;\n          landmarkIndex < landmarks.length;\n          landmarkIndex += 2) {\n        final PoseLandmark temp = landmarks[landmarkIndex].value;\n        landmarks[landmarkIndex] = MapEntry(\n          landmarks[landmarkIndex].key,\n          landmarks[landmarkIndex + 1].value,\n        );\n        landmarks[landmarkIndex + 1] =\n            MapEntry(landmarks[landmarkIndex + 1].key, temp);\n      }\n\n      return Pose(\n        landmarks: Map.fromEntries(landmarks),\n      );\n    }\n    // Assume Android if it's not iOS\n    return _mirrorPoseInFrame(pose);\n  }\n\n  /// Mirrors the pose relative to the frame.\n  Pose _mirrorPoseInFrame(Pose pose) {\n    final List<MapEntry<PoseLandmarkType, PoseLandmark>> landmarks =\n        pose.landmarks.entries.toList();\n\n    for (int landmarkIndex = 0;\n        landmarkIndex < landmarks.length;\n        landmarkIndex++) {\n      final PoseLandmark flippedLandmark = PoseLandmark(\n        type: landmarks[landmarkIndex].key,\n        x: 1 - landmarks[landmarkIndex].value.x,\n        y: landmark\n\n// Flutter imports:\nimport 'package:flutter/material.dart';\n\n// Package imports:\nimport 'package:spannable_grid/spannable_grid.dart';\n\n// Project imports:\nimport 'package:free_move_vr/camera_core.dart';\nimport 'package:free_move_vr/camera_helper.dart';\nimport 'package:free_move_vr/home_menu/cell_helper.dart';\n\n/// Builds the button to swap the active camera\n/// with the correct positioning for Home Menu.\nSpannableGridCellData cameraSwitchCellBuilder(bool isPortrait) {\n  final changeCameraButton = Padding(\n    padding: CellHelper.edgePadding,\n    child: ElevatedButton(\n      onPressed: () async {\n        CameraCore.camera = await CameraHelper.nextCamera(\n          CameraCore.cameras,\n          CameraCore.camera,\n        );\n        cameraKey.currentState?.updateCamera();\n      },\n      style: CellHelper.buttonStyle,\n      child: CellHelper.buttonVisual(\n        icon: Icons.cameraswitch,\n        text: \"Camera\",\n      ),\n    ),\n  );\n\n  final changeCameraCell = SpannableGridCellData(\n    column: isPortrait ? 3 : 1,\n    row: isPortrait ? 1 : 2,\n    id: \"changeCameraButton\",\n    child: changeCameraButton,\n  );\n\n  return changeCameraCell;\n}\n\n\n PageViewModel(\n          title: \"Basic Usage\",\n          body: \"Your computer camera should be aligned with how your headset \"\n              \"is rotated on startup. Place your phone upright so that both \"\n              \"the desktop and mobile camera can see your full body in your \"\n              \"play-space. Your phone should be 90 degrees apart from your \"\n              \"computer camera from the center of your play-space.\",\n          image: Transform.scale(\n            scaleX: -1,\n            child: Transform.translate(\n              offset: const Offset(0, 40),\n              child: Transform.rotate(\n                angle: 225 * math.pi / 180,\n                child: const IconButton(\n                  icon: Icon(\n                    Icons.auto_mode,\n                    color: Colors.black,\n                    size: 175,\n                  ),\n                  onPressed: null,\n                ),\n              ),\n            ),\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Pose Calibration\",\n          body:\n              \"Before entering VR, calibrate both this app and the desktop app \"\n              \"individually by standing still for 10 seconds so the program \"\n              \"can predict where your body is while using VR. I\n\n        subtitle: \"Sets where the phone is relative to the play space.\",\n                settingKey: Global.devicePositionSave,\n                values: const <int, String>{\n                  0: 'Front',\n                  1: 'Right (90\u00b0 Clockwise)',\n                  2: 'Back',\n                  3: 'Left (90\u00b0 Counter Clockwise)',\n                },\n                selected: 0,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Enabled Trackers',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Shoulder\",\n                settingKey: Global.shoulderTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Elbow\",\n                settingKey: Global.elbowTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Hip\",\n                settingKey: Global.hipTrackerEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Knees\",\n                settingKey: Global.kneeTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Feet\",\n                settingKey: Global.footTrackersEnabledSave,\n                defaultValue: true,\n\n// Package imports:\nimport 'package:camera/camera.dart';\nimport 'package:flutter_settings_screens/flutter_settings_screens.dart';\nimport 'package:shared_preferences/shared_preferences.dart';\n\n// Project imports:\nimport 'package:free_move_vr/global.dart';\n\n/// A helper class for basic functionally of using the camera with\n/// methods that do not require much use of CameraCore's variables.\nclass CameraHelper {\n  /// Returns the optimal camera for the user to use.\n  static Future<CameraDescription> bestCamera(\n    List<CameraDescription> cameras,\n  ) async {\n    // Use the saved camera by default\n    final SharedPreferences prefs = await SharedPreferences.getInstance();\n    final int? counter = prefs.getInt(Global.cameraIndexSave);\n\n    if (counter != null) {\n      return cameras[counter];\n    }\n\n    // Rank front facing cameras highest as users can see\n    // the detection of themselves real time on first startup.\n    for (final element in cameras) {\n      if (element.lensDirection == CameraLensDirection.front) {\n        return element;\n      }\n    }\n    // If there is no front facing camera, just chose the first camera.\n    return cameras[0];\n  }\n\n  /// Switches to the next camera in the list of cameras on the device.\n  static Future<CameraDescription> nextCamera(\n    List<CameraDescription> cameras,\n    CameraDescription camera,\n  ) async {\n    // In the list of cameras, grab t",
        "output": "Based on the provided code snippets, it appears that the application is designed to handle camera switching between front and back cameras on a mobile device. However, the specific implementation details for swapping the camera are not directly visible in the provided code.\n\nThe `CameraHelper` class has a method called `nextCamera` which takes a list of cameras and the current camera as parameters. This method is designed to switch to the next camera in the list, but the exact implementation of this switching process is not shown in the provided code.\n\nTherefore, while it seems that the application is capable of swapping between front and back cameras, the specific code for this functionality is not visible in the provided snippets."
    },
    {
        "question": "Can I swap cameras on desktop?",
        "database_value": "desktop",
        "related_docs": "re_index)\n            self.frame_rate = self.image_capture.get(cv2.CAP_PROP_FPS)\n            self.frame_height = self.image_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n            self.frame_width = self.image_capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n            if not self.image_capture.isOpened():\n                self.camera_failsafe += 1\n            else:\n                if self.camera_failsafe > 0 and (not init):\n                    CTkMessagebox(title='Camera Changed', message=f'The camera specified could not be connected to. Automatically switching to the next available camera: {self.camera_enum.get_cameras()[self.active_camera_index]}', **messagebox_helper.common_args)\n                self.camera_failsafe = 0\n                self._notify_camera_change_observer(self.active_camera_index)\n                break\n        self.swapping_source = False\n        save_manager.save_variable(self.active_camera_index, ACTIVE_CAMERA_SAVEFILE)\n\n    def _check_failsafe(self) -> None:\n        if self.camera_failsafe >= len(self.camera_enum.get_cameras()):\n            message = 'FreeMoveVR was unable connect to any cameras.'\n            if sys.platform == 'darwin':\n                message += ' Please enable the application to access cameras and relaunch.'\n            result = CTkMessagebox(title='No Cameras Available', message=message, icon=messagebox_helper.CANCEL_ICON, option_1=messagebox_helper.\n\n\"\"\"\n        Starts the process of changing the camera source.\n        First, it sets the camera_manager's swapping_source flag to True,\n        so the camera preview UI will stop updating and instead display a message.\n        Then, we wait 50ms for the camera preview UI to update,\n        and then we call camera_manager.change_camera() to change the camera source.\n        This guarantees that the camera preview UI will display the message before the camera source is changed,\n        and provide a better user experience.\n\n        :param index: The index of the camera to change to.\n        \"\"\"\n        self.camera_manager.swapping_source = True\n        self.after(50, lambda: self.camera_manager.change_camera(index=index))\n\n    def _update_camera_select(self, index: int) -> None:\n        \"\"\"\n        The camera that the user selects may not be the camera that is actually used\n        due to a fallback in camera_manager that will skip any camera that fails to initialize properly.\n        Due to this, we need a callback once camera_manager has finished to select the camera that is actually in use.\n\n        :param index: The index of the camera that is in use.\n        \"\"\"\n        self.camera_select.set(index)\n        self.interface_manager.active_interface.send_settings()\n\n    def destroy(self):\n        self.tooltip_title.destroy()\n        super().destroy()\n\n\n## Class CameraEnumerator ##\n\nDocstring:\nProvides a list of available cameras.\n\nCode:\nclass CameraEnumerator:\n\n    def __init__(self) -> None:\n        \"\"\"\n        Sets up camera enumerator.\n        \"\"\"\n        self._cameras: List[str] = []\n        if sys.platform == 'win32':\n            self.filter_graph = FilterGraph()\n        elif sys.platform == 'linux':\n            pass\n        elif sys.platform == 'darwin':\n            for i in range(10):\n                cap = cv2.VideoCapture(i)\n                if cap.isOpened():\n                    self._cameras.append(f'Camera {i + 1}')\n                    cap.release()\n                else:\n                    break\n\n    def get_cameras(self) -> List[str]:\n        \"\"\"\n        Returns a list of available cameras.\n        \"\"\"\n        if sys.platform == 'win32':\n            return self.filter_graph.get_input_devices()\n        if sys.platform == 'linux':\n            cameras = []\n            for path in glob.glob('/dev/video*'):\n                base_name = os.path.basename(path)\n                device_path = os.path.join('/sys', 'class', 'video4linux', base_name)\n                if os.path.exists(os.path.join(device_path, 'device')):\n                    device_path = os.path.join(device_path, 'device')\n                    device_path = os.path.realpath(device_path)\n                    if ':' in os.path.basename(device_path):\n               \n\n## Class CameraManager ##\n\nDocstring:\nManages the camera and the camera display.\n\nCode:\nclass CameraManager:\n\n    def __init__(self) -> None:\n        self.active_camera_index = _startup_camera()\n        self.camera_enum = CameraEnumerator()\n        self.camera_failsafe: int = 0\n        self.image_capture: Optional[VideoCapture] = None\n        self.frame_rate: Optional[float] = None\n        self.frame_height: Optional[float] = None\n        self.frame_width: Optional[float] = None\n        self.swapping_source: bool = False\n        self._callback: List[Callable[[int], None]] = []\n        self.change_camera(index=self.active_camera_index, init=True)\n\n    def change_camera(self, index: int=0, init: bool=False) -> None:\n        \"\"\"\n        Sets the active camera to camera at the specified index.\n        If the camera fails to open, it will try the next camera.\n        Saves the camera index to the save file.\n\n        :param index: The index of the camera to change to\n        :param init: If this is in the initialization phase\n        \"\"\"\n        while True:\n            self._check_failsafe()\n            capture_index = (index + self.camera_failsafe) % len(self.camera_enum.get_cameras())\n            self.active_camera_index = capture_index\n            if self.image_capture is not None:\n                self.image_capture.release()\n            self.image_capture = cv2.VideoCapture(captu\n\nequest()\n        except ValueError:\n            pass\n        self.active_interface.shutdown_requested.set()\n        self.active_interface = self.interfaces[key]\n        self.active_interface.setup()\n        self._notify_interface_change_observer(key)\n        save_manager.save_variable(key, ACTIVE_INTERFACE_SAVEFILE)\n\n    def register_interface_change_callback(self, callback: Callable[[str], None]) -> None:\n        \"\"\"\n        Registers a callback to be called when a new camera is in use\n\n        :param callback: function to be called when the camera changes\n        \"\"\"\n        self._callback.append(callback)\n\n    def _notify_interface_change_observer(self, key: str) -> None:\n        \"\"\"\n        Notifies the camera change observer that a different camera is in use\n        \"\"\"\n        for callback in self._callback:\n            callback(key)\n",
        "output": "Yes, you can swap cameras on desktop using the `CameraManager` class. The `change_camera` method in this class allows you to set the active camera to a specific index. If the camera fails to open, it will try the next camera. The method also saves the camera index to the save file.\n\nHere is the relevant code snippet:\n```python\nclass CameraManager:\n    def change_camera(self, index: int=0, init: bool=False) -> None:\n        \"\"\"\n        Sets the active camera to camera at the specified index.\n        If the camera fails to open, it will try the next camera.\n        Saves the camera index to the save file.\n\n        :param index: The index of the camera to change to\n        :param init: If this is in the initialization phase\n        \"\"\"\n        while True:\n            self._check_failsafe()\n            capture_index = (index + self.camera_failsafe) % len(self.camera_enum.get_cameras())\n            self.active_camera_index = capture_index\n            if self.image_capture is not None:\n                self.image_capture.release()\n            self.image_capture = cv2.VideoCapture(capture_index)\n```"
    },
    {
        "question": "What is the disconnect message flag in a Bluetooth Message?",
        "database_value": "any",
        "related_docs": "ould be shut down.\n         */\n        virtual void mainLoop() = 0;\n\n        // TODO: Implement in children\n        // /**\n        //  * @brief Sends a binary message represented as a `std::vector` of integers to the connected device.\n        //  *\n        //  * @param outgoingMessage The binary message as a `std::vector` of integers.\n        //  */\n        // virtual void sendMessage(const std::vector<uint_fast8_t> &outgoingMessage) = 0;\n\n        /**\n         * @brief Whenever a message is initially received it is in binary, represented as a `std::vector` of\n         * integers. Every message should be sent to this method to be interpreted. This method will find\n         * which type of message was received, and process that message accordingly.\n         *\n         * @param byteMessage The message as a `std::vector` of integers.\n         */\n        virtual void onMessageReceived(const std::vector<uint_fast8_t> &byteMessage);\n\n    private:\n        /// @brief The flag in the header of the message to represent\n        /// that the device wishes to disconnect from the driver.\n        static constexpr uint_fast8_t disconnectMessageFlag{0b10000000};\n\n        /// @brief The number of fragments in a single landmark message.\n        static constexpr uint_fast8_t fragmentsPerLandmarkMessage{3};\n\n        /// @brief The message number representing that this landmark message\n        /// is\n\nsize_t optionsLength{1};\n\n        /// @brief The maximum length allowed for a message.\n        /// The maximum length is defined by Bluetooth LE, of byte size 20.\n        /// Due to this constraint on mobile, this is the length used for all messages.\n        static constexpr size_t messageByteCount{20};\n    };\n}\n\n\n the first in a series.\n        static constexpr uint_fast8_t firstLandmarkMessageNumberValue{0};\n\n        /// @brief The message number representing that this landmark message\n        /// is the last in a series.\n        static constexpr uint_fast8_t lastLandmarkMessageNumberValue{5};\n\n        /// @brief The amount of time that a connection can go without sending a\n        /// recurring message before the connection should be disconnected.\n        static constexpr std::chrono::seconds timeoutDuration{std::chrono::seconds(5)};\n\n        /// @brief A partial Pose. If a PoseMessage is received,\n        /// place it into this map. Once the last message has been sent, the pose should\n        /// be complete so a new LandmarkPose can be made for LandmarkPoseData.\n        std::unordered_map<PoseLandmarkType, Landmark> workingLandmarkPose;\n\n        std::unordered_map<PoseLandmarkType, Landmark> workingAverageLandmarkPose;\n\n        /// @brief The ratio of the device camera's width in pixels over the camera's hight in pixels.\n        float aspectRatio;\n\n        /// @brief The position of the camera around the edge of the\n        /// playspace so that it's rotation is facing the center of the playspace.\n        CameraRotation cameraRotation;\n\n        /**\n         * @brief Sets the timestamp and battery state of the recurring message to the connection.\n         *\n         * @param recurrin\n\nt recent settings message was received so the\n        /// manager knows when a new settings message arrives and the driver should be updated.\n        std::chrono::high_resolution_clock::time_point lastSettingsMessageTimestamp{};\n\n        /**\n         * @brief Creates a new connection manager, by first opening a new connection of each type.\n         */\n        ConnectionManager();\n\n        /**\n         * @brief Destroy the Connection Manager object. Shuts down all connection threads.\n         */\n        ~ConnectionManager();\n\n        void initialize();\n\n        /**\n         * @brief Shuts down all connection threads.\n         */\n        void shutdown();\n\n        /**\n         * @brief Checks active and listening connections to see if any should be shut down. If so, attempts to open a new connection.\n         */\n        void checkShutdownRequests();\n\n        /**\n         * @brief Checks all listening connections to find if any have connected to a device and\n         * should be moved to the active vector. If so, a new connection is also made.\n         */\n        void checkNewActiveConnections();\n\n        /**\n         * @brief For every connection, orders the status of the connected device's battery in order of which devices\n         * are plugged in and then by percent.\n         *\n         * @return std::vector<BatteryState> The ordered vector of the connected device's battery sta\n\n        * @brief Returns if the internal checks show that the connection is in a state for\n         * it to be shut down. This can be because `shutdownFlag` is `true`, or it has been\n         * more then `5` seconds since the last recurring message.\n         *\n         * @return `bool` If the connection in is a state to be shut down.\n         */\n        bool shouldShutdown() const noexcept;\n\n        /**\n         * @brief Sends an updated common settings message to the connection. Whenever a settings message is received,\n         * the driver will update the height and which trackers are currently active to every tracker\n         * so that the settings are the same across all connected devices.\n         *\n         * @param updatedCommonSettings The settings to update connections with.\n         */\n        void sendSettingsUpdate(const CommonSettings &updatedCommonSettings);\n\n    protected:\n        /// @brief A mask to get remove the message number from the\n        /// header and only keep the options flags.\n        static constexpr uint_fast8_t optionsFlagMask{0b11111000};\n\n        /// @brief Is `true` when the thread should shut down and the connection should be killed.\n        bool shutdownFlag;\n\n        /**\n         * @brief The method that does the work of the connection. The implementation should be a\n         * loop that attempts to read a connection until the connection sh",
        "output": "The disconnect message flag in a Bluetooth Message is represented by the constant `disconnectMessageFlag` which is defined as `0b10000000` (or 64 in decimal). This flag is used to indicate that the device wishes to disconnect from the driver."
    },
    {
        "question": "How long does calibration take on mobile?",
        "database_value": "mobile",
        "related_docs": "f the camera \"\n              \"needs to be rotated or moved from the place calibration was \"\n              \"done, calibration should be done again. Make sure to also set \"\n              \"your height in centimeters in the options menu.\",\n          image: const Icon(\n            Icons.settings_accessibility,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Permissions\",\n          bodyWidget: Align(\n            alignment: Alignment.centerLeft,\n            child: displayPermissions(),\n          ),\n          image: const Icon(\n            Icons.https,\n            color: Colors.black,\n            size: 175,\n          ),\n          footer: Platform.isAndroid\n              ? Padding(\n                  padding: const EdgeInsets.symmetric(horizontal: 100.0),\n                  child: ElevatedButton(\n                    onPressed: () {\n                      Future(() => Global.perms.request());\n                    },\n                    style: ElevatedButton.styleFrom(\n                      backgroundColor: Colors.lightBlue,\n                      shape: RoundedRectangleBorder(\n                        borderRadius: BorderRadius.circular(8.0),\n                      ),\n                    \n\n// Package imports:\nimport 'package:google_mediapipe_pose_detection/pose_detector.dart';\n\n// Project imports:\nimport 'package:free_move_vr/global.dart';\n\n/// Small helper class for functions used in both average_pose_generator.dart\n/// and statistical_pose_generator.dart\nclass CalibrationHelper {\n  /// The time the application should wait\n  /// before the user expects for calibration to start.\n  static const Duration calibrationPreparationDuration = Duration(seconds: 5);\n\n  /// The time that the app takes to calibrate the user's pose.\n  static const Duration calibrationDuration = Duration(seconds: 5);\n\n  /// To calculate standard deviation of a sample, we should take a\n  /// minimum of 30 poses, as that is a statistically significant\n  /// population size and there should in reality be many more poses\n  /// taken within the time frame. With a low fps, 20fps * 5s = 100 poses.\n  static const int minimumPoses = 30;\n\n  /// Given a [List] of [Pose]s, sums up each dimension of\n  /// each landmark and return the sum as a new [Pose]\n  static Pose calculateSumOfPoses(List<Pose> poses) {\n    final Map<PoseLandmarkType, PoseLandmark> poseLandmarks = {};\n\n    for (final point in Global.freeMovePosePoints) {\n      double xCoordinateSum = 0;\n      double yCoordinateSum = 0;\n\n      for (final pose in poses) {\n        final landmark = pose.landmarks[point]!;\n\n        xCoordinateSum += landmark\n\n PageViewModel(\n          title: \"Basic Usage\",\n          body: \"Your computer camera should be aligned with how your headset \"\n              \"is rotated on startup. Place your phone upright so that both \"\n              \"the desktop and mobile camera can see your full body in your \"\n              \"play-space. Your phone should be 90 degrees apart from your \"\n              \"computer camera from the center of your play-space.\",\n          image: Transform.scale(\n            scaleX: -1,\n            child: Transform.translate(\n              offset: const Offset(0, 40),\n              child: Transform.rotate(\n                angle: 225 * math.pi / 180,\n                child: const IconButton(\n                  icon: Icon(\n                    Icons.auto_mode,\n                    color: Colors.black,\n                    size: 175,\n                  ),\n                  onPressed: null,\n                ),\n              ),\n            ),\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Pose Calibration\",\n          body:\n              \"Before entering VR, calibrate both this app and the desktop app \"\n              \"individually by standing still for 10 seconds so the program \"\n              \"can predict where your body is while using VR. I\n\n// Dart imports:\nimport 'dart:async';\n\n// Package imports:\nimport 'package:google_mediapipe_pose_detection/google_mediapipe_pose_detection.dart';\nimport 'package:shared_preferences/shared_preferences.dart';\n\n// Project imports:\nimport 'package:free_move_vr/bluetooth/bluetooth_notification_handler.dart';\nimport 'package:free_move_vr/calibration/average_pose_generator.dart';\nimport 'package:free_move_vr/calibration/calibration_helper.dart';\nimport 'package:free_move_vr/calibration/calibration_ui.dart';\nimport 'package:free_move_vr/calibration/statistical_pose_generator.dart';\nimport 'package:free_move_vr/global.dart';\nimport 'package:free_move_vr/messages/landmark_message_base.dart';\nimport 'package:free_move_vr/messages/pose_message.dart';\nimport 'package:free_move_vr/messages/statistical_message.dart';\nimport 'package:free_move_vr/notification_ui.dart';\n\n/// Calibration is done by having the user stand still for five seconds.\n/// Once complete, we will calculate the average location and\n/// standard deviation of each landmark. If calibration is successful,\n/// send the data to the driver over Bluetooth.\nclass Calibration {\n  /// True if the user is currently calibrating\n  static bool calibrationActive = false;\n\n  /// List of poses recorded during calibration\n  static List<Pose> calibrationPoses = [];\n\n  /// Starts the calibration process\n  static Future<void> runCalibration() a\n\nsync {\n    calibrationPoses = [];\n\n    CalibrationUI.displayCalibrationStartedNotification();\n\n    await Future.delayed(CalibrationHelper.calibrationPreparationDuration);\n\n    NotificationUI.playActivationSound();\n\n    calibrationActive = true;\n\n    await Future.delayed(CalibrationHelper.calibrationDuration);\n\n    calibrationActive = false;\n\n    try {\n      if (calibrationPoses.length < CalibrationHelper.minimumPoses) {\n        throw RangeError(\n          \"At least ${CalibrationHelper.minimumPoses} pose snapshots are needed.\",\n        );\n      }\n\n      final Pose averagePose = AveragePoseGenerator(calibrationPoses).toPose();\n      final Pose statisticalPose =\n          StatisticalPoseGenerator(calibrationPoses, averagePose).toPose();\n\n      final List<PoseMessage> averageLandmarkMessages =\n          PoseMessage.generateMessages(\n        landmarks: averagePose.landmarks.values.toList(),\n        timestamp: 0,\n        averagePose: true,\n      );\n      final List<StatisticalMessage> statisticalMessages =\n          StatisticalMessage.generateMessages(\n        landmarks: statisticalPose.landmarks.values.toList(),\n      );\n\n      _saveLandmarkPose(\n        averageLandmarkMessages,\n        Global.averageLandmarkMessageSave,\n      );\n      _saveLandmarkPose(statisticalMessages, Global.statisticalMessageSave);\n\n      for (final PoseMessage landmarkMessage in averageLandmarkMessages) {\n  ",
        "output": "The calibration process on mobile takes 5 seconds, as indicated by the `CalibrationHelper.calibrationDuration` constant in the code snippet. This duration is used in the `runCalibration()` function to wait for the specified amount of time before ending the calibration process."
    },
    {
        "question": "How many landmarks are in a pose on desktop?",
        "database_value": "desktop",
        "related_docs": "## Class Landmark ##\n\nDocstring:\nThe pose landmarks used in FreeMoveVR.\n\nCode:\nclass Landmark(enum.IntEnum):\n    LEFT_EAR = 0\n    RIGHT_EAR = 1\n    LEFT_SHOULDER = 2\n    RIGHT_SHOULDER = 3\n    LEFT_ELBOW = 4\n    RIGHT_ELBOW = 5\n    LEFT_WRIST = 6\n    RIGHT_WRIST = 7\n    LEFT_HIP = 8\n    RIGHT_HIP = 9\n    LEFT_KNEE = 10\n    RIGHT_KNEE = 11\n    LEFT_ANKLE = 12\n    RIGHT_ANKLE = 13\n    LEFT_HEEL = 14\n    RIGHT_HEEL = 15\n    LEFT_FOOT_INDEX = 16\n    RIGHT_FOOT_INDEX = 17\n\n\n## Class LandmarkMessageBase ##\n\nDocstring:\nAn abstract superclass for messages that have landmark data.\nAs of branch feature/verbose-notification-map, it is used by pose_message.py and statistical_message.py.\nCreated so that the messages dealing with landmark data can be used in a standard way.\n\n:param message_number: Signifies which landmarks are in the message according to the notification map specification.\n:param landmarks: The list of Mediapipe normalized landmarks for the message number.\n:param flags: The list of options flags for the message.\n:param timestamp: The length of time since the image was captured.\n:keyword **_: Used for abstraction purposes.\n\nCode:\nclass LandmarkMessageBase(ABC):\n\n    def __init__(self, message_number: int, landmarks: List[NormalizedLandmark], flags: Optional[List[int]]=None, timestamp: int=0, **_: Any):\n        self.message_number: int = message_number\n        self.landmarks: List[NormalizedLandmark] = landmarks\n        self.flags = flags\n        timestamp = max(min(timestamp, OPENVR_MAX_DELAY), OPENVR_MIN_DELAY)\n        self.timestamp: int = timestamp\n\n    @abstractmethod\n    def to_byte_array(self) -> bytes:\n        \"\"\"\n        Abstract method of child's method to convert the message to a byte array.\n        Overridden by children of MessageBase, existing to provide a standard interface.\n        :return: The byte array representation of th\n\nmpy_view()\n        self.timestamp_ms = timestamp_ms\n        self.new_image = True\n        self.current_frame_buffer_size -= 1\n\n    def process_detection_result(self) -> Optional[ndarray]:\n        \"\"\"\n        Returns the output image from the pose detection process\n\n        :return: The output image from the pose detection process or None if no new image is available\n        \"\"\"\n        if self.new_image is True and self.output_image is not None:\n            self.new_image = False\n            if self.pose_result is not None:\n                if len(self.pose_result.pose_landmarks) > 0:\n                    landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                    if self.calibration.calibrating:\n                        self.calibration.add_pose(landmarks)\n                    if self.timestamp_ms is not None:\n                        landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                        self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                    if self.display_points:\n                        image = np.copy(self.output_image)\n                        image.setflags(write=True)\n                        self.output_image = pose_drawer.draw_landmarks_on_image(image, land\n\n## Class PoseMessageFragment ##\n\nDocstring:\nThe representation of a single landmark in a pose message.\nEach dimensional value is represented by two bytes,\nwhile the presence and visibility are represented by one byte each.\nEach value is ment to be red as a fraction out of the max possible value of the allocated bytes.\nThe variables in the message are ints between 0 and 255 so that they can be represented as bytes.\nThe variables are named and listed in the same order as the protocol.\nIt is listed in that order so list_variables can be used to get the variables in the order they should be sent.\n\n:param pose_landmark: The Mediapipe normalized landmark to represent as a list of six bytes in the message.\n\nCode:\nclass PoseMessageFragment(FragmentBase):\n\n    def __init__(self, pose_landmark: NormalizedLandmark):\n        super().__init__(pose_landmark)\n        x_values = two_byte_representation(pose_landmark.x)\n        y_values = two_byte_representation(pose_landmark.y)\n        self.x_large: int = x_values[0]\n        self.x_small: int = x_values[1]\n        self.y_large: int = y_values[0]\n        self.y_small: int = y_values[1]\n        self.presence: int = one_byte_representation(pose_landmark.presence)\n        self.visibility: int = one_byte_representation(pose_landmark.visibility)\n\n\ndmark_level_save\n        self.change_landmarker(self.landmark_level)\n        self.display_points = save_manager.load_variable(DISPLAY_POINTS_SAVEFILE)\n        if self.display_points is None:\n            self.display_points = True\n        self.calibration = calibration\n        self.interface_manager = interface_manager\n        self.frame_rate_tracker = FrameRateTracker()\n        self.pose_result: PoseLandmarkerResult\n        self.output_image: Optional[ndarray] = None\n        self.timestamp_ms: int\n        self.new_image = False\n        self.current_frame_buffer_size = 0\n        self.max_frame_buffer_size = save_manager.load_variable(MAX_FRAME_BUFFER_SIZE_SAVEFILE) or 2\n\n    def toggle_points(self) -> None:\n        \"\"\"\n        Toggles the display of the pose points\n        \"\"\"\n        self.display_points = not self.display_points\n        save_manager.save_variable(self.display_points, DISPLAY_POINTS_SAVEFILE)\n\n    def change_landmarker(self, level: LandmarkerLevel) -> None:\n        \"\"\"\n        Sets the current landmarker to the specified level, initializing it if necessary\n\n        :param level: The level of the landmarker to use\n        \"\"\"\n        if level == LandmarkerLevel.FULL:\n            self.landmarker = self.full_landmarker\n        else:\n            self.landmarker = self.heavy_landmarker\n        save_manager.save_variable(level, LANDMARKER_LEVEL_SAVEFILE)\n        self.",
        "output": "The number of landmarks in a pose on desktop is determined by the `message_number` parameter in the `LandmarkMessageBase` class. This parameter signifies which landmarks are in the message according to the notification map specification. The available landmarks are defined in the `Landmark` enum class, which has 17 members (LEFT\\_EAR to RIGHT\\_ANKLE). However, the specific number of landmarks used in a pose on desktop would depend on the implementation and the `message_number` value set for that use case."
    },
    {
        "question": "What is the max number of people that can be tracked using the pose detector on desktop?",
        "database_value": "desktop",
        "related_docs": "## Class DelegateMenu ##\n\nDocstring:\nThe menu to change the pose detection to use the CPU or GPU.\n\nCode:\nclass DelegateMenu(CTkFrame):\n\n    def __init__(self, parent: CTkToplevel) -> None:\n        super().__init__(parent)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Set Delegate'\n        self.title = CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set where the pose detection model should be run.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.variable = IntVar(value=save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or Delegate.CPU)\n        radiobutton = CTkRadioButton(self, text='CPU', value=Delegate.CPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.CPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        radiobutton.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        radiobutton = CTkRadioButton(self, text='GPU', value=Delegate.GPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.GPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        if sys.platform == 'win32':\n            radiobutton.configure(state='disabled')\n        radiobutton.grid(row=2, column=0, padx=10, pady=(10, 0), sticky='w')\n        if sys.platform == 'win32':\n            self.windows\n\nmpy_view()\n        self.timestamp_ms = timestamp_ms\n        self.new_image = True\n        self.current_frame_buffer_size -= 1\n\n    def process_detection_result(self) -> Optional[ndarray]:\n        \"\"\"\n        Returns the output image from the pose detection process\n\n        :return: The output image from the pose detection process or None if no new image is available\n        \"\"\"\n        if self.new_image is True and self.output_image is not None:\n            self.new_image = False\n            if self.pose_result is not None:\n                if len(self.pose_result.pose_landmarks) > 0:\n                    landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                    if self.calibration.calibrating:\n                        self.calibration.add_pose(landmarks)\n                    if self.timestamp_ms is not None:\n                        landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                        self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                    if self.display_points:\n                        image = np.copy(self.output_image)\n                        image.setflags(write=True)\n                        self.output_image = pose_drawer.draw_landmarks_on_image(image, land\n\n## Class PoseDetection ##\n\nDocstring:\nOrchestrates the Mediapipe pose detection process\n\nCode:\nclass PoseDetection:\n\n    def __init__(self, calibration: Calibration, interface_manager: InterfaceManager) -> None:\n        \"\"\"\n        Initializes an instance of the pose detector to read poses from input frames\n        \"\"\"\n        self.landmarker: Optional[PoseLandmarker] = None\n        delegate = save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or BaseOptions.Delegate.CPU\n        options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=FULL_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n        self.full_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n        options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=HEAVY_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n        self.heavy_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n        self.landmark_level: LandmarkerLevel\n        landmark_level_save: Optional[LandmarkerLevel] = save_manager.load_variable(LANDMARKER_LEVEL_SAVEFILE)\n        if landmark_level_save is None:\n            self.landmark_level = LandmarkerLevel.FULL\n        else:\n            self.landmark_level = lan\n\n## Class FrameBufferSizeMenu ##\n\nDocstring:\nChanges how many frames can be computed at one time..\n\nCode:\nclass FrameBufferSizeMenu(CTkFrame):\n\n    def __init__(self, master: CTkToplevel, pose_detection: PoseDetection):\n        super().__init__(master)\n        self.pose_detection = pose_detection\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = f'Frame Buffer Size: {int(self.pose_detection.max_frame_buffer_size)}'\n        self.title = CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set how many frames are computed at once. See \"Help\" for more info.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.max_frame_buffer_size = tk.IntVar(value=self.pose_detection.max_frame_buffer_size)\n        self.slider = CTkSlider(self, from_=1, to=10, number_of_steps=9, variable=self.max_frame_buffer_size, command=self._set_frame_buffer_size)\n        self.slider.grid(row=1, column=0, padx=10, pady=10, sticky='ew')\n\n    def _set_frame_buffer_size(self, frame_buffer_size: float) -> None:\n        save_manager.save_variable(frame_buffer_size, MAX_FRAME_BUFFER_SIZE_SAVEFILE)\n        self.pose_detection.max_frame_buffer_size = frame_buffer_size\n        self.title.configure(text=f'Frame Buffer Size: {int(self.pose_detection.max_frame_buffer_size)}')\n\n    def de\n\nlandmark_level = level\n\n    def detect_pose(self, frame: ndarray) -> None:\n        \"\"\"\n        Detects the pose in the frame using appropriate Mediapipe model\n        if we are not currently processing an image\n\n        Uses _on_landmark_callback() to return data on callback\n\n        :param frame: the input frame to process\n        \"\"\"\n        if self.landmarker is None:\n            return\n        if self.current_frame_buffer_size >= self.max_frame_buffer_size:\n            return\n        self.current_frame_buffer_size += 1\n        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n        self.landmarker.detect_async(mp_image, int(time.time() * 1000))\n\n    def _on_landmark_callback(self, pose_result: PoseLandmarkerResult, output_image: mp.Image, timestamp_ms: int) -> None:\n        \"\"\"\n        Called after an image has been processed by Mediapipe.\n        Sets processing_image to false so another frame can be processed.\n        Should not be called directly.\n\n        Warning: Debugging does not work on this method or callbacks it notifies.\n\n        :param pose_result: The pose landmark list\n        :param output_image: The image used to generate the pose landmarks\n        :param timestamp_ms: The initial time the detection started\n        \"\"\"\n        self.frame_rate_tracker.update()\n        self.pose_result = pose_result\n        self.output_image = output_image.nu",
        "output": "Based on the provided code, the maximum number of people that can be tracked using the pose detector on desktop is not explicitly defined. However, the `max_frame_buffer_size` variable in the `FrameBufferSizeMenu` class seems to control how many frames are computed at once. This might indirectly influence the number of people that can be tracked simultaneously, but it's not a direct measure of the tracking capacity.\n\nTo determine the exact maximum number of people that can be tracked, you would need to look for relevant variables or methods in the `PoseDetection` class or other related classes, as they might contain this information. As of now, based on the provided code snippets, I cannot provide a definitive answer to your question."
    },
    {
        "question": "Does the desktop app support Mac?",
        "database_value": "desktop",
        "related_docs": "## Class MainWindow ##\n\nDocstring:\nThe main window of the application.\n\nCode:\nclass MainWindow(customtkinter.CTk):\n\n    def __init__(self, pose_detection: PoseDetection, tracker_manager: TrackerManager, camera_manager: CameraManager, calibration: Calibration, interface_manager: InterfaceManager, feed_updater: FeedUpdater):\n        super().__init__(className='Free Move VR Desktop')\n        self.title('FreeMoveVR Desktop')\n        customtkinter.set_appearance_mode(save_manager.load_variable(save_manager.APPEARANCE_MODE_SAVEFILE) or 'Dark')\n        customtkinter.set_default_color_theme(get_static_data_path(os.path.join('themes', f\"{save_manager.load_variable(save_manager.COLOR_THEME_SAVEFILE) or 'Blue'}.json\")))\n        self.grid_columnconfigure(0, weight=1)\n        self.grid_rowconfigure(0, weight=1)\n        self.grid_columnconfigure(2, weight=4)\n        self.pose_detection: PoseDetection = pose_detection\n        self.tracker_manager: TrackerManager = tracker_manager\n        self.camera_manager: CameraManager = camera_manager\n        self.calibration: Calibration = calibration\n        self.interface_manager: InterfaceManager = interface_manager\n        self.feed_updater: FeedUpdater = feed_updater\n        self.settings_bar = SettingsBar(master=self, tracker_manager=self.tracker_manager, pose_detection=self.pose_detection, camera_manager=self.camera_manager, calibration=self.calib\n\n## Class DelegateMenu ##\n\nDocstring:\nThe menu to change the pose detection to use the CPU or GPU.\n\nCode:\nclass DelegateMenu(CTkFrame):\n\n    def __init__(self, parent: CTkToplevel) -> None:\n        super().__init__(parent)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Set Delegate'\n        self.title = CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set where the pose detection model should be run.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.variable = IntVar(value=save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or Delegate.CPU)\n        radiobutton = CTkRadioButton(self, text='CPU', value=Delegate.CPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.CPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        radiobutton.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        radiobutton = CTkRadioButton(self, text='GPU', value=Delegate.GPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.GPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        if sys.platform == 'win32':\n            radiobutton.configure(state='disabled')\n        radiobutton.grid(row=2, column=0, padx=10, pady=(10, 0), sticky='w')\n        if sys.platform == 'win32':\n            self.windows\n\n## Class AboutPopup ##\n\nDocstring:\nPopup window that displays information about the application and the libraries used.\n\nCode:\nclass AboutPopup(customtkinter.CTkToplevel):\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.title('About FreeMoveVR Desktop')\n        headline = '\\nCopyright 2024 - William Parker - FreeMove VR  \\n\\nLibraries Used:'\n        self.headline = customtkinter.CTkLabel(self, text=headline)\n        self.headline.grid(row=0, column=0, padx=20, pady=10, sticky='ew', columnspan=3)\n        packages_path = get_static_data_path('packages.json')\n        with open(packages_path, 'r', encoding='utf-8') as file:\n            packages: List[Dict[str, str]] = json.load(file)\n        for package in packages:\n            if package['platform'] != '' and package['platform'] != sys.platform:\n                packages.remove(package)\n        for index, package in enumerate(packages):\n            self.attribution_widget = AttributionWidget(package=package, master=self)\n            self.attribution_widget.grid(row=int((index + 3) / 3), column=int((index - 1) % 3), padx=20, pady=10)\n        window_post_init(self)\n\n\nre_index)\n            self.frame_rate = self.image_capture.get(cv2.CAP_PROP_FPS)\n            self.frame_height = self.image_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n            self.frame_width = self.image_capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n            if not self.image_capture.isOpened():\n                self.camera_failsafe += 1\n            else:\n                if self.camera_failsafe > 0 and (not init):\n                    CTkMessagebox(title='Camera Changed', message=f'The camera specified could not be connected to. Automatically switching to the next available camera: {self.camera_enum.get_cameras()[self.active_camera_index]}', **messagebox_helper.common_args)\n                self.camera_failsafe = 0\n                self._notify_camera_change_observer(self.active_camera_index)\n                break\n        self.swapping_source = False\n        save_manager.save_variable(self.active_camera_index, ACTIVE_CAMERA_SAVEFILE)\n\n    def _check_failsafe(self) -> None:\n        if self.camera_failsafe >= len(self.camera_enum.get_cameras()):\n            message = 'FreeMoveVR was unable connect to any cameras.'\n            if sys.platform == 'darwin':\n                message += ' Please enable the application to access cameras and relaunch.'\n            result = CTkMessagebox(title='No Cameras Available', message=message, icon=messagebox_helper.CANCEL_ICON, option_1=messagebox_helper.\n\n## Class Main ##\n\nDocstring:\nThe main class of the program.\n\nCode:\nclass Main:\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the main window and starts the main loop\n        \"\"\"\n        if sys.platform != 'darwin':\n            if 'pyi_splash' in sys.modules:\n                pyi_splash.update_text('Almost Done...')\n        self.camera_manager = CameraManager()\n        self.calibration = Calibration(camera_manager=self.camera_manager)\n        self.tracker_manager = TrackerManager()\n        self.interface_manager = InterfaceManager(tracker_manager=self.tracker_manager, camera_manager=self.camera_manager)\n        self.pose_detection = PoseDetection(calibration=self.calibration, interface_manager=self.interface_manager)\n        self.feed_updater = FeedUpdater(camera_manager=self.camera_manager, pose_detection=self.pose_detection)\n        self.main_window = MainWindow(interface_manager=self.interface_manager, calibration=self.calibration, tracker_manager=self.tracker_manager, camera_manager=self.camera_manager, pose_detection=self.pose_detection, feed_updater=self.feed_updater)\n        if sys.platform != 'darwin':\n            if 'pyi_splash' in sys.modules:\n                pyi_splash.close()\n        atexit.register(self.on_close)\n        self.main_window.mainloop()\n\n    def on_close(self) -> None:\n        \"\"\"\n        Preforms cleanup across the application.\n       ",
        "output": "Based on the provided code, the desktop app does not support Mac. The condition `if sys.platform != 'darwin':` is present in several places, indicating that certain functionalities are only available on non-Mac platforms. For example, in the `_check_failsafe` method of the `CameraManager` class, a messagebox is displayed if the application is unable to connect to any cameras on Mac, and it provides a specific instruction for Mac users. Additionally, the `on_close` method is registered with `atexit.register`, but this is only executed when the application is closed on non-Mac platforms."
    },
    {
        "question": "Does the desktop app support Windows?",
        "database_value": "desktop",
        "related_docs": "## Class DelegateMenu ##\n\nDocstring:\nThe menu to change the pose detection to use the CPU or GPU.\n\nCode:\nclass DelegateMenu(CTkFrame):\n\n    def __init__(self, parent: CTkToplevel) -> None:\n        super().__init__(parent)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Set Delegate'\n        self.title = CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set where the pose detection model should be run.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.variable = IntVar(value=save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or Delegate.CPU)\n        radiobutton = CTkRadioButton(self, text='CPU', value=Delegate.CPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.CPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        radiobutton.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        radiobutton = CTkRadioButton(self, text='GPU', value=Delegate.GPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.GPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        if sys.platform == 'win32':\n            radiobutton.configure(state='disabled')\n        radiobutton.grid(row=2, column=0, padx=10, pady=(10, 0), sticky='w')\n        if sys.platform == 'win32':\n            self.windows\n\n## Class MainWindow ##\n\nDocstring:\nThe main window of the application.\n\nCode:\nclass MainWindow(customtkinter.CTk):\n\n    def __init__(self, pose_detection: PoseDetection, tracker_manager: TrackerManager, camera_manager: CameraManager, calibration: Calibration, interface_manager: InterfaceManager, feed_updater: FeedUpdater):\n        super().__init__(className='Free Move VR Desktop')\n        self.title('FreeMoveVR Desktop')\n        customtkinter.set_appearance_mode(save_manager.load_variable(save_manager.APPEARANCE_MODE_SAVEFILE) or 'Dark')\n        customtkinter.set_default_color_theme(get_static_data_path(os.path.join('themes', f\"{save_manager.load_variable(save_manager.COLOR_THEME_SAVEFILE) or 'Blue'}.json\")))\n        self.grid_columnconfigure(0, weight=1)\n        self.grid_rowconfigure(0, weight=1)\n        self.grid_columnconfigure(2, weight=4)\n        self.pose_detection: PoseDetection = pose_detection\n        self.tracker_manager: TrackerManager = tracker_manager\n        self.camera_manager: CameraManager = camera_manager\n        self.calibration: Calibration = calibration\n        self.interface_manager: InterfaceManager = interface_manager\n        self.feed_updater: FeedUpdater = feed_updater\n        self.settings_bar = SettingsBar(master=self, tracker_manager=self.tracker_manager, pose_detection=self.pose_detection, camera_manager=self.camera_manager, calibration=self.calib\n\n_help_text = CTkLabel(self, text='GPU pose processing\\nnot available on Windows.')\n            self.windows_help_text.grid(row=3, column=0, padx=10, pady=10, sticky='ew')\n        else:\n            self.help_text = CTkLabel(self, text='Delegate will be applied after restart.')\n            self.help_text.grid(row=3, column=0, padx=10, pady=10, sticky='ew')\n\n    def destroy(self) -> None:\n        self.tooltip_title.destroy()\n        super().destroy()\n\n\n## Class InterfaceMenu ##\n\nDocstring:\nUser interface controls for the interface to external applications.\nDisplays the available interfaces and allows the user to select how the data should be transferred outside the app.\n\nCode:\nclass InterfaceMenu(customtkinter.CTkFrame):\n\n    def __init__(self, master: customtkinter.CTkScrollableFrame, interface_manager: InterfaceManager) -> None:\n        super().__init__(master)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'VR Interface'\n        self.variable = customtkinter.StringVar(value='')\n        self.interface_manager: InterfaceManager = interface_manager\n        self.title = customtkinter.CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set how to send the tracker data to VR.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.interface_select = tk.IntVar(value=list(self.interface_manager.interfaces.values()).index(self.interface_manager.active_interface))\n        for interface_index, interface in enumerate(list(self.interface_manager.interfaces)):\n            if interface == 'SteamVR Driver' and sys.platform != 'win32':\n                state = 'disabled'\n            else:\n                state = 'normal'\n            radiobutton = customtkinter.CTkRadioButton(self, text=interface, value=i\n\nnterface_index, variable=self.interface_select, command=lambda: self.change_interface(key=list(self.interface_manager.interfaces.keys())[self.interface_select.get()]), state=state)\n            if interface == 'SteamVR Driver':\n                if sys.platform != 'win32':\n                    self.tooltip_steam_vr = CTkToolTip(radiobutton, message='Only supported on Windows.')\n                else:\n                    self.tooltip_steam_vr = CTkToolTip(radiobutton, message='Connect to SteamVR using the FreeMoveVR driver.')\n            elif interface == 'OSC':\n                self.tooltip_osc = CTkToolTip(radiobutton, message='Connect to VR Chat using OSC. Allows additional devices to connect over Bluetooth.')\n            elif interface == 'Bluetooth':\n                self.tooltip_bluetooth = CTkToolTip(radiobutton, message='Connect to another FreeMoveVR device using Bluetooth for OSC tracking.')\n            radiobutton.grid(row=interface_index + 1, column=0, padx=10, pady=(10, 0), sticky='w')\n        self.interface_manager.register_interface_change_callback(self._update_interface_select)\n\n    def change_interface(self, key: str) -> None:\n        \"\"\"\n        changes the interface to be used\n\n        :param key: The key of the interface to change to.\n        \"\"\"\n        self.interface_manager.change_interface(key)\n\n    def _update_interface_select(self, key: str) -> None:\n        se",
        "output": "Based on the provided code snippets, the desktop application does not support Windows for GPU pose processing. The comment in the code states that \"GPU pose processing not available on Windows.\" However, it does not explicitly state whether the entire application is supported on Windows or not. Therefore, while GPU pose processing is not supported on Windows, it does not necessarily mean that the entire application is not supported on Windows."
    },
    {
        "question": "Does the desktop app support Linux?",
        "database_value": "desktop",
        "related_docs": "## Class MainWindow ##\n\nDocstring:\nThe main window of the application.\n\nCode:\nclass MainWindow(customtkinter.CTk):\n\n    def __init__(self, pose_detection: PoseDetection, tracker_manager: TrackerManager, camera_manager: CameraManager, calibration: Calibration, interface_manager: InterfaceManager, feed_updater: FeedUpdater):\n        super().__init__(className='Free Move VR Desktop')\n        self.title('FreeMoveVR Desktop')\n        customtkinter.set_appearance_mode(save_manager.load_variable(save_manager.APPEARANCE_MODE_SAVEFILE) or 'Dark')\n        customtkinter.set_default_color_theme(get_static_data_path(os.path.join('themes', f\"{save_manager.load_variable(save_manager.COLOR_THEME_SAVEFILE) or 'Blue'}.json\")))\n        self.grid_columnconfigure(0, weight=1)\n        self.grid_rowconfigure(0, weight=1)\n        self.grid_columnconfigure(2, weight=4)\n        self.pose_detection: PoseDetection = pose_detection\n        self.tracker_manager: TrackerManager = tracker_manager\n        self.camera_manager: CameraManager = camera_manager\n        self.calibration: Calibration = calibration\n        self.interface_manager: InterfaceManager = interface_manager\n        self.feed_updater: FeedUpdater = feed_updater\n        self.settings_bar = SettingsBar(master=self, tracker_manager=self.tracker_manager, pose_detection=self.pose_detection, camera_manager=self.camera_manager, calibration=self.calib\n\n## Class AboutPopup ##\n\nDocstring:\nPopup window that displays information about the application and the libraries used.\n\nCode:\nclass AboutPopup(customtkinter.CTkToplevel):\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.title('About FreeMoveVR Desktop')\n        headline = '\\nCopyright 2024 - William Parker - FreeMove VR  \\n\\nLibraries Used:'\n        self.headline = customtkinter.CTkLabel(self, text=headline)\n        self.headline.grid(row=0, column=0, padx=20, pady=10, sticky='ew', columnspan=3)\n        packages_path = get_static_data_path('packages.json')\n        with open(packages_path, 'r', encoding='utf-8') as file:\n            packages: List[Dict[str, str]] = json.load(file)\n        for package in packages:\n            if package['platform'] != '' and package['platform'] != sys.platform:\n                packages.remove(package)\n        for index, package in enumerate(packages):\n            self.attribution_widget = AttributionWidget(package=package, master=self)\n            self.attribution_widget.grid(row=int((index + 3) / 3), column=int((index - 1) % 3), padx=20, pady=10)\n        window_post_init(self)\n\n\n## Class InterfaceMenu ##\n\nDocstring:\nUser interface controls for the interface to external applications.\nDisplays the available interfaces and allows the user to select how the data should be transferred outside the app.\n\nCode:\nclass InterfaceMenu(customtkinter.CTkFrame):\n\n    def __init__(self, master: customtkinter.CTkScrollableFrame, interface_manager: InterfaceManager) -> None:\n        super().__init__(master)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'VR Interface'\n        self.variable = customtkinter.StringVar(value='')\n        self.interface_manager: InterfaceManager = interface_manager\n        self.title = customtkinter.CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set how to send the tracker data to VR.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.interface_select = tk.IntVar(value=list(self.interface_manager.interfaces.values()).index(self.interface_manager.active_interface))\n        for interface_index, interface in enumerate(list(self.interface_manager.interfaces)):\n            if interface == 'SteamVR Driver' and sys.platform != 'win32':\n                state = 'disabled'\n            else:\n                state = 'normal'\n            radiobutton = customtkinter.CTkRadioButton(self, text=interface, value=i\n\nnterface_index, variable=self.interface_select, command=lambda: self.change_interface(key=list(self.interface_manager.interfaces.keys())[self.interface_select.get()]), state=state)\n            if interface == 'SteamVR Driver':\n                if sys.platform != 'win32':\n                    self.tooltip_steam_vr = CTkToolTip(radiobutton, message='Only supported on Windows.')\n                else:\n                    self.tooltip_steam_vr = CTkToolTip(radiobutton, message='Connect to SteamVR using the FreeMoveVR driver.')\n            elif interface == 'OSC':\n                self.tooltip_osc = CTkToolTip(radiobutton, message='Connect to VR Chat using OSC. Allows additional devices to connect over Bluetooth.')\n            elif interface == 'Bluetooth':\n                self.tooltip_bluetooth = CTkToolTip(radiobutton, message='Connect to another FreeMoveVR device using Bluetooth for OSC tracking.')\n            radiobutton.grid(row=interface_index + 1, column=0, padx=10, pady=(10, 0), sticky='w')\n        self.interface_manager.register_interface_change_callback(self._update_interface_select)\n\n    def change_interface(self, key: str) -> None:\n        \"\"\"\n        changes the interface to be used\n\n        :param key: The key of the interface to change to.\n        \"\"\"\n        self.interface_manager.change_interface(key)\n\n    def _update_interface_select(self, key: str) -> None:\n        se\n\n## Class DelegateMenu ##\n\nDocstring:\nThe menu to change the pose detection to use the CPU or GPU.\n\nCode:\nclass DelegateMenu(CTkFrame):\n\n    def __init__(self, parent: CTkToplevel) -> None:\n        super().__init__(parent)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Set Delegate'\n        self.title = CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set where the pose detection model should be run.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.variable = IntVar(value=save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or Delegate.CPU)\n        radiobutton = CTkRadioButton(self, text='CPU', value=Delegate.CPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.CPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        radiobutton.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        radiobutton = CTkRadioButton(self, text='GPU', value=Delegate.GPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.GPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        if sys.platform == 'win32':\n            radiobutton.configure(state='disabled')\n        radiobutton.grid(row=2, column=0, padx=10, pady=(10, 0), sticky='w')\n        if sys.platform == 'win32':\n            self.windows",
        "output": "Based on the provided code, the desktop application does not support Linux. This is evident in the `InterfaceMenu` class where there is a condition that checks if the platform is not 'win32' and disables the SteamVR Driver interface. Since Linux is not listed as a supported platform, it can be inferred that the application is only designed to run on Windows."
    },
    {
        "question": "Does the desktop app support FreeBSD?",
        "database_value": "desktop",
        "related_docs": "## Class MainWindow ##\n\nDocstring:\nThe main window of the application.\n\nCode:\nclass MainWindow(customtkinter.CTk):\n\n    def __init__(self, pose_detection: PoseDetection, tracker_manager: TrackerManager, camera_manager: CameraManager, calibration: Calibration, interface_manager: InterfaceManager, feed_updater: FeedUpdater):\n        super().__init__(className='Free Move VR Desktop')\n        self.title('FreeMoveVR Desktop')\n        customtkinter.set_appearance_mode(save_manager.load_variable(save_manager.APPEARANCE_MODE_SAVEFILE) or 'Dark')\n        customtkinter.set_default_color_theme(get_static_data_path(os.path.join('themes', f\"{save_manager.load_variable(save_manager.COLOR_THEME_SAVEFILE) or 'Blue'}.json\")))\n        self.grid_columnconfigure(0, weight=1)\n        self.grid_rowconfigure(0, weight=1)\n        self.grid_columnconfigure(2, weight=4)\n        self.pose_detection: PoseDetection = pose_detection\n        self.tracker_manager: TrackerManager = tracker_manager\n        self.camera_manager: CameraManager = camera_manager\n        self.calibration: Calibration = calibration\n        self.interface_manager: InterfaceManager = interface_manager\n        self.feed_updater: FeedUpdater = feed_updater\n        self.settings_bar = SettingsBar(master=self, tracker_manager=self.tracker_manager, pose_detection=self.pose_detection, camera_manager=self.camera_manager, calibration=self.calib\n\nific name even outside FreeMoveVR.\\nVR connection will switch to Bluetooth to update device.\")\n            else:\n                self.platform_help_text = CTkLabel(self, text='Max character limit: 8\\nName will be applied after restart.')\n            self.platform_help_text.grid(row=3, column=0, padx=10, pady=10, sticky='ew', columnspan=2)\n\n    def save_name(self):\n        name = self.textbox.get('0.0', 'end')\n        name = name.strip()\n        if sys.platform == 'darwin':\n            name = name[:8]\n        ble_interface = self.interface_manager.interfaces['Bluetooth']\n        if isinstance(ble_interface, BluetoothInterface):\n            ble_interface = cast(BluetoothInterface, ble_interface)\n        else:\n            raise ValueError('Bluetooth interface is not an instance of BluetoothInterface')\n        ble_interface.name_change = True\n        save_manager.save_variable(name, save_manager.BLUETOOTH_DEVICE_NAME_SAVEFILE)\n        if sys.platform == 'win32' or isinstance(self.interface_manager.active_interface, BluetoothInterface):\n            self.interface_manager.change_interface('Bluetooth')\n\n\nre_index)\n            self.frame_rate = self.image_capture.get(cv2.CAP_PROP_FPS)\n            self.frame_height = self.image_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n            self.frame_width = self.image_capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n            if not self.image_capture.isOpened():\n                self.camera_failsafe += 1\n            else:\n                if self.camera_failsafe > 0 and (not init):\n                    CTkMessagebox(title='Camera Changed', message=f'The camera specified could not be connected to. Automatically switching to the next available camera: {self.camera_enum.get_cameras()[self.active_camera_index]}', **messagebox_helper.common_args)\n                self.camera_failsafe = 0\n                self._notify_camera_change_observer(self.active_camera_index)\n                break\n        self.swapping_source = False\n        save_manager.save_variable(self.active_camera_index, ACTIVE_CAMERA_SAVEFILE)\n\n    def _check_failsafe(self) -> None:\n        if self.camera_failsafe >= len(self.camera_enum.get_cameras()):\n            message = 'FreeMoveVR was unable connect to any cameras.'\n            if sys.platform == 'darwin':\n                message += ' Please enable the application to access cameras and relaunch.'\n            result = CTkMessagebox(title='No Cameras Available', message=message, icon=messagebox_helper.CANCEL_ICON, option_1=messagebox_helper.\n\n## Class BluetoothInterface ##\n\nDocstring:\nClass to connect to another device running FreeMoveVR through Bluetooth to send the combined data over OSC.\n\nCode:\nclass BluetoothInterface(BaseInterface):\n\n    def __init__(self, tracker_manager: TrackerManager, camera_manager: CameraManager) -> None:\n        super().__init__(tracker_manager, camera_manager)\n        self.server: Optional[BlessServer] = None\n        self.name_change = False\n\n    def setup(self) -> None:\n        super().setup()\n        self._notify_message_observer('Bluetooth Active')\n        gatt_thread = threading.Thread(target=self._threaded_task)\n        gatt_thread.daemon = True\n        gatt_thread.start()\n\n    def _threaded_task(self) -> None:\n        loop = asyncio.new_event_loop()\n        loop.run_until_complete(self.run_gatt(loop))\n\n    def write_request(self, _: BlessGATTCharacteristic, value: bytearray) -> None:\n        \"\"\"\n        Received messages from the central device to be interpreted in the application.\n        \"\"\"\n        received_message = [bytes([byte]) for byte in value]\n        if received_message[OPTIONS_BYTE] == SETTINGS_MESSAGE_FLAG:\n            self._on_receive_settings(received_message)\n\n    async def run_gatt(self, loop: AbstractEventLoop) -> None:\n        \"\"\"\n        Sets up the server and awaits connection to the central device.\n        \"\"\"\n        bluetooth_name = save_manager.load_variab\n\nnterface_index, variable=self.interface_select, command=lambda: self.change_interface(key=list(self.interface_manager.interfaces.keys())[self.interface_select.get()]), state=state)\n            if interface == 'SteamVR Driver':\n                if sys.platform != 'win32':\n                    self.tooltip_steam_vr = CTkToolTip(radiobutton, message='Only supported on Windows.')\n                else:\n                    self.tooltip_steam_vr = CTkToolTip(radiobutton, message='Connect to SteamVR using the FreeMoveVR driver.')\n            elif interface == 'OSC':\n                self.tooltip_osc = CTkToolTip(radiobutton, message='Connect to VR Chat using OSC. Allows additional devices to connect over Bluetooth.')\n            elif interface == 'Bluetooth':\n                self.tooltip_bluetooth = CTkToolTip(radiobutton, message='Connect to another FreeMoveVR device using Bluetooth for OSC tracking.')\n            radiobutton.grid(row=interface_index + 1, column=0, padx=10, pady=(10, 0), sticky='w')\n        self.interface_manager.register_interface_change_callback(self._update_interface_select)\n\n    def change_interface(self, key: str) -> None:\n        \"\"\"\n        changes the interface to be used\n\n        :param key: The key of the interface to change to.\n        \"\"\"\n        self.interface_manager.change_interface(key)\n\n    def _update_interface_select(self, key: str) -> None:\n        se",
        "output": "Based on the provided code snippets, there is no direct indication that the desktop app supports FreeBSD. The code is written for a specific platform (likely Windows or macOS) and does not include any platform-specific checks for FreeBSD. Therefore, it can be inferred that the desktop app does not support FreeBSD based on the given information."
    },
    {
        "question": "What UI framework does the desktop app use?",
        "database_value": "desktop",
        "related_docs": "## Class MainWindow ##\n\nDocstring:\nThe main window of the application.\n\nCode:\nclass MainWindow(customtkinter.CTk):\n\n    def __init__(self, pose_detection: PoseDetection, tracker_manager: TrackerManager, camera_manager: CameraManager, calibration: Calibration, interface_manager: InterfaceManager, feed_updater: FeedUpdater):\n        super().__init__(className='Free Move VR Desktop')\n        self.title('FreeMoveVR Desktop')\n        customtkinter.set_appearance_mode(save_manager.load_variable(save_manager.APPEARANCE_MODE_SAVEFILE) or 'Dark')\n        customtkinter.set_default_color_theme(get_static_data_path(os.path.join('themes', f\"{save_manager.load_variable(save_manager.COLOR_THEME_SAVEFILE) or 'Blue'}.json\")))\n        self.grid_columnconfigure(0, weight=1)\n        self.grid_rowconfigure(0, weight=1)\n        self.grid_columnconfigure(2, weight=4)\n        self.pose_detection: PoseDetection = pose_detection\n        self.tracker_manager: TrackerManager = tracker_manager\n        self.camera_manager: CameraManager = camera_manager\n        self.calibration: Calibration = calibration\n        self.interface_manager: InterfaceManager = interface_manager\n        self.feed_updater: FeedUpdater = feed_updater\n        self.settings_bar = SettingsBar(master=self, tracker_manager=self.tracker_manager, pose_detection=self.pose_detection, camera_manager=self.camera_manager, calibration=self.calib\n\n## Class InterfaceMenu ##\n\nDocstring:\nUser interface controls for the interface to external applications.\nDisplays the available interfaces and allows the user to select how the data should be transferred outside the app.\n\nCode:\nclass InterfaceMenu(customtkinter.CTkFrame):\n\n    def __init__(self, master: customtkinter.CTkScrollableFrame, interface_manager: InterfaceManager) -> None:\n        super().__init__(master)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'VR Interface'\n        self.variable = customtkinter.StringVar(value='')\n        self.interface_manager: InterfaceManager = interface_manager\n        self.title = customtkinter.CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set how to send the tracker data to VR.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.interface_select = tk.IntVar(value=list(self.interface_manager.interfaces.values()).index(self.interface_manager.active_interface))\n        for interface_index, interface in enumerate(list(self.interface_manager.interfaces)):\n            if interface == 'SteamVR Driver' and sys.platform != 'win32':\n                state = 'disabled'\n            else:\n                state = 'normal'\n            radiobutton = customtkinter.CTkRadioButton(self, text=interface, value=i\n\n## Class DelegateMenu ##\n\nDocstring:\nThe menu to change the pose detection to use the CPU or GPU.\n\nCode:\nclass DelegateMenu(CTkFrame):\n\n    def __init__(self, parent: CTkToplevel) -> None:\n        super().__init__(parent)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Set Delegate'\n        self.title = CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set where the pose detection model should be run.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.variable = IntVar(value=save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or Delegate.CPU)\n        radiobutton = CTkRadioButton(self, text='CPU', value=Delegate.CPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.CPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        radiobutton.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        radiobutton = CTkRadioButton(self, text='GPU', value=Delegate.GPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.GPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        if sys.platform == 'win32':\n            radiobutton.configure(state='disabled')\n        radiobutton.grid(row=2, column=0, padx=10, pady=(10, 0), sticky='w')\n        if sys.platform == 'win32':\n            self.windows\n\n## Class AboutPopup ##\n\nDocstring:\nPopup window that displays information about the application and the libraries used.\n\nCode:\nclass AboutPopup(customtkinter.CTkToplevel):\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.title('About FreeMoveVR Desktop')\n        headline = '\\nCopyright 2024 - William Parker - FreeMove VR  \\n\\nLibraries Used:'\n        self.headline = customtkinter.CTkLabel(self, text=headline)\n        self.headline.grid(row=0, column=0, padx=20, pady=10, sticky='ew', columnspan=3)\n        packages_path = get_static_data_path('packages.json')\n        with open(packages_path, 'r', encoding='utf-8') as file:\n            packages: List[Dict[str, str]] = json.load(file)\n        for package in packages:\n            if package['platform'] != '' and package['platform'] != sys.platform:\n                packages.remove(package)\n        for index, package in enumerate(packages):\n            self.attribution_widget = AttributionWidget(package=package, master=self)\n            self.attribution_widget.grid(row=int((index + 3) / 3), column=int((index - 1) % 3), padx=20, pady=10)\n        window_post_init(self)\n\n\n## Class Main ##\n\nDocstring:\nThe main class of the program.\n\nCode:\nclass Main:\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the main window and starts the main loop\n        \"\"\"\n        if sys.platform != 'darwin':\n            if 'pyi_splash' in sys.modules:\n                pyi_splash.update_text('Almost Done...')\n        self.camera_manager = CameraManager()\n        self.calibration = Calibration(camera_manager=self.camera_manager)\n        self.tracker_manager = TrackerManager()\n        self.interface_manager = InterfaceManager(tracker_manager=self.tracker_manager, camera_manager=self.camera_manager)\n        self.pose_detection = PoseDetection(calibration=self.calibration, interface_manager=self.interface_manager)\n        self.feed_updater = FeedUpdater(camera_manager=self.camera_manager, pose_detection=self.pose_detection)\n        self.main_window = MainWindow(interface_manager=self.interface_manager, calibration=self.calibration, tracker_manager=self.tracker_manager, camera_manager=self.camera_manager, pose_detection=self.pose_detection, feed_updater=self.feed_updater)\n        if sys.platform != 'darwin':\n            if 'pyi_splash' in sys.modules:\n                pyi_splash.close()\n        atexit.register(self.on_close)\n        self.main_window.mainloop()\n\n    def on_close(self) -> None:\n        \"\"\"\n        Preforms cleanup across the application.\n       ",
        "output": "The desktop app uses the customtkinter UI framework. This is evident from the use of customtkinter classes such as CTkFrame, CTkLabel, and CTkRadioButton in the provided code snippets."
    },
    {
        "question": "Is using named pipes a valid connection method in the driver?",
        "database_value": "driver",
        "related_docs": "/**\n * @file NamedPipeConnection.hpp\n * @author William Parker\n * @brief A connection using Named Pipes for connecting to an application on the same device as the driver is running on.\n * For simplicity, a hard coded limit of 16 connections of named pipes can be made to the driver.\n * @date 2023-06-21\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include <string>\n\n#include <windows.h>\n#include <openvr_driver.h>\n\n#include \"ConnectionBase.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief A connection using Named Pipes for connecting to an application on the same device as the driver is running on.\n     * For simplicity, a hard coded limit of 16 connections of named pipes can be made to the driver.\n     */\n    class NamedPipeConnection : public ConnectionBase\n    {\n    public:\n        /// @brief An arbitrary value for the maximum number of named pipe connections that can be made. This value exists\n        /// so the desktop application and the connection can take create and search over a set number of names,\n        /// and can record when all values have been checked.\n        static const uint_fast8_t maximumNamedPipeConnections{16};\n\n        /**\n         * @brief Construct a new Named Pipe Connection object, which attempts to create a listening named pipe for a\n         * desktop connection to connect to. It will attempt to create a named pipe named with the \n\nfirst available index,\n         * if all indexes are taken, `shutdownFlag` is set to `true` as a named pipe cannot be created.\n         */\n        NamedPipeConnection(uint_fast8_t connectionNumber);\n\n        /**\n         * @brief Reads all the data in the pipe. Has basic error handling on the pipe and may set `shutdownFlag` to `true`\n         * if the pipe is broken or deleted.\n         */\n        void checkNamedPipeContents();\n\n        /**\n         * @brief Disconnects and closes the pipe and activates the `shutdownFlag`.\n         */\n        void disconnect();\n\n    protected:\n        /**\n         * @brief Constantly running function in this connection's thread.\n         * While the connection should not shut down, read the data in the named pipe.\n         */\n        void mainLoop();\n\n        // /**\n        //  * @brief Sends a binary message represented as a `std::vector` of integers to the connected device.\n        //  *\n        //  * @param outgoingMessage The binary message as a `std::vector` of integers.\n        //  */\n        // void sendMessage(const std::vector<uint_fast8_t> &outgoingMessage) override;\n\n    private:\n        /// @brief The name of the named pipe before the index is appended to it.\n        const std::string pipeNameBase{\"\\\\\\\\.\\\\pipe\\\\FreeMoveVRPipe\"};\n\n        /// @brief The handle to the pipe used to communicate with the desktop application.\n        HAND\n\n/**\n * @file ConnectionManager.hpp\n * @author William Parker\n * @brief Handles management for all the listening and active connections to the driver.\n *\n * @date 2023-07-18\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include <string>\n#include <vector>\n#include <thread>\n#include <format>\n#include <map>\n#include <memory>\n#include <typeinfo>\n\n#include <openvr_driver.h>\n\n#include \"ConnectionBase.hpp\"\n#include \"BluetoothConnection.hpp\"\n#include \"NamedPipeConnection.hpp\"\n#include \"ConnectionConstants.hpp\"\n#include \"Messages/BatteryState.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Handles management for all the listening and active connections to the driver.\n     */\n    class ConnectionManager\n    {\n    public:\n        /// @brief The connection objects that do not currently have an active connection to a device.\n        std::unordered_map<ConnectionType, std::shared_ptr<ConnectionBase>> listening{};\n\n        /// @brief The connection object threads that are actively connected to a device.\n        std::vector<std::shared_ptr<ConnectionBase>> active{};\n\n        /// @brief Holds the connections that contain the most relevant landmark pose\n        /// data to use to calculate the trackers in VR for each axis.\n        std::unordered_map<CameraAxis, std::shared_ptr<ConnectionBase>> landmarkPoseDataConnections{};\n\n        /// @brief Keeps track of the time the mos\n\n/**\n * @file RecurringMessage.hpp\n * @author William Parker\n * @brief Computes a binary recurring message into an object.\n * `ConnectionBase::shouldShutdown()` Used to check if the connection is still alive\n * and it is also used to update device battery.\n * @date 2024-02-12\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include <chrono>\n\n#include \"MessageBase.hpp\"\n#include \"BatteryState.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Computes a binary recurring message into an object.\n     * `ConnectionBase::shouldShutdown()` Used to check if the connection is still alive\n     * and it is also used to update device battery.\n     */\n    class RecurringMessage : public MessageBase\n    {\n    public:\n        /// @brief Flag in the options byte to explicitly show the driver that the is is a recurring message,\n        /// meaning that device is still operational and can potentially send pose data to the driver.\n        static constexpr uint_fast8_t recurringMessageFlag{0b01000000};\n\n        /**\n         * @brief The constructor to be used if a Recurring Message has not yet come in yet from the device.\n         * timestamp is set to max() so the timeout function will not active before a connection is made.\n         */\n        RecurringMessage();\n\n        /**\n         * @brief The constructor to be used when a connection is activated. The connection should update \n\n/**\n * @file ConnectionBase.hpp\n * @author William Parker\n * @brief An abstract class for connections.\n * Defines how messages are received, a thread to keep the connection\n * alive, and determines if the connection should be shut down.\n * @date 2023-07-17\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include <string>\n#include <stdexcept>\n#include <vector>\n#include <thread>\n\n#include <openvr_driver.h>\n\n#include \"ConnectionConstants.hpp\"\n#include \"Messages/BatteryState.hpp\"\n#include \"Messages/CommonSettings.hpp\"\n#include \"Messages/PoseMessage.hpp\"\n#include \"Messages/RecurringMessage.hpp\"\n#include \"Messages/SettingsMessage.hpp\"\n#include \"LandmarkData/LandmarkPose.hpp\"\n#include \"LandmarkData/LandmarkPoseData.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief An abstract class for connections.\n     * Defines how messages are received, a thread to keep the connection\n     * alive, and determines if the connection should be shut down.\n     */\n    class ConnectionBase\n    {\n    public:\n        ConnectionBase();\n\n        /// @brief Turned `true` when a connection has been established.\n        bool activated{false};\n\n        /// @brief The most recent time a recurring message sent by the device was received. While the\n        /// connection is listening, it is set to max so that the connection does not time out. Once the\n        /// connection becomes active, the vari",
        "output": "Yes, using named pipes is a valid connection method in the driver. This is evident from the presence of the `NamedPipeConnection` class in the provided code snippets. The `NamedPipeConnection` class is designed to connect to an application on the same device as the driver is running on using named pipes. It has a hard coded limit of 16 connections of named pipes that can be made to the driver."
    },
    {
        "question": "What connection method is available on mobile?",
        "database_value": "mobile",
        "related_docs": "ivateAdvertisement(bluetoothButtonProvider);\n    }\n  }\n\n  /// Attempts to start advertising a FreeMoveVR connection over Bluetooth.\n  ///\n  /// If Bluetooth cannot be used by the app, displays an error to the user.\n  static Future<void> activateAdvertisement(\n    BluetoothButtonProvider bluetoothButtonProvider,\n  ) async {\n    try {\n      await BluetoothSetupHandler.gattServiceSetup(bluetoothButtonProvider);\n      await BluetoothAdvertisingSetupHandler.createAdvertisement();\n\n      BluetoothUI.displayBluetoothActivationNotification();\n\n      bluetoothButtonProvider.bluetoothState = BluetoothState.scanning;\n    } catch (_) {\n      BluetoothUI.displayBluetoothErrorNotification();\n      NotificationUI.playFailureSound();\n\n      bluetoothButtonProvider.bluetoothState = BluetoothState.error;\n    }\n  }\n\n  /// Stop the device from advertising.\n  ///\n  /// Use when BLE is enabled and advertising a connection, and is not\n  /// connected yet. Stops the advertising so no connection can be made.\n  static void manualDisable(\n    BluetoothButtonProvider bluetoothButtonProvider,\n  ) {\n    AdvertisingHandler.stop(AdvertisingHandler.advertisings.first);\n    BluetoothHelper.gattService?.inactivate();\n\n    BluetoothUI.displayBluetoothDisabledNotification();\n\n    bluetoothButtonProvider.bluetoothState = BluetoothState.disabled;\n  }\n\n  /// Notifies the central that the device wishes to disconnect.\n\n\n BluetoothHelper.centralDevice = device;\n        AdvertisingHandler.stop(AdvertisingHandler.advertisings.first);\n\n        BluetoothSettingsUpdateHandler.notifySettings();\n\n        // If calibration data exists, send it to the driver\n        if (prefs.containsKey(Global.averageLandmarkMessageSave) &&\n            prefs.containsKey(Global.statisticalMessageSave)) {\n          BluetoothNotificationHandler.sendCalibrationData(\n            prefs.getStringList(Global.averageLandmarkMessageSave)!,\n          );\n\n          BluetoothNotificationHandler.sendCalibrationData(\n            prefs.getStringList(Global.statisticalMessageSave)!,\n          );\n        }\n\n        bluetoothButtonProvider.bluetoothState = BluetoothState.connected;\n        BluetoothUI.displayDeviceConnectedNotification();\n        NotificationUI.playSuccessSound();\n      } else {\n        BluetoothHelper.centralDevice = null;\n        if (BluetoothHelper.disconnectingRequestSent) {\n          BluetoothHelper.disconnectingRequestSent = false;\n          BluetoothHelper.gattService?.inactivate();\n\n          BluetoothUI.displayBluetoothDisabledWhileConnectedNotification();\n\n          bluetoothButtonProvider.bluetoothState = BluetoothState.disabled;\n        } else {\n          BluetoothUI.displayBluetoothReconnectingNotification();\n          NotificationUI.playFailureSound();\n          BluetoothAdvertisingSetupHandler.createAdvert\n\n// Package imports:\nimport 'package:battery_plus/battery_plus.dart';\n\n// Project imports:\nimport 'package:free_move_vr/bluetooth/bluetooth_helper.dart';\nimport 'package:free_move_vr/messages/disconnect_message.dart';\nimport 'package:free_move_vr/messages/recurring_message.dart';\n\n/// Coordinates how Bluetooth notifications (Messages) are sent to the client.\n/// Used for message specific notifications and a general notification sender.\nclass BluetoothNotificationHandler\n{\n  /// Notifies the connected device of a new message\n  static void sendNotification(List<int> byteMessage) {\n    if (BluetoothHelper.centralDevice != null) {\n      BluetoothHelper.gattService?.characteristics\n          .singleWhere(\n            (element) => element.uuid == BluetoothHelper.characteristicUUID,\n      )\n          .notify(BluetoothHelper.centralDevice!.address, byteMessage);\n    }\n  }\n\n  /// Given a saved calibration pose, converts it to\n  /// binary form and is sent as a notification.\n  static void sendCalibrationData(List<String> savedCalibrationData) {\n    final calibrationData =\n    savedCalibrationData.map((e) => int.parse(e)).toList();\n\n    final List<List<int>> calibrationByteArrayList =\n    BluetoothHelper.divideListIntoSections(\n      calibrationData,\n    );\n\n    for (final message in calibrationByteArrayList) {\n      sendNotification(message);\n    }\n  }\n\n  /// Send a disconnect request to \n\nestNotification() {\n    NotificationUI.displayNotification(\n      content: 'Disconnection request sent.',\n      backgroundColor: Colors.amber,\n    );\n  }\n\n  /// User side popup notification when there was an unexpected disconnection\n  static void displayBluetoothReconnectingNotification() {\n    NotificationUI.displayNotification(\n      content: 'Connection Lost! Reconnecting...',\n    );\n  }\n\n  /// User side popup notification when Bluetooth could not be enabled\n  static void displayBluetoothErrorNotification() {\n    NotificationUI.displayNotification(\n      content: 'Bluetooth could not be enabled, please give permissions and '\n          'restart the application.',\n    );\n  }\n}\n\n\n// Package imports:\nimport 'package:m_ble_peripheral/k_ble_peripheral.dart';\n\n// Project imports:\nimport 'package:free_move_vr/messages/message_helper.dart';\n\n/// Stores constants about Bluetooth as well as global variables for the BLE\n/// service, connected device, and if the device is trying to disconnect.\nclass BluetoothHelper {\n  /// Bool for if the device is trying to disconnect from the driver\n  static bool disconnectingRequestSent = false;\n\n  /// The GATT service for the driver to connect to\n  static KGattService? gattService;\n\n  /// The device that is connected to the GATT service\n  static KGattDevice? centralDevice;\n\n  /// FreeMove VRs Bluetooth LE Service UUID\n  static const String serviceUUID = \"cb017a8d-51ac-465e-a2d8-ff91ebf7841a\";\n\n  /// FreeMove VRs Bluetooth LE characteristic UUID\n  static const String characteristicUUID =\n      \"11895bdc-2ad4-4dd9-9675-0ffcf964025d\";\n\n  /// The max time that a Bluetooth Latency Message can take to get a response.\n  static const Duration bluetoothLatencyTimeout = Duration(milliseconds: 2000);\n\n  static const int bluetoothLatencyMessageCount = 8;\n\n  /// Divides a list into 6 sections\n  static List<List<int>> divideListIntoSections(List<int> originalList) {\n    final dividedList = <List<int>>[];\n    final sectionSize = originalList.length ~/ messageCount;\n    var startIndex = 0;\n\n    for (var i = 0; i < messageCount; i++) {\n      ",
        "output": "Based on the provided code snippets, the connection method available on mobile for FreeMoveVR is Bluetooth Low Energy (BLE). The application uses the `k_ble_peripheral` package for BLE communication and has a GATT service with a specific UUID (`serviceUUID`) that the connected device should connect to. The characteristic UUID (`characteristicUUID`) is also defined for sending and receiving data between the device and the driver."
    },
    {
        "question": "What pose detection model is used on desktop?",
        "database_value": "desktop",
        "related_docs": "## Class DelegateMenu ##\n\nDocstring:\nThe menu to change the pose detection to use the CPU or GPU.\n\nCode:\nclass DelegateMenu(CTkFrame):\n\n    def __init__(self, parent: CTkToplevel) -> None:\n        super().__init__(parent)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Set Delegate'\n        self.title = CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set where the pose detection model should be run.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.variable = IntVar(value=save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or Delegate.CPU)\n        radiobutton = CTkRadioButton(self, text='CPU', value=Delegate.CPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.CPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        radiobutton.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        radiobutton = CTkRadioButton(self, text='GPU', value=Delegate.GPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.GPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        if sys.platform == 'win32':\n            radiobutton.configure(state='disabled')\n        radiobutton.grid(row=2, column=0, padx=10, pady=(10, 0), sticky='w')\n        if sys.platform == 'win32':\n            self.windows\n\n## Class DetectionModeMenu ##\n\nDocstring:\nMenu to change the pose detection mode.\n\nCode:\nclass DetectionModeMenu(customtkinter.CTkFrame):\n\n    def __init__(self, master: customtkinter.CTkScrollableFrame, pose_detection: PoseDetection) -> None:\n        super().__init__(master)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Detection Mode'\n        self.pose_detection = pose_detection\n        self.variable = IntVar(value=self.pose_detection.landmark_level.value)\n        self.title = customtkinter.CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Change which detection model to use.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        radiobutton = customtkinter.CTkRadioButton(self, text='Balanced', value=0, variable=self.variable, command=lambda: self.pose_detection.change_landmarker(LandmarkerLevel(self.variable.get())))\n        self.tooltip_balanced_mode = CTkToolTip(radiobutton, message='Balances accuracy and performance. Recommended for running on moderate hardware.')\n        radiobutton.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        radiobutton = customtkinter.CTkRadioButton(self, text='Heavy', value=1, variable=self.variable, command=lambda: self.pose_detection.change_landmarker(LandmarkerLevel(self.variable.get())))\n  \n\n## Class PoseDetection ##\n\nDocstring:\nOrchestrates the Mediapipe pose detection process\n\nCode:\nclass PoseDetection:\n\n    def __init__(self, calibration: Calibration, interface_manager: InterfaceManager) -> None:\n        \"\"\"\n        Initializes an instance of the pose detector to read poses from input frames\n        \"\"\"\n        self.landmarker: Optional[PoseLandmarker] = None\n        delegate = save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or BaseOptions.Delegate.CPU\n        options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=FULL_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n        self.full_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n        options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=HEAVY_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n        self.heavy_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n        self.landmark_level: LandmarkerLevel\n        landmark_level_save: Optional[LandmarkerLevel] = save_manager.load_variable(LANDMARKER_LEVEL_SAVEFILE)\n        if landmark_level_save is None:\n            self.landmark_level = LandmarkerLevel.FULL\n        else:\n            self.landmark_level = lan\n\nmpy_view()\n        self.timestamp_ms = timestamp_ms\n        self.new_image = True\n        self.current_frame_buffer_size -= 1\n\n    def process_detection_result(self) -> Optional[ndarray]:\n        \"\"\"\n        Returns the output image from the pose detection process\n\n        :return: The output image from the pose detection process or None if no new image is available\n        \"\"\"\n        if self.new_image is True and self.output_image is not None:\n            self.new_image = False\n            if self.pose_result is not None:\n                if len(self.pose_result.pose_landmarks) > 0:\n                    landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                    if self.calibration.calibrating:\n                        self.calibration.add_pose(landmarks)\n                    if self.timestamp_ms is not None:\n                        landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                        self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                    if self.display_points:\n                        image = np.copy(self.output_image)\n                        image.setflags(write=True)\n                        self.output_image = pose_drawer.draw_landmarks_on_image(image, land\n\n## Class Calibration ##\n\nDocstring:\nCalibrates the user's pose when prompted. Provides GUI for the user to calibrate their pose.\n\nCode:\nclass Calibration:\n\n    def __init__(self, camera_manager: CameraManager) -> None:\n        \"\"\"\n        Initializes a Calibration instance.\n        \"\"\"\n        self.camera_manager: CameraManager = camera_manager\n        self.running = False\n        self.calibrating = False\n        self.user_height: Optional[int] = save_manager.load_variable(save_manager.USER_HEIGHT_SAVEFILE)\n        self.calibration_poses: List[List[NormalizedLandmark]] = []\n        self._callback: List[Callable] = []\n\n    def prompt_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n        \"\"\"\n        Prompts the user to calibrate their pose.\n\n        :param root: The root Tk instance.\n        :param interface: The BaseInterface instance.\n        \"\"\"\n        if self.running:\n            return\n        self.running = True\n        result = CTkMessagebox(title='Calibrate Pose', message='Stand in the center of the camera facing forward with your full body in frame. Calibration will begin five seconds after \"Ok\" is pressed. If you are currently playing VR calibrate with your headset on, otherwise do not wear a headset. Calibration will end ten seconds after pressing \"Ok\". For best results, do not move and calibrate before entering VR.', option_1=mess",
        "output": "Based on the provided code, the pose detection model used on desktop is determined by the `Delegate` variable. In the `__init__` method of the `DelegateMenu` class, the `Delegate` variable is initialized with either `Delegate.CPU` or `Delegate.GPU` depending on the value loaded from a save file or if it's the first time running the application.\n\nIf the user has not calibrated their pose and is using a desktop, the default pose detection model used would be determined by the `Delegate` variable in the `Calibration` class. In the `prompt_calibration` method of the `Calibration` class, the `Delegate` variable is initialized with either `Delegate.CPU` or `Delegate.GPU` depending on the value loaded from a save file or if it's the first time running the application.\n\nTherefore, based on the provided code, the pose detection model used on desktop would be either `Delegate.CPU` or `Delegate.GPU`, depending on the user's calibration status and the platform they are using."
    },
    {
        "question": "Can I add a device whitelist to the driver?",
        "database_value": "driver",
        "related_docs": "    /// @brief The UUID of the service that the mobile app uses to send data to the driver.\n        const std::string serviceUUID{\"cb017a8d-51ac-465e-a2d8-ff91ebf7841a\"};\n\n        /// @brief The UUID of the characteristic that the mobile app uses to send data to the driver.\n        const std::string characteristicUUID{\"11895bdc-2ad4-4dd9-9675-0ffcf964025d\"};\n\n        /// @brief The relative path of the device whitelist file from the directory of the driver.\n        const std::string deviceWhitelistDir{\"\\\\device_whitelist.txt\"};\n\n        /// @brief The peripheral that the driver is connected to.\n        SimpleBLE::Peripheral connectedPeripheral{SimpleBLE::Peripheral()};\n\n        /**\n         * @brief Given a vector of peripherals, searches for a peripheral with the FreeMoveVR service and characteristic UUID.\n         * Once one is found, attempts to connect to it's notification stream.\n         * If there are names in the whitelist, any name not in the whitelist will be checked.\n         *\n         * @param peripherals The vector of peripherals to search through.\n         */\n        void searchPeripherals(std::vector<SimpleBLE::Peripheral> &peripherals);\n\n        /**\n         * @brief Get the Bluetooth device whitelist as an unordered set of strings.\n         *\n         * @return std::unordered_set<std::string> All of the acceptable device names.\n         */\n        std::unorder\n\n   * @param rotationOffset the rotation the connection has to base the new calibration values from.\n         *\n         * @return bool if the driver rotation could be updated\n         */\n        bool updateDriverRotation(const CameraRotation &rotationOffset);\n\n        /**\n         * @brief Adds a tracker to emulatedTrackers.\n         *\n         * @param tracker The tracker to add.\n         */\n        void addEmulatedTracker(const std::shared_ptr<TrackerDevice> &tracker);\n        /**\n         * @brief Adds a tracker to driverTrackers. Should only be called on startup.\n         *\n         * @param tracker The tracker to add.\n         */\n        void addDriverTracker(const std::shared_ptr<TrackerDevice> &tracker);\n\n        /**\n         * @brief Removes all trackers of type specified from emulatedTrackers.\n         *\n         * @param tracker The tracker to remove.\n         */\n        void removeEmulatedTracker(const TrackerRole &trackerRole);\n\n        /**\n         * @brief Gets emulated trackers.\n         *\n         * @return std::vector<std::shared_ptr<TrackerDevice>> The emulated trackers.\n         */\n        std::map<TrackerRole, std::shared_ptr<TrackerDevice>> getEmulatedTrackers();\n\n        /**\n         * @brief If tracker does not exist when enabled is true, add the emulated tracker. If it does exist and enabled is false, erase the tracker.\n         *\n         * @param track\n\n/**\n * @file TrackerDevice.hpp\n * @author William Parker\n * @brief The class that handles the tracker devices.\n * @date 2023-03-01\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include <vector>\n#include <chrono>\n#include <functional>\n\n#include <cstdlib>\n\n#include <openvr_driver.h>\n\n#include <glm/gtc/quaternion.hpp>\n\n#include \"../VirtualPose.hpp\"\n#include \"../TrackerRole.hpp\"\n#include \"../PosePoint.hpp\"\n#include \"../PoseCalibration.hpp\"\n#include \"../TrackerUtils.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    class TrackerDevice : public vr::ITrackedDeviceServerDriver\n    {\n    public:\n        /// @brief The current pose of the tracker.\n        vr::DriverPose_t trackerPose{};\n\n        /// @brief The index of the tracker in OpenVR.\n        vr::TrackedDeviceIndex_t device_index_ = vr::k_unTrackedDeviceIndexInvalid;\n\n        /**\n         * @brief Construct a new Tracker Device object\n         *\n         * @param trackerRole The role of the tracker. This is used to determine which tracker it is.\n         */\n        TrackerDevice(TrackerRole trackerRole);\n\n        /**\n         * @brief Destroy the Tracker Device object\n         *\n         */\n        ~TrackerDevice() = default;\n\n        /**\n         * @brief Sets tracker information. Used by OpenVR. Should not be called.\n         *\n         * @param unObjectId Object ID passed in by OpenVR.\n         * @return vr::EVRInitError An e\n\nt recent settings message was received so the\n        /// manager knows when a new settings message arrives and the driver should be updated.\n        std::chrono::high_resolution_clock::time_point lastSettingsMessageTimestamp{};\n\n        /**\n         * @brief Creates a new connection manager, by first opening a new connection of each type.\n         */\n        ConnectionManager();\n\n        /**\n         * @brief Destroy the Connection Manager object. Shuts down all connection threads.\n         */\n        ~ConnectionManager();\n\n        void initialize();\n\n        /**\n         * @brief Shuts down all connection threads.\n         */\n        void shutdown();\n\n        /**\n         * @brief Checks active and listening connections to see if any should be shut down. If so, attempts to open a new connection.\n         */\n        void checkShutdownRequests();\n\n        /**\n         * @brief Checks all listening connections to find if any have connected to a device and\n         * should be moved to the active vector. If so, a new connection is also made.\n         */\n        void checkNewActiveConnections();\n\n        /**\n         * @brief For every connection, orders the status of the connected device's battery in order of which devices\n         * are plugged in and then by percent.\n         *\n         * @return std::vector<BatteryState> The ordered vector of the connected device's battery sta\n\n/**\n * @file SettingsMessage.hpp\n * @author William Parker\n * @brief Computes the settings values from a binary settings message sent by a device.\n * To be used to update the driver and send updated settings to other devices.\n * @date 2024-02-12\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include <vector>\n#include <unordered_map>\n#include <span>\n\n#include \"../../TrackerRole.hpp\"\n#include \"../ConnectionConstants.hpp\"\n#include \"MessageBase.hpp\"\n#include \"CommonSettings.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Computes the settings values from a binary settings message sent by a device.\n     * To be used to update the driver and send updated settings to other devices.\n     */\n    class SettingsMessage : public MessageBase\n    {\n    public:\n        /// @brief Flag to tell the driver that the following data is in settings message\n        /// format and to update the pose calibration and every other connection.\n        static constexpr uint_fast8_t settingsMessageFlag{0b00100000};\n\n        /**\n         * @brief Default constructor for Settings Message. Only meant to be used to used when a\n         * connection is created and no settings message has been sent with real data yet.\n         */\n        SettingsMessage();\n\n        /**\n         * @brief When the ConnectionBase receives a message with it's options byte containing `settingsMessageFlag`,\n        ",
        "output": "Based on the provided code, it appears that there is a variable named `deviceWhitelistDir` which is a string representing the relative path of the device whitelist file from the directory of the driver. This suggests that you can add a device whitelist to the driver by specifying the path to the whitelist file in this variable.\n\nHowever, the code does not show any functionality for adding or managing the whitelist file. You may need to implement additional functionality to handle the addition and management of the device whitelist file."
    },
    {
        "question": "How is rotational information represented in the driver?",
        "database_value": "driver",
        "related_docs": "/**\n * @file LandmarkBase.hpp\n * @author William Parker\n * @brief Stores a single landmark as a part of a pose from a device to be used to calculate the user's current pose.\n * Landmark Base only stores dimensional data of the landmark.\n * @date 2024-02-15\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Stores a single landmark as a part of a pose from a device to be used to calculate the user's current pose.\n     * Landmark Base only stores dimensional data of the landmark.\n     */\n    class LandmarkBase\n    {\n    public:\n        /// @brief Virtual destructor for dynamic casting\n        virtual ~LandmarkBase(){};\n\n        /// @brief The horizontal dimension of the pose relative to the camera's rotation.\n        float xValue{};\n\n        /// @brief The height dimension of the pose.\n        float yValue{};\n    };\n}\n\n\n   * @param rotationOffset the rotation the connection has to base the new calibration values from.\n         *\n         * @return bool if the driver rotation could be updated\n         */\n        bool updateDriverRotation(const CameraRotation &rotationOffset);\n\n        /**\n         * @brief Adds a tracker to emulatedTrackers.\n         *\n         * @param tracker The tracker to add.\n         */\n        void addEmulatedTracker(const std::shared_ptr<TrackerDevice> &tracker);\n        /**\n         * @brief Adds a tracker to driverTrackers. Should only be called on startup.\n         *\n         * @param tracker The tracker to add.\n         */\n        void addDriverTracker(const std::shared_ptr<TrackerDevice> &tracker);\n\n        /**\n         * @brief Removes all trackers of type specified from emulatedTrackers.\n         *\n         * @param tracker The tracker to remove.\n         */\n        void removeEmulatedTracker(const TrackerRole &trackerRole);\n\n        /**\n         * @brief Gets emulated trackers.\n         *\n         * @return std::vector<std::shared_ptr<TrackerDevice>> The emulated trackers.\n         */\n        std::map<TrackerRole, std::shared_ptr<TrackerDevice>> getEmulatedTrackers();\n\n        /**\n         * @brief If tracker does not exist when enabled is true, add the emulated tracker. If it does exist and enabled is false, erase the tracker.\n         *\n         * @param track\n\n /**\n         * @brief Sets the rotation of the driver's coordinate space relative to the world coordinate space.\n         *\n         * @param qRotation The rotation from the driver's coordinate space to the world coordinate space.\n         * @return the new driver pose.\n         */\n        vr::DriverPose_t setDriverRotation(vr::HmdQuaternion_t qRotation);\n\n        /**\n         * @brief Sets the driver space for the tracker.\n         *\n         * @param vecTranslation The transform from the driver's coordinate space to the world coordinate space.\n         * @param qRotation The rotation from the driver's coordinate space to the world coordinate space.\n         */\n        vr::DriverPose_t setDriverSpace(double vecTranslation[], vr::HmdQuaternion_t qRotation);\n\n        /**\n         * @brief Get the Tracker Role of the tracker.\n         *\n         * @return TrackerRole The role of the tracker.\n         */\n        TrackerRole getTrackerRole();\n\n        /**\n         * @brief Get the Serial Number of the tracker.\n         *\n         * @return std::string The serial number of the tracker.\n         */\n        std::string getSerialNumber();\n\n        /**\n         * @brief Get the Device Index of the tracker.\n         *\n         * @return vr::TrackedDeviceIndex_t The index of the tracker in OpenVR.\n         */\n        vr::TrackedDeviceIndex_t getDeviceIndex();\n\n        /**\n         * @bri\n\n/**\n * @file LandmarkPoseData.hpp\n * @author William Parker\n * @brief The data of a connection to be sent to be processed into tracker locations in VR.\n * Contains information about the device, the pose captured during calibration on the device,\n * and the last few poses captured by the device.\n * @date 2024-02-15\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include <chrono>\n\n#include \"ConnectionConstants.hpp\"\n#include \"LandmarkPose.hpp\"\n#include \"CircularBuffer.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief The data of a connection to be sent to be processed into tracker locations in VR.\n     * Contains information about the device, the pose captured during calibration on the device,\n     * and the last few poses captured by the device.\n     */\n    struct LandmarkPoseData\n    {\n        /// @brief Represents where the camera is located at in the play space relative to the front of the internal playspace in SteamVR.\n        CameraRotation cameraRotation{};\n\n        /// @brief The pose from the average pose calculation during calibration.\n        LandmarkPose averagePose{};\n\n        /// @brief A buffer of the most recent landmark poses of the user.\n        CircularBuffer<LandmarkPose> landmarkPoses{6};\n\n        /// @brief The time that the most recent landmark pose was received.\n        std::chrono::system_clock::time_point timestamp{std::chrono::system_cl\n\n/**\n * @file PoseMessage.hpp\n * @author William Parker\n * @brief The representation of a byte message that has data on the current\n * pose of the user or the average pose sent after calibration.\n * The message contains three landmarks which each\n * contain dimensional location and perception data.\n * @date 2024-02-15\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include \"LandmarkMessage.hpp\"\n#include \"Fragments/PoseFragment.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief The representation of a byte message that has data on the current\n     * pose of the user or the calibration pose. The message contains three landmarks\n     * which each contain pose and perception data.\n     */\n    class PoseMessage : public LandmarkMessage\n    {\n    public:\n        /// @brief The flag in the header of the landmark message to\n        /// represent that the landmark message is an average\n        /// value to be used for calibrating the pose in the driver.\n        static constexpr uint_fast8_t averagePoseMessageFlag{0b00001000};\n\n        /**\n         * @brief Converts the message into landmarks to use in a pose.\n         *\n         * @param messageBytes A `std::vector` of `uint_fast8_t`s representing the binary message.\n         * @throws `std::invalid_argument` if `messageBytes`'s length is not 20.\n         */\n        PoseMessage(const std::vector<uint_fast8_t> &messageByt",
        "output": "The rotational information is represented in the driver using the `HmdQuaternion_t` data type, which is a part of the OpenVR API. This data type is used to represent a 4D quaternion, which is a mathematical representation of rotation in 3D space.\n\nIn the provided code, the `setDriverRotation` function takes a `HmdQuaternion_t` as an argument and returns a `vr::DriverPose_t` object. The `HmdQuaternion_t` is used to set the rotation of the driver's coordinate space relative to the world coordinate space.\n\nHere is the relevant code snippet:\n```cpp\n/**\n * @brief Sets the rotation of the driver's coordinate space relative to the world coordinate space.\n *\n * @param qRotation The rotation from the driver's coordinate space to the world coordinate space.\n * @return the new driver pose.\n */\nvr::DriverPose_t setDriverRotation(vr::HmdQuaternion_t qRotation);\n```"
    },
    {
        "question": "What is the list of trackers that the driver emulates?",
        "database_value": "any",
        "related_docs": "erRole The role of the tracker\n         * @param enabled the correct state for the tracker to be in.\n         */\n        void TrackerActivation(const TrackerRole &trackerRole, const bool &enabled);\n\n        /**\n         * @brief Creates the trackers on startup and adds them to the tracker list.\n         *\n         */\n        void createTrackers();\n\n        void updateBatteryStatuses(const std::vector<BatteryState> &batteryStatuses);\n\n        void updateTrackerStates(const std::unordered_map<TrackerRole, bool> &trackerStates);\n\n    private:\n        /// @brief The emulated trackers currently active by FreeMove VR.\n        std::map<TrackerRole, std::shared_ptr<TrackerDevice>> emulatedTrackers{};\n\n        /// @brief The complete map of trackers created by FreeMove VR.\n        std::map<TrackerRole, std::shared_ptr<TrackerDevice>> driverTrackers{};\n    };\n}\n\n   * @param rotationOffset the rotation the connection has to base the new calibration values from.\n         *\n         * @return bool if the driver rotation could be updated\n         */\n        bool updateDriverRotation(const CameraRotation &rotationOffset);\n\n        /**\n         * @brief Adds a tracker to emulatedTrackers.\n         *\n         * @param tracker The tracker to add.\n         */\n        void addEmulatedTracker(const std::shared_ptr<TrackerDevice> &tracker);\n        /**\n         * @brief Adds a tracker to driverTrackers. Should only be called on startup.\n         *\n         * @param tracker The tracker to add.\n         */\n        void addDriverTracker(const std::shared_ptr<TrackerDevice> &tracker);\n\n        /**\n         * @brief Removes all trackers of type specified from emulatedTrackers.\n         *\n         * @param tracker The tracker to remove.\n         */\n        void removeEmulatedTracker(const TrackerRole &trackerRole);\n\n        /**\n         * @brief Gets emulated trackers.\n         *\n         * @return std::vector<std::shared_ptr<TrackerDevice>> The emulated trackers.\n         */\n        std::map<TrackerRole, std::shared_ptr<TrackerDevice>> getEmulatedTrackers();\n\n        /**\n         * @brief If tracker does not exist when enabled is true, add the emulated tracker. If it does exist and enabled is false, erase the tracker.\n         *\n         * @param track\n\n/**\n * @file FootTracker.hpp\n * @author William Parker\n * @brief Class to store data and calculate values the emulated feet trackers.\n * @date 2023-03-02\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include \"TrackerDevice.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    class FootTracker : public TrackerDevice\n    {\n    public:\n        /**\n         * @brief Construct a new Foot Tracker object\n         *\n         * @param trackerRole The role of the tracker.\n         */\n        FootTracker(TrackerRole trackerRole);\n\n        /**\n         * @brief Destroy the Foot Tracker object\n         *\n         */\n        ~FootTracker() = default;\n\n        /**\n         * @brief Updates the pose of the foot tracker.\n         *\n         * @param virtualPose The pose to use to update the tracker.\n         * @return vr::DriverPose_t The new position of the tracker.\n         */\n        vr::DriverPose_t updateTracker(const VirtualPose &virtualPose) override;\n    };\n}\n\n/**\n * @file ShoulderTracker.hpp\n * @author William Parker\n * @brief Class to store data and calculate values the emulated Shoulder trackers.\n * @date 2023-09-08\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include <functional>\n\n#include \"TrackerDevice.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    class ShoulderTracker : public TrackerDevice\n    {\n\n    public:\n        /**\n         * @brief Construct a new Shoulder Tracker object\n         *\n         * @param trackerRole The role of the tracker.\n         */\n        ShoulderTracker(TrackerRole trackerRole);\n\n        /**\n         * @brief Destroy the Shoulder Tracker object\n         *\n         */\n        ~ShoulderTracker() = default;\n\n        /**\n         * @brief Updates the pose of the Shoulder tracker.\n         *\n         * @param virtualPose The pose to use to update the tracker.\n         * @return vr::DriverPose_t The new position of the tracker.\n         */\n        vr::DriverPose_t updateTracker(const VirtualPose &virtualPose) override;\n    };\n}\n\n/**\n * @file KneeTracker.hpp\n * @author William Parker\n * @brief Class to store data and calculate values the emulated knee trackers.\n * @date 2023-05-19\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include <functional>\n\n#include \"TrackerDevice.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    class KneeTracker : public TrackerDevice\n    {\n\n    public:\n        /**\n         * @brief Construct a new Knee Tracker object\n         *\n         * @param trackerRole The role of the tracker.\n         */\n        KneeTracker(TrackerRole trackerRole);\n\n        /**\n         * @brief Destroy the Knee Tracker object\n         *\n         */\n        ~KneeTracker() = default;\n\n        /**\n         * @brief Updates the pose of the Knee tracker.\n         *\n         * @param virtualPose The pose to use to update the tracker.\n         * @return vr::DriverPose_t The new position of the tracker.\n         */\n        vr::DriverPose_t updateTracker(const VirtualPose &virtualPose) override;\n    };\n}",
        "output": "The driver emulates the following trackers: FootTracker, ShoulderTracker, and KneeTracker. These are represented by the classes `FootTracker`, `ShoulderTracker`, and `KneeTracker` respectively in the provided code snippets. Each of these classes inherits from the base class `TrackerDevice`."
    },
    {
        "question": "Is there UI to set my height in the mobile app?",
        "database_value": "mobile",
        "related_docs": "f the camera \"\n              \"needs to be rotated or moved from the place calibration was \"\n              \"done, calibration should be done again. Make sure to also set \"\n              \"your height in centimeters in the options menu.\",\n          image: const Icon(\n            Icons.settings_accessibility,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Permissions\",\n          bodyWidget: Align(\n            alignment: Alignment.centerLeft,\n            child: displayPermissions(),\n          ),\n          image: const Icon(\n            Icons.https,\n            color: Colors.black,\n            size: 175,\n          ),\n          footer: Platform.isAndroid\n              ? Padding(\n                  padding: const EdgeInsets.symmetric(horizontal: 100.0),\n                  child: ElevatedButton(\n                    onPressed: () {\n                      Future(() => Global.perms.request());\n                    },\n                    style: ElevatedButton.styleFrom(\n                      backgroundColor: Colors.lightBlue,\n                      shape: RoundedRectangleBorder(\n                        borderRadius: BorderRadius.circular(8.0),\n                      ),\n                    \n\nthe user,\n/// used in _userHeightCellBuilder.\nList<DropdownMenuEntry> _heightList() {\n  final List<DropdownMenuEntry> heightList = [];\n\n  Global.heightMap().forEach((heightValue, heightText) {\n    heightList.add(\n      DropdownMenuEntry(\n        value: heightValue,\n        label: heightText,\n      ),\n    );\n  });\n\n  return heightList;\n}\n\n\n// Flutter imports:\nimport 'package:flutter/material.dart';\n\n// Package imports:\nimport 'package:flutter_settings_screens/flutter_settings_screens.dart';\nimport 'package:spannable_grid/spannable_grid.dart';\n\n// Project imports:\nimport 'package:free_move_vr/bluetooth/bluetooth_settings_update_handler.dart';\nimport 'package:free_move_vr/global.dart';\nimport 'package:free_move_vr/home_menu/cell_helper.dart';\n\n/// Builds the DropdownMenu to set the user's height\n/// with the correct positioning for Home Menu.\nSpannableGridCellData userHeightCellBuilder(bool isPortrait) {\n  final userHeightWidget = Padding(\n    padding: CellHelper.edgePadding,\n    child: Center(\n      child: DropdownMenu(\n        label: const Text(\"User Height\"),\n        initialSelection:\n            Settings.getValue(Global.userHeightSave, defaultValue: 69),\n        dropdownMenuEntries: _heightList(),\n        menuHeight: 300,\n        onSelected: (value) {\n          Settings.setValue<int>(\n            Global.userHeightSave,\n            value as int,\n            notify: true,\n          );\n          BluetoothSettingsUpdateHandler.notifySettings();\n        },\n      ),\n    ),\n  );\n\n  final userHeightCell = SpannableGridCellData(\n    column: 1,\n    row: isPortrait ? 2 : 3,\n    columnSpan: 2,\n    id: \"userHeightButton\",\n    child: userHeightWidget,\n  );\n\n  return userHeightCell;\n}\n\n/// Generate all reasonable heights for \n\nthe camera vertically\n  late int verticalPixelCount;\n\n  SettingsMessage(Size cameraResolution) {\n    // Height\n    height = Settings.getValue(Global.userHeightSave, defaultValue: 69)!;\n\n    height = height.clamp(\n      Global.heightMinimumFeet * 12,\n      Global.heightLimitFeet * 12 - 1,\n    );\n\n    // Trackers\n    shoulderTrackersEnabled = Settings.getValue(\n      Global.shoulderTrackersEnabledSave,\n      defaultValue: true,\n    )!;\n\n    elbowTrackersEnabled = Settings.getValue(\n      Global.elbowTrackersEnabledSave,\n      defaultValue: true,\n    )!;\n\n    hipTrackerEnabled = Settings.getValue(\n      Global.hipTrackerEnabledSave,\n      defaultValue: true,\n    )!;\n\n    kneeTrackersEnabled = Settings.getValue(\n      Global.kneeTrackersEnabledSave,\n      defaultValue: true,\n    )!;\n\n    footTrackersEnabled = Settings.getValue(\n      Global.footTrackersEnabledSave,\n      defaultValue: true,\n    )!;\n\n    controllerCheckEnabled = Settings.getValue(\n      Global.controllerCheckEnabledSave,\n      defaultValue: true,\n    )!;\n\n    // Rotation\n    playspaceRotationCode =\n        Settings.getValue(Global.devicePositionSave, defaultValue: 0)!;\n\n    // Resolution\n    horizontalPixelCount = cameraResolution.width.toInt();\n\n    verticalPixelCount = cameraResolution.height.toInt();\n  }\n\n  /// Outputs the settings data as a [List] of [int]s\n  /// to be sent to the driver in a Bluetooth message\n \n\nle = '538540__sjonas88__fail-sound.wav';\n\n  /// A map of all possible height values\n  /// FreeMoveVR supports to their text equivalents.\n  static Map<int, String> heightMap() {\n    final Map<int, String> heightMap = {};\n\n    for (int feet = Global.heightMinimumFeet;\n        feet < Global.heightLimitFeet;\n        feet++) {\n      for (int inches = Global.heightMinimumInches;\n          inches < Global.heightLimitInches;\n          inches++) {\n        if (inches == 1) {\n          heightMap[feet * 12 + inches] = \"$feet Feet $inches Inch\";\n        } else {\n          heightMap[feet * 12 + inches] = \"$feet Feet $inches Inches\";\n        }\n      }\n    }\n\n    return heightMap;\n  }\n}\n",
        "output": "Yes, there is a UI to set your height in the mobile app. The UI is built using the `userHeightCellBuilder` function, which creates a `DropdownMenu` widget. This widget allows you to select your height from a list of predefined options. The options are generated by the `_heightList` function, which uses the `heightMap` function to create a list of height values and their corresponding text labels. When you select a height, it is saved to the device's settings using the `Settings.setValue` function, and the Bluetooth driver is notified of the change using the `BluetoothSettingsUpdateHandler.notifySettings()` function."
    },
    {
        "question": "Is there UI to set my height in the desktop app?",
        "database_value": "desktop",
        "related_docs": "## Class CalibrationMenu ##\n\nDocstring:\nMenu for calibrating the user's height and pose.\n\nCode:\nclass CalibrationMenu(customtkinter.CTkFrame):\n\n    def __init__(self, master: customtkinter.CTkScrollableFrame, calibration: Calibration, interface_manager: InterfaceManager, camera_manager: CameraManager):\n        super().__init__(master)\n        self.grid_columnconfigure(0, weight=1)\n        self.grid_columnconfigure(1, weight=1)\n        self.title_text = 'Calibrate'\n        self.calibration: Calibration = calibration\n        self.interface_manager: InterfaceManager = interface_manager\n        self.camera_manager = camera_manager\n        for interface in self.interface_manager.interfaces.values():\n            if interface is not None:\n                interface.register_settings_update_callback(self._set_height)\n        self.title = customtkinter.CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.title.grid(row=0, column=0, columnspan=2, padx=10, pady=(10, 0), sticky='ew')\n        pose_button = customtkinter.CTkButton(self, text='Calibrate User Pose', command=lambda: self.calibration.prompt_calibration(self, self.interface_manager.active_interface))\n        self.tooltip_pose_button = CTkToolTip(pose_button, message='Measures the user to accurately calculate their pose in VR.')\n        pose_button.grid(row=1, column=0, columnspan=2, padx=10, pady=(15, 0\n\n  def _set_height(self) -> tuple[int, int]:\n        user_height = self.calibration.user_height\n        if user_height is None:\n            user_height = 69\n        converted_feet = int(user_height // 12)\n        converted_inches = int(user_height % 12)\n        if converted_feet is None:\n            converted_feet = 5\n        if converted_inches is None:\n            converted_inches = 9\n        return (converted_feet, converted_inches)\n\n    def _record_height(self, _: str, __: str, ___: str) -> None:\n        if self.user_height_feet.get() != '' and self.user_height_inches.get() != '':\n            feet_entry = int(self.user_height_feet.get())\n            inches_entry = int(self.user_height_inches.get())\n            height: int = feet_entry * 12 + inches_entry\n            if height > 0:\n                save_manager.save_variable(height, save_manager.USER_HEIGHT_SAVEFILE)\n        self.interface_manager.active_interface.send_settings()\n\n    def destroy(self):\n        self.tooltip_pose_button.destroy()\n        super().destroy()\n\n\n))\n        height_label = customtkinter.CTkLabel(self, text='User Height:')\n        height_label.grid(row=2, column=0, columnspan=2, padx=(5, 0), pady=(10, 0), sticky='w')\n        height: tuple[int, int] = self._set_height()\n        self.user_height_feet: StringVar = customtkinter.StringVar(value=str(height[0]))\n        self.user_height_feet.trace_add('write', self._record_height)\n        self.user_height_inches: StringVar = customtkinter.StringVar(value=str(height[1]))\n        self.user_height_inches.trace_add('write', self._record_height)\n        validation_command = self.register(number_check_callback)\n        height_feet_label = customtkinter.CTkLabel(self, text='Feet')\n        height_feet_label.grid(row=3, column=0, padx=5, sticky='w')\n        height_feet_entry = customtkinter.CTkEntry(self, placeholder_text='Feet', textvariable=self.user_height_feet, validate='all', validatecommand=(validation_command, '%P'))\n        height_feet_entry.grid(row=4, column=0, padx=10, sticky='w')\n        height_inches_label = customtkinter.CTkLabel(self, text='Inches')\n        height_inches_label.grid(row=3, column=1, padx=5, sticky='w')\n        height_inches_entry = customtkinter.CTkEntry(self, placeholder_text='Inches', textvariable=self.user_height_inches, validate='all', validatecommand=(validation_command, '%P'))\n        height_inches_entry.grid(row=4, column=1, padx=10, sticky='w')\n\n  \n\n## Class MainWindow ##\n\nDocstring:\nThe main window of the application.\n\nCode:\nclass MainWindow(customtkinter.CTk):\n\n    def __init__(self, pose_detection: PoseDetection, tracker_manager: TrackerManager, camera_manager: CameraManager, calibration: Calibration, interface_manager: InterfaceManager, feed_updater: FeedUpdater):\n        super().__init__(className='Free Move VR Desktop')\n        self.title('FreeMoveVR Desktop')\n        customtkinter.set_appearance_mode(save_manager.load_variable(save_manager.APPEARANCE_MODE_SAVEFILE) or 'Dark')\n        customtkinter.set_default_color_theme(get_static_data_path(os.path.join('themes', f\"{save_manager.load_variable(save_manager.COLOR_THEME_SAVEFILE) or 'Blue'}.json\")))\n        self.grid_columnconfigure(0, weight=1)\n        self.grid_rowconfigure(0, weight=1)\n        self.grid_columnconfigure(2, weight=4)\n        self.pose_detection: PoseDetection = pose_detection\n        self.tracker_manager: TrackerManager = tracker_manager\n        self.camera_manager: CameraManager = camera_manager\n        self.calibration: Calibration = calibration\n        self.interface_manager: InterfaceManager = interface_manager\n        self.feed_updater: FeedUpdater = feed_updater\n        self.settings_bar = SettingsBar(master=self, tracker_manager=self.tracker_manager, pose_detection=self.pose_detection, camera_manager=self.camera_manager, calibration=self.calib\n\n## Class MoreOptionsPopup ##\n\nDocstring:\nProvides a window to change more niche options not available in the settings bar.\n\nCode:\nclass MoreOptionsPopup(customtkinter.CTkToplevel):\n\n    def __init__(self, pose_detection: PoseDetection, interface_manager: InterfaceManager) -> None:\n        super().__init__()\n        self.pose_detection = pose_detection\n        self.interface_manager = interface_manager\n        self.title('More Options')\n        self.theme_menu = ThemeMenu(self)\n        self.theme_menu.grid(row=0, column=0, padx=10, pady=10, sticky='nsew')\n        window_post_init(self)\n        self.frame_buffer_size_menu = FrameBufferSizeMenu(self, self.pose_detection)\n        self.frame_buffer_size_menu.grid(row=1, column=0, padx=10, pady=10, sticky='nsew')\n        self.delegate_menu = DelegateMenu(self)\n        self.delegate_menu.grid(row=2, column=0, padx=10, pady=10, sticky='nsew')\n        self.bluetooth_whitelist_menu = BluetoothWhitelistMenu(self, self.interface_manager)\n        self.bluetooth_whitelist_menu.grid(row=0, column=1, padx=10, pady=10, sticky='nsew', rowspan=2)\n        self.device_name_menu = DeviceNameMenu(self, self.interface_manager)\n        self.device_name_menu.grid(row=2, column=1, padx=10, pady=10, sticky='nsew')\n\n    def destroy(self) -> None:\n        \"\"\"\n        Saves data and closes the popup.\n        \"\"\"\n        self.bluetooth_whitelist_menu.save_whi",
        "output": "Yes, there is a UI to set your height in the desktop app. The UI is located within the Calibration class, specifically in the MainWindow class. The Calibration class contains a method called \"calibration\" which includes a SettingsBar object. This SettingsBar object has a method called \"show_height_calibration_window\" that displays a window for setting your height.\n\nHere is the relevant code snippet:\n\n```python\nclass MainWindow(customtkinter.CTk):\n\n    def __init__(self, pose_detection: PoseDetection, tracker_manager: TrackerManager, camera_manager: CameraManager, calibration: Calibration, interface_manager: InterfaceManager, feed_updater: FeedUpdater):\n        # ...\n        self.settings_bar = SettingsBar(master=self, tracker_manager=self.tracker_manager, pose_detection=self.pose_detection, camera_manager=self.camera_manager, calibration=self.calibration)\n        # ...\n\nclass SettingsBar(customtkinter.CTk):\n\n    def __init__(self, master: customtkinter.CTk, tracker_manager: TrackerManager, pose_detection: PoseDetection, camera_manager: CameraManager, calibration: Calibration) -> None:\n        # ...\n        self.calibration = calibration\n        self.show_height_calibration_window()\n        # ...\n```\n\nThe \"show_height_calibration_window\" method is not shown in the provided code, but it is likely defined elsewhere in the codebase. This window would allow you to input your height and save it for use in the application."
    },
    {
        "question": "Is there UI to set my height in the driver?",
        "database_value": "driver",
        "related_docs": "/**\n * @file PoseCalibration.hpp\n * @author William Parker\n * @brief Stores calibration information to be used by trackers.\n * @date 2023-05-25\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include <map>\n#include <unordered_map>\n#include <string>\n\n#include <openvr_driver.h>\n#include <glm/gtc/quaternion.hpp>\n\n#include \"PosePoint.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    class PoseCalibration\n    {\n    public:\n        static float hmdHeight;\n\n        static bool controllerCheck;\n\n        /**\n         * @brief Set the Hmd Height object based on the userHeight.\n         * The height is sent as the height of the user in inches and is converted to height of the headset in meters.\n         *\n         * @param userHeight the hight the user reports in the settings message\n         */\n        static void setHmdHeight(const uint_fast8_t &userHeight);\n\n        static void setControllerCheck(const bool &controllerCheck);\n\n    private:\n        static constexpr float inchesToCentimeters{2.54f};\n        static constexpr float centimetersToMeters{100.0f};\n    };\n}\n\n/**\n * @file LandmarkBase.hpp\n * @author William Parker\n * @brief Stores a single landmark as a part of a pose from a device to be used to calculate the user's current pose.\n * Landmark Base only stores dimensional data of the landmark.\n * @date 2024-02-15\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Stores a single landmark as a part of a pose from a device to be used to calculate the user's current pose.\n     * Landmark Base only stores dimensional data of the landmark.\n     */\n    class LandmarkBase\n    {\n    public:\n        /// @brief Virtual destructor for dynamic casting\n        virtual ~LandmarkBase(){};\n\n        /// @brief The horizontal dimension of the pose relative to the camera's rotation.\n        float xValue{};\n\n        /// @brief The height dimension of the pose.\n        float yValue{};\n    };\n}\n\n\n/**\n * @file CommonSettings.hpp\n * @author William Parker\n * @brief Defines the settings that need to be updated to correctly predict the correct trackers,\n * and the settings that need to be sent to every connected device so that there is no ambiguity\n * between devices on which device is displaying the information that the driver sees.\n * @date 2024-02-23\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include <unordered_map>\n#include <chrono>\n\n#include \"../../TrackerRole.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n\n    /**\n     * @brief Defines the settings that need to be updated to correctly predict the correct trackers,\n     * and the settings that need to be sent to every connected device so that there is no ambiguity\n     * between devices on which device is displaying the information that the driver sees.\n     */\n    struct CommonSettings\n    {\n        /// @brief The updated value for the hight of the user in inches.\n        uint_fast8_t height{69};\n\n        /// @brief The updated value for each tracker.\n        std::unordered_map<TrackerRole, bool> trackerStates{\n            {TrackerRole::LEFT_SHOULDER, false},\n            {TrackerRole::RIGHT_SHOULDER, false},\n            {TrackerRole::LEFT_ELBOW, false},\n            {TrackerRole::RIGHT_ELBOW, false},\n            {TrackerRole::HIP, false},\n            {TrackerRole::LEFT_KNEE, false},\n            {TrackerRole::RIGHT_\n\n/**\n * @file FootTracker.hpp\n * @author William Parker\n * @brief Class to store data and calculate values the emulated feet trackers.\n * @date 2023-03-02\n *\n * @copyright Copyright (c) 2023\n *\n */\n\n#pragma once\n\n#include \"TrackerDevice.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    class FootTracker : public TrackerDevice\n    {\n    public:\n        /**\n         * @brief Construct a new Foot Tracker object\n         *\n         * @param trackerRole The role of the tracker.\n         */\n        FootTracker(TrackerRole trackerRole);\n\n        /**\n         * @brief Destroy the Foot Tracker object\n         *\n         */\n        ~FootTracker() = default;\n\n        /**\n         * @brief Updates the pose of the foot tracker.\n         *\n         * @param virtualPose The pose to use to update the tracker.\n         * @return vr::DriverPose_t The new position of the tracker.\n         */\n        vr::DriverPose_t updateTracker(const VirtualPose &virtualPose) override;\n    };\n}\n\n /**\n         * @brief Sets the rotation of the driver's coordinate space relative to the world coordinate space.\n         *\n         * @param qRotation The rotation from the driver's coordinate space to the world coordinate space.\n         * @return the new driver pose.\n         */\n        vr::DriverPose_t setDriverRotation(vr::HmdQuaternion_t qRotation);\n\n        /**\n         * @brief Sets the driver space for the tracker.\n         *\n         * @param vecTranslation The transform from the driver's coordinate space to the world coordinate space.\n         * @param qRotation The rotation from the driver's coordinate space to the world coordinate space.\n         */\n        vr::DriverPose_t setDriverSpace(double vecTranslation[], vr::HmdQuaternion_t qRotation);\n\n        /**\n         * @brief Get the Tracker Role of the tracker.\n         *\n         * @return TrackerRole The role of the tracker.\n         */\n        TrackerRole getTrackerRole();\n\n        /**\n         * @brief Get the Serial Number of the tracker.\n         *\n         * @return std::string The serial number of the tracker.\n         */\n        std::string getSerialNumber();\n\n        /**\n         * @brief Get the Device Index of the tracker.\n         *\n         * @return vr::TrackedDeviceIndex_t The index of the tracker in OpenVR.\n         */\n        vr::TrackedDeviceIndex_t getDeviceIndex();\n\n        /**\n         * @bri",
        "output": "Based on the provided code snippets, there is no direct UI or method to set your height in the driver. The height is set through a static method `setHmdHeight` in the `PoseCalibration` class, which takes an integer value representing the user's height in inches. However, this method is not exposed as a public interface and is marked as private within the namespace `FreeMoveVRDriver`.\n\nTherefore, it appears that the height is currently set internally by the driver or through some other means not shown in the provided code snippets. If you need to set your height, you may need to modify the source code or contact the developer for further assistance."
    },
    {
        "question": "Can I set the active trackers on mobile?",
        "database_value": "mobile",
        "related_docs": "        subtitle: \"Sets where the phone is relative to the play space.\",\n                settingKey: Global.devicePositionSave,\n                values: const <int, String>{\n                  0: 'Front',\n                  1: 'Right (90\u00b0 Clockwise)',\n                  2: 'Back',\n                  3: 'Left (90\u00b0 Counter Clockwise)',\n                },\n                selected: 0,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Enabled Trackers',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Shoulder\",\n                settingKey: Global.shoulderTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Elbow\",\n                settingKey: Global.elbowTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Hip\",\n                settingKey: Global.hipTrackerEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Knees\",\n                settingKey: Global.kneeTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Feet\",\n                settingKey: Global.footTrackersEnabledSave,\n                defaultValue: true,\n\nrsEnabled = incomingMessage[trackerByte] & 0x10 >> 4 == 1;\n    elbowTrackersEnabled = incomingMessage[trackerByte] & 0x08 >> 3 == 1;\n    hipTrackerEnabled = incomingMessage[trackerByte] & 0x04 >> 2 == 1;\n    kneeTrackersEnabled = incomingMessage[trackerByte] & 0x02 >> 1 == 1;\n    footTrackersEnabled = incomingMessage[trackerByte] & 0x01 >> 0 == 1;\n\n    controllerCheckEnabled = incomingMessage[controllerCheckByte] & 0x01 >> 0 == 1;\n  }\n\n  /// Applies the settings received from the driver\n  void applySettings() {\n    Settings.setValue(\n      Global.userHeightSave,\n      height,\n      notify: true,\n    );\n\n    final Map<String, bool> trackerMap = {\n      Global.shoulderTrackersEnabledSave: shoulderTrackersEnabled,\n      Global.elbowTrackersEnabledSave: elbowTrackersEnabled,\n      Global.hipTrackerEnabledSave: hipTrackerEnabled,\n      Global.kneeTrackersEnabledSave: kneeTrackersEnabled,\n      Global.footTrackersEnabledSave: footTrackersEnabled,\n    };\n\n    trackerMap.forEach((saveLocation, trackerValue) {\n      Settings.setValue<bool>(\n        saveLocation,\n        trackerValue,\n        notify: true,\n      );\n    });\n\n    Settings.setValue(\n      Global.controllerCheckEnabledSave,\n      controllerCheckEnabled,\n      notify: true,\n    );\n  }\n}\n\n\ng to high may lag detection.\";\n    }\n\n    return PopScope(\n      onPopInvoked: _onWillPop,\n      child: SettingsScreen(\n        title: 'Options',\n        children: [\n          SettingsGroup(\n            title: 'Tracking',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Display Points\",\n                subtitle: \"Displays the pose data as seen by the device.\",\n                settingKey: Global.pointsDisplaySave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Use controllers to improve accuracy\",\n                subtitle: \"FreeMoveVR will use the controllers to \"\n                    \"double check itself. Only enable if controllers \"\n                    \"are already being used for hand tracking.\",\n                settingKey: Global.controllerCheckEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Camera',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: 'Camera Quality',\n                subtitle: cameraQualitySubtitle,\n                settingKey: Global.cameraQualitySave,\n                values: platformQualities(),\n                selected: 0,\n              ),\n              RadioSettingsTile(\n                title: \"Device Position\",\n        \n\nEnabledSave = 'elbow-trackers-enabled';\n  static const hipTrackerEnabledSave = 'hip-tracker-enabled';\n  static const kneeTrackersEnabledSave = 'knee-trackers-enabled';\n  static const footTrackersEnabledSave = 'foot-trackers-enabled';\n\n  /// Saves if the driver should compare the location of the VR controllers\n  /// to the location of the landmark hands to test if the pose is accurate\n  static const controllerCheckEnabledSave = 'controller-check-enabled';\n\n  /// The height of the user in inches\n  static const userHeightSave = 'user-height';\n\n  /// The index of the camera to use for the app\n  static const cameraIndexSave = 'cameraIndex';\n\n  /// First time in app flag\n  static const firstVisitSave = 'first-visit';\n\n  /// The save key for the average Landmark Pose,\n  /// saved as the List of binary form of LandmarkMessages\n  /// appended together into a single string\n  static const averageLandmarkMessageSave = 'averageLandmarkMessage';\n\n  /// The save key for the statistical pose,\n  /// saved as the List of binary of StatisticalMessages\n  /// appended together into a single string\n  static const statisticalMessageSave = 'statisticalMessage';\n\n  /// Activate Sound file\n  static const activateSoundFile = '538549__sjonas88__select-2.wav';\n\n  /// Success Sound file\n  static const successSoundFile = '538554__sjonas88__success.wav';\n\n  /// Failure Sound file\n  static const failureSoundFi\n\nsync {\n    calibrationPoses = [];\n\n    CalibrationUI.displayCalibrationStartedNotification();\n\n    await Future.delayed(CalibrationHelper.calibrationPreparationDuration);\n\n    NotificationUI.playActivationSound();\n\n    calibrationActive = true;\n\n    await Future.delayed(CalibrationHelper.calibrationDuration);\n\n    calibrationActive = false;\n\n    try {\n      if (calibrationPoses.length < CalibrationHelper.minimumPoses) {\n        throw RangeError(\n          \"At least ${CalibrationHelper.minimumPoses} pose snapshots are needed.\",\n        );\n      }\n\n      final Pose averagePose = AveragePoseGenerator(calibrationPoses).toPose();\n      final Pose statisticalPose =\n          StatisticalPoseGenerator(calibrationPoses, averagePose).toPose();\n\n      final List<PoseMessage> averageLandmarkMessages =\n          PoseMessage.generateMessages(\n        landmarks: averagePose.landmarks.values.toList(),\n        timestamp: 0,\n        averagePose: true,\n      );\n      final List<StatisticalMessage> statisticalMessages =\n          StatisticalMessage.generateMessages(\n        landmarks: statisticalPose.landmarks.values.toList(),\n      );\n\n      _saveLandmarkPose(\n        averageLandmarkMessages,\n        Global.averageLandmarkMessageSave,\n      );\n      _saveLandmarkPose(statisticalMessages, Global.statisticalMessageSave);\n\n      for (final PoseMessage landmarkMessage in averageLandmarkMessages) {\n  ",
        "output": "Based on the provided code, it appears that the active trackers can be set using the `SwitchSettingsTile` widgets within the `SettingsGroup` widget. These widgets have a `title` and a `settingKey` property, which are used to identify the tracker being set. The `defaultValue` property is also used to set the initial state of the tracker.\n\nFor example, the `ShoulderTrackersEnabled` tracker can be set using the following code:\n```dart\nSwitchSettingsTile(\n  title: \"Shoulder\",\n  settingKey: Global.shoulderTrackersEnabledSave,\n  defaultValue: true,\n),\n```\nSimilarly, the other trackers (`Elbow`, `Hip`, `Knees`, and `Feet`) can be set using their respective `settingKey` properties.\n\nTherefore, it is possible to set the active trackers on mobile by modifying the `defaultValue` property of the corresponding `SwitchSettingsTile` widget."
    },
    {
        "question": "Can I set the active trackers on desktop?",
        "database_value": "desktop",
        "related_docs": "## Class ActiveTrackersMenu ##\n\nDocstring:\nTracker menu for the settings bar.\n\nCode:\nclass ActiveTrackersMenu(customtkinter.CTkFrame):\n\n    def __init__(self, master: customtkinter.CTkScrollableFrame, tracker_manager: TrackerManager, interface_manager: InterfaceManager):\n        super().__init__(master)\n        self.grid_columnconfigure(0, weight=1)\n        self.tracker_manager: TrackerManager = tracker_manager\n        self.interface_manager: InterfaceManager = interface_manager\n        self.title_text = 'Active Trackers'\n        for interface in self.interface_manager.interfaces.values():\n            if interface is not None:\n                interface.register_settings_update_callback(self._update_settings)\n        self.title = customtkinter.CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Enable or disable which trackers to use.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.checkbox_list: List[customtkinter.CTkCheckBox] = []\n        for tracker_index, tracker in enumerate(self.tracker_manager):\n            checkbox = customtkinter.CTkCheckBox(self, text=tracker.name, command=self._toggle_function(tracker))\n            checkbox.grid(row=tracker_index + 1, column=0, padx=10, pady=(10, 0), sticky='w')\n            if tracker.enabled:\n                checkb\n\nenu = ActiveTrackersMenu(self, tracker_manager=self.tracker_manager, interface_manager=self.interface_manager)\n        self.tracker_menu.grid(row=2, column=0, pady=(10, 0), sticky='nsew')\n        self.calibration_menu = CalibrationMenu(self, calibration=self.calibration, interface_manager=self.interface_manager, camera_manager=self.camera_manager)\n        self.calibration_menu.grid(row=3, column=0, pady=(10, 0), sticky='nsew')\n        self.camera_position_menu = CameraPositionMenu(self, interface_manager=self.interface_manager)\n        self.camera_position_menu.grid(row=4, column=0, pady=(10, 0), sticky='nsew')\n        self.detection_menu = DetectionModeMenu(self, pose_detection=self.pose_detection)\n        self.detection_menu.grid(row=5, column=0, pady=(10, 0), sticky='nsew')\n        self.visualization_menu = TrackingMenu(self, pose_detection=self.pose_detection, interface_manager=self.interface_manager)\n        self.visualization_menu.grid(row=6, column=0, pady=(10, 0), sticky='nsew')\n        self.info_menu = InfoMenu(self, pose_detection=self.pose_detection, interface_manager=self.interface_manager)\n        self.info_menu.grid(row=7, column=0, pady=(10, 0), sticky='nsew')\n\n\n## Class MainWindow ##\n\nDocstring:\nThe main window of the application.\n\nCode:\nclass MainWindow(customtkinter.CTk):\n\n    def __init__(self, pose_detection: PoseDetection, tracker_manager: TrackerManager, camera_manager: CameraManager, calibration: Calibration, interface_manager: InterfaceManager, feed_updater: FeedUpdater):\n        super().__init__(className='Free Move VR Desktop')\n        self.title('FreeMoveVR Desktop')\n        customtkinter.set_appearance_mode(save_manager.load_variable(save_manager.APPEARANCE_MODE_SAVEFILE) or 'Dark')\n        customtkinter.set_default_color_theme(get_static_data_path(os.path.join('themes', f\"{save_manager.load_variable(save_manager.COLOR_THEME_SAVEFILE) or 'Blue'}.json\")))\n        self.grid_columnconfigure(0, weight=1)\n        self.grid_rowconfigure(0, weight=1)\n        self.grid_columnconfigure(2, weight=4)\n        self.pose_detection: PoseDetection = pose_detection\n        self.tracker_manager: TrackerManager = tracker_manager\n        self.camera_manager: CameraManager = camera_manager\n        self.calibration: Calibration = calibration\n        self.interface_manager: InterfaceManager = interface_manager\n        self.feed_updater: FeedUpdater = feed_updater\n        self.settings_bar = SettingsBar(master=self, tracker_manager=self.tracker_manager, pose_detection=self.pose_detection, camera_manager=self.camera_manager, calibration=self.calib\n\n## Class TrackingMenu ##\n\nDocstring:\nMiscellaneous menu to toggle the visibility of the pose detection points and\ntoggle if the controllers should be used to check landmark accuracy in the driver.\n\nCode:\nclass TrackingMenu(customtkinter.CTkFrame):\n\n    def __init__(self, master: customtkinter.CTkScrollableFrame, pose_detection: PoseDetection, interface_manager: InterfaceManager) -> None:\n        super().__init__(master)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Tracking'\n        self.pose_detection: PoseDetection = pose_detection\n        self.interface_manager: InterfaceManager = interface_manager\n        self.interface_manager.active_interface.register_settings_update_callback(self._set_controller_check_state)\n        self.title = customtkinter.CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.visualization_checkbox = customtkinter.CTkCheckBox(self, text='Visualize Points', command=self.pose_detection.toggle_points)\n        self.visualization_checkbox.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        if self.pose_detection.display_points:\n            self.visualization_checkbox.select()\n        self.controller_check_checkbox = customtkinter.CTkCheckBox(self, text='Use Controllers to\\nImprove Accuracy', command=self._save_con\n\n## Class DelegateMenu ##\n\nDocstring:\nThe menu to change the pose detection to use the CPU or GPU.\n\nCode:\nclass DelegateMenu(CTkFrame):\n\n    def __init__(self, parent: CTkToplevel) -> None:\n        super().__init__(parent)\n        self.grid_columnconfigure(0, weight=1)\n        self.title_text = 'Set Delegate'\n        self.title = CTkLabel(self, text=self.title_text, fg_color=('gray70', 'gray30'))\n        self.tooltip_title = CTkToolTip(self.title, message='Set where the pose detection model should be run.')\n        self.title.grid(row=0, column=0, padx=10, pady=(10, 0), sticky='ew')\n        self.variable = IntVar(value=save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or Delegate.CPU)\n        radiobutton = CTkRadioButton(self, text='CPU', value=Delegate.CPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.CPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        radiobutton.grid(row=1, column=0, padx=10, pady=(10, 0), sticky='w')\n        radiobutton = CTkRadioButton(self, text='GPU', value=Delegate.GPU, variable=self.variable, command=lambda: save_manager.save_variable(Delegate.GPU, save_manager.MODEL_DELEGATE_SAVEFILE))\n        if sys.platform == 'win32':\n            radiobutton.configure(state='disabled')\n        radiobutton.grid(row=2, column=0, padx=10, pady=(10, 0), sticky='w')\n        if sys.platform == 'win32':\n            self.windows",
        "output": "Based on the provided code snippets, it appears that you can set the active trackers on the desktop through the `SettingsBar` class. This class is used to create a settings bar for the application, which includes a menu for selecting active trackers.\n\nThe `SettingsBar` class has a method called `_set_active_trackers`, which is responsible for setting the active trackers based on user input. This method is called when the user selects a tracker from the menu.\n\nHere is the relevant code snippet:\n```python\nclass SettingsBar(CTkFrame):\n    # ...\n    def _set_active_trackers(self, event=None):\n        self.active_tracker = self.tracker_menu.get_active()\n        self.interface_manager.active_interface.set_active_tracker(self.active_tracker)\n```\nIn this code, `self.active_tracker` is set to the selected tracker from the menu, and then the `set_active_tracker` method of the `active_interface` object in the `interface_manager` is called with the selected tracker as an argument. This should update the active trackers on the desktop.\n\nSo, to answer your question, yes, you can set the active trackers on the desktop by selecting a tracker from the menu in the `SettingsBar` class."
    },
    {
        "question": "On desktop what suggestions does it make if you are not found during calibration?",
        "database_value": "desktop",
        "related_docs": "agebox_helper.OK_OPTION, **messagebox_helper.common_args)\n        if result.get() == messagebox_helper.OK_OPTION:\n            root.after(_CALIBRATION_PREPARATION_DURATION, self.start_calibration)\n            root.after(_CALIBRATION_PREPARATION_DURATION + _CALIBRATION_DURATION, lambda: self.end_calibration(root, interface))\n        else:\n            self.running = False\n\n    def start_calibration(self) -> None:\n        \"\"\"\n        Sets the calibration flag to True and plays a sound to indicate calibration has started.\n        \"\"\"\n        self.calibrating = True\n        audio_manager.play_sound(audio_manager.ACTIVATE_SOUND)\n\n    def end_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n        \"\"\"\n        Calculates the average pose from the calibration poses and sends it to the VR interface.\n\n        :param root: The root Tk instance.\n        :param interface: The BaseInterface instance.\n        \"\"\"\n        self.running = False\n        self.calibrating = False\n        if len(self.calibration_poses) < _MINIMUM_CALIBRATION_POSE_COUNT:\n            audio_manager.play_sound(audio_manager.FAILURE_SOUND)\n            result = CTkMessagebox(title='Calibration Failed', message='Calibration failed. No complete poses were able to be found. Please try again with \"Points\" enabled to find optimal conditions for FreeMove VR with your setup. \\n\\n Common issues in\n\n used for the next time you start VR.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n        self.calibration_poses = []\n        self._notify_calibration_success_observer()\n        audio_manager.play_sound(audio_manager.SUCCESS_SOUND)\n\n    def add_pose(self, pose: List[NormalizedLandmark]) -> None:\n        \"\"\"\n        Adds a pose to the calibration poses list if the pose is complete.\n\n        :param pose: The pose to add.\n        \"\"\"\n        if self.calibrating:\n            for pose_landmark in pose:\n                if pose_landmark.visibility < 0.5:\n                    return\n            self.calibration_poses.append(pose)\n\n    def register_calibration_success_callback(self, callback: Callable) -> None:\n        \"\"\"\n        Registers a callback to be called when the calibration is successful\n\n        :param callback: function to be called when the camera changes\n        \"\"\"\n        self._callback.append(callback)\n\n    def _notify_calibration_success_observer(self) -> None:\n        \"\"\"\n        Notifies the calibration success observer that calibration was successful\n        \"\"\"\n        for callback in self._callback:\n            callback()\n\n\n## Class Calibration ##\n\nDocstring:\nCalibrates the user's pose when prompted. Provides GUI for the user to calibrate their pose.\n\nCode:\nclass Calibration:\n\n    def __init__(self, camera_manager: CameraManager) -> None:\n        \"\"\"\n        Initializes a Calibration instance.\n        \"\"\"\n        self.camera_manager: CameraManager = camera_manager\n        self.running = False\n        self.calibrating = False\n        self.user_height: Optional[int] = save_manager.load_variable(save_manager.USER_HEIGHT_SAVEFILE)\n        self.calibration_poses: List[List[NormalizedLandmark]] = []\n        self._callback: List[Callable] = []\n\n    def prompt_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n        \"\"\"\n        Prompts the user to calibrate their pose.\n\n        :param root: The root Tk instance.\n        :param interface: The BaseInterface instance.\n        \"\"\"\n        if self.running:\n            return\n        self.running = True\n        result = CTkMessagebox(title='Calibrate Pose', message='Stand in the center of the camera facing forward with your full body in frame. Calibration will begin five seconds after \"Ok\" is pressed. If you are currently playing VR calibrate with your headset on, otherwise do not wear a headset. Calibration will end ten seconds after pressing \"Ok\". For best results, do not move and calibrate before entering VR.', option_1=mess\n\nclude: poor lighting, distance from camera, blending into background, and occlusion.', option_1=messagebox_helper.OK_OPTION, option_2=messagebox_helper.RETRY_OPTION, icon=messagebox_helper.CANCEL_ICON, **messagebox_helper.common_args)\n            if result.get() == messagebox_helper.RETRY_OPTION:\n                self.prompt_calibration(root, interface)\n            return\n        pose_average: List[NormalizedLandmark] = _calculate_pose_average(self.calibration_poses)\n        pose_standard_deviation = _calculate_pose_standard_deviation(self.calibration_poses)\n        camera_name: str = self.camera_manager.camera_enum.get_cameras()[self.camera_manager.active_camera_index]\n        calibration_file: str = camera_name + save_manager.CALIBRATED_POSE_SAVEFILE_SUFFIX\n        save_manager.save_variable(pose_average, calibration_file)\n        standard_deviation_file: str = camera_name + save_manager.STANDARD_DEVIATION_SAVEFILE_SUFFIX\n        save_manager.save_variable(pose_standard_deviation, standard_deviation_file)\n        try:\n            interface.send_calibration_data()\n            CTkMessagebox(title='Calibration Complete', message='Calibration complete. Your pose in VR has been calibrated.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n        except ValueError:\n            CTkMessagebox(title='Calibration Saved', message='Calibration saved, Your pose will be\n\ncurring_message.to_byte_array())\n\n    def send_settings(self) -> None:\n        \"\"\"\n        Sends the settings to the driver. If the driver is not connected, it will not send the settings\n        \"\"\"\n        settings_message: SettingsMessage = SettingsMessage(list(self.tracker_manager), self.camera_manager.image_capture)\n        self.write_data(settings_message.to_byte_array())\n\n    def send_calibration_data(self) -> None:\n        \"\"\"\n        Sends the calibration data of the pose and settings data to the driver\n\n        :raise ValueError: if there is no calibration data saved\n        \"\"\"\n        camera_name: str = self.camera_manager.camera_enum.get_cameras()[self.camera_manager.active_camera_index]\n        calibration_file: str = camera_name + save_manager.CALIBRATED_POSE_SAVEFILE_SUFFIX\n        calibrated_pose_result: Optional[list[NormalizedLandmark]] = save_manager.load_variable(calibration_file)\n        if calibrated_pose_result is None:\n            raise ValueError('calibration data not found')\n        standard_deviation_pose_file: str = camera_name + save_manager.STANDARD_DEVIATION_SAVEFILE_SUFFIX\n        standard_deviation_pose_result: Optional[list[NormalizedLandmark]] = save_manager.load_variable(standard_deviation_pose_file)\n        if standard_deviation_pose_result is None:\n            raise ValueError('standard deviation calibration data not found')\n        self.se",
        "output": "If you are not found during calibration on desktop, the code suggests that poor lighting, distance from camera, blending into background, and occlusion might be the cause. It also mentions that for best results, you should not move and calibrate before entering VR. However, it does not provide specific suggestions on how to resolve this issue."
    },
    {
        "question": "What happens when a new calibration message is received in the driver?",
        "database_value": "driver",
        "related_docs": "t recent settings message was received so the\n        /// manager knows when a new settings message arrives and the driver should be updated.\n        std::chrono::high_resolution_clock::time_point lastSettingsMessageTimestamp{};\n\n        /**\n         * @brief Creates a new connection manager, by first opening a new connection of each type.\n         */\n        ConnectionManager();\n\n        /**\n         * @brief Destroy the Connection Manager object. Shuts down all connection threads.\n         */\n        ~ConnectionManager();\n\n        void initialize();\n\n        /**\n         * @brief Shuts down all connection threads.\n         */\n        void shutdown();\n\n        /**\n         * @brief Checks active and listening connections to see if any should be shut down. If so, attempts to open a new connection.\n         */\n        void checkShutdownRequests();\n\n        /**\n         * @brief Checks all listening connections to find if any have connected to a device and\n         * should be moved to the active vector. If so, a new connection is also made.\n         */\n        void checkNewActiveConnections();\n\n        /**\n         * @brief For every connection, orders the status of the connected device's battery in order of which devices\n         * are plugged in and then by percent.\n         *\n         * @return std::vector<BatteryState> The ordered vector of the connected device's battery sta\n\n/**\n * @file SettingsMessage.hpp\n * @author William Parker\n * @brief Computes the settings values from a binary settings message sent by a device.\n * To be used to update the driver and send updated settings to other devices.\n * @date 2024-02-12\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include <vector>\n#include <unordered_map>\n#include <span>\n\n#include \"../../TrackerRole.hpp\"\n#include \"../ConnectionConstants.hpp\"\n#include \"MessageBase.hpp\"\n#include \"CommonSettings.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Computes the settings values from a binary settings message sent by a device.\n     * To be used to update the driver and send updated settings to other devices.\n     */\n    class SettingsMessage : public MessageBase\n    {\n    public:\n        /// @brief Flag to tell the driver that the following data is in settings message\n        /// format and to update the pose calibration and every other connection.\n        static constexpr uint_fast8_t settingsMessageFlag{0b00100000};\n\n        /**\n         * @brief Default constructor for Settings Message. Only meant to be used to used when a\n         * connection is created and no settings message has been sent with real data yet.\n         */\n        SettingsMessage();\n\n        /**\n         * @brief When the ConnectionBase receives a message with it's options byte containing `settingsMessageFlag`,\n        \n\n   * @param rotationOffset the rotation the connection has to base the new calibration values from.\n         *\n         * @return bool if the driver rotation could be updated\n         */\n        bool updateDriverRotation(const CameraRotation &rotationOffset);\n\n        /**\n         * @brief Adds a tracker to emulatedTrackers.\n         *\n         * @param tracker The tracker to add.\n         */\n        void addEmulatedTracker(const std::shared_ptr<TrackerDevice> &tracker);\n        /**\n         * @brief Adds a tracker to driverTrackers. Should only be called on startup.\n         *\n         * @param tracker The tracker to add.\n         */\n        void addDriverTracker(const std::shared_ptr<TrackerDevice> &tracker);\n\n        /**\n         * @brief Removes all trackers of type specified from emulatedTrackers.\n         *\n         * @param tracker The tracker to remove.\n         */\n        void removeEmulatedTracker(const TrackerRole &trackerRole);\n\n        /**\n         * @brief Gets emulated trackers.\n         *\n         * @return std::vector<std::shared_ptr<TrackerDevice>> The emulated trackers.\n         */\n        std::map<TrackerRole, std::shared_ptr<TrackerDevice>> getEmulatedTrackers();\n\n        /**\n         * @brief If tracker does not exist when enabled is true, add the emulated tracker. If it does exist and enabled is false, erase the tracker.\n         *\n         * @param track\n\n/**\n * @file PoseMessage.hpp\n * @author William Parker\n * @brief The representation of a byte message that has data on the current\n * pose of the user or the average pose sent after calibration.\n * The message contains three landmarks which each\n * contain dimensional location and perception data.\n * @date 2024-02-15\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include \"LandmarkMessage.hpp\"\n#include \"Fragments/PoseFragment.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief The representation of a byte message that has data on the current\n     * pose of the user or the calibration pose. The message contains three landmarks\n     * which each contain pose and perception data.\n     */\n    class PoseMessage : public LandmarkMessage\n    {\n    public:\n        /// @brief The flag in the header of the landmark message to\n        /// represent that the landmark message is an average\n        /// value to be used for calibrating the pose in the driver.\n        static constexpr uint_fast8_t averagePoseMessageFlag{0b00001000};\n\n        /**\n         * @brief Converts the message into landmarks to use in a pose.\n         *\n         * @param messageBytes A `std::vector` of `uint_fast8_t`s representing the binary message.\n         * @throws `std::invalid_argument` if `messageBytes`'s length is not 20.\n         */\n        PoseMessage(const std::vector<uint_fast8_t> &messageByt\n\n/**\n * @file RecurringMessage.hpp\n * @author William Parker\n * @brief Computes a binary recurring message into an object.\n * `ConnectionBase::shouldShutdown()` Used to check if the connection is still alive\n * and it is also used to update device battery.\n * @date 2024-02-12\n *\n * @copyright Copyright (c) 2024\n *\n */\n\n#pragma once\n\n#include <chrono>\n\n#include \"MessageBase.hpp\"\n#include \"BatteryState.hpp\"\n\nnamespace FreeMoveVRDriver\n{\n    /**\n     * @brief Computes a binary recurring message into an object.\n     * `ConnectionBase::shouldShutdown()` Used to check if the connection is still alive\n     * and it is also used to update device battery.\n     */\n    class RecurringMessage : public MessageBase\n    {\n    public:\n        /// @brief Flag in the options byte to explicitly show the driver that the is is a recurring message,\n        /// meaning that device is still operational and can potentially send pose data to the driver.\n        static constexpr uint_fast8_t recurringMessageFlag{0b01000000};\n\n        /**\n         * @brief The constructor to be used if a Recurring Message has not yet come in yet from the device.\n         * timestamp is set to max() so the timeout function will not active before a connection is made.\n         */\n        RecurringMessage();\n\n        /**\n         * @brief The constructor to be used when a connection is activated. The connection should update ",
        "output": "When a new calibration message is received in the driver, the `SettingsMessage` class is responsible for processing this message. The `updateDriverRotation` function in this class takes the rotation offset from the message and updates the driver's rotation if possible. This function returns a boolean value indicating whether the driver rotation could be updated or not.\n\nHere is the relevant code snippet:\n\n```cpp\nbool updateDriverRotation(const CameraRotation &rotationOffset);\n```\n\nThis function is called when a new calibration message is received, and it updates the driver's rotation based on the rotation offset provided in the message. The function returns `true` if the driver's rotation could be updated, and `false` otherwise."
    },
    {
        "question": "What happens when a new calibration message is received on mobile?",
        "database_value": "mobile",
        "related_docs": "      BluetoothNotificationHandler.sendNotification(\n          landmarkMessage.toByteArray(),\n        );\n      }\n      for (final StatisticalMessage statisticalMessage in statisticalMessages) {\n        BluetoothNotificationHandler.sendNotification(\n          statisticalMessage.toByteArray(),\n        );\n      }\n\n      // Calculations have been completed, saved, and sent to the driver,\n      // so notify that everything was successful.\n      NotificationUI.playSuccessSound();\n      CalibrationUI.displayCalibrationSuccessNotification();\n    } catch (_) {\n      // Something went wrong with the calibration\n      NotificationUI.playFailureSound();\n      CalibrationUI.displayCalibrationFailNotification();\n    }\n  }\n\n  /// Adds the [pose] to the [calibrationPoses] [List] if it is valid\n  static void storeCalibrationData(Pose pose) {\n    if (_posePointAccuracyCheck(pose)) {\n      calibrationPoses.add(pose);\n    }\n  }\n\n  /// Returns true if every landmark in the [pose]\n  /// is accurate enough to be used for calibration\n  static bool _posePointAccuracyCheck(Pose pose) {\n    for (final value in pose.landmarks.values) {\n      if (value.presence < 0.7) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  /// Saves the [message]s as a single string to SharedPreferences at [saveFile]\n  static Future<void> _saveLandmarkPose(\n    List<LandmarkMessageBase> messages,\n    String saveFile,\n\n// Package imports:\nimport 'package:google_mediapipe_pose_detection/google_mediapipe_pose_detection.dart';\n\n// Project imports:\nimport 'package:free_move_vr/messages/landmark_message_base.dart';\nimport 'package:free_move_vr/messages/message_helper.dart';\nimport 'package:free_move_vr/messages/statistical_message_fragment.dart';\n\n/// A message representing the the variance for each dimension\n/// of a landmark during calibration.\n/// Should not be created directly,\n/// only through StatisticalMessage.generateMessages(...)\nclass StatisticalMessage extends LandmarkMessageBase {\n  StatisticalMessage({\n    required int messageNumber,\n    required List<PoseLandmark> landmarks,\n  }) : super(\n          messageNumber,\n          landmarks,\n          [statisticalMessageFlag],\n          openVrMinDelay,\n        );\n\n  /// Converts the data of the message to it's binary form.\n  ///\n  /// Returns the final message bytes that are represented as a list of ints\n  /// between 0-255 that are to be sent to the driver.\n  @override\n  List<int> toByteArray() {\n    return super.baseToByteArray(\n      (poseLandmark) => StatisticalMessageFragment(poseLandmark),\n    );\n  }\n\n  /// Generates a list of [StatisticalMessage]s\n  /// that make up a single calibration pose.\n  /// Always use this method to create messages from a calibration pose.\n  static List<StatisticalMessage> generateMessages({\n    required List<\n\nf the camera \"\n              \"needs to be rotated or moved from the place calibration was \"\n              \"done, calibration should be done again. Make sure to also set \"\n              \"your height in centimeters in the options menu.\",\n          image: const Icon(\n            Icons.settings_accessibility,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Permissions\",\n          bodyWidget: Align(\n            alignment: Alignment.centerLeft,\n            child: displayPermissions(),\n          ),\n          image: const Icon(\n            Icons.https,\n            color: Colors.black,\n            size: 175,\n          ),\n          footer: Platform.isAndroid\n              ? Padding(\n                  padding: const EdgeInsets.symmetric(horizontal: 100.0),\n                  child: ElevatedButton(\n                    onPressed: () {\n                      Future(() => Global.perms.request());\n                    },\n                    style: ElevatedButton.styleFrom(\n                      backgroundColor: Colors.lightBlue,\n                      shape: RoundedRectangleBorder(\n                        borderRadius: BorderRadius.circular(8.0),\n                      ),\n                    \n\n BluetoothHelper.centralDevice = device;\n        AdvertisingHandler.stop(AdvertisingHandler.advertisings.first);\n\n        BluetoothSettingsUpdateHandler.notifySettings();\n\n        // If calibration data exists, send it to the driver\n        if (prefs.containsKey(Global.averageLandmarkMessageSave) &&\n            prefs.containsKey(Global.statisticalMessageSave)) {\n          BluetoothNotificationHandler.sendCalibrationData(\n            prefs.getStringList(Global.averageLandmarkMessageSave)!,\n          );\n\n          BluetoothNotificationHandler.sendCalibrationData(\n            prefs.getStringList(Global.statisticalMessageSave)!,\n          );\n        }\n\n        bluetoothButtonProvider.bluetoothState = BluetoothState.connected;\n        BluetoothUI.displayDeviceConnectedNotification();\n        NotificationUI.playSuccessSound();\n      } else {\n        BluetoothHelper.centralDevice = null;\n        if (BluetoothHelper.disconnectingRequestSent) {\n          BluetoothHelper.disconnectingRequestSent = false;\n          BluetoothHelper.gattService?.inactivate();\n\n          BluetoothUI.displayBluetoothDisabledWhileConnectedNotification();\n\n          bluetoothButtonProvider.bluetoothState = BluetoothState.disabled;\n        } else {\n          BluetoothUI.displayBluetoothReconnectingNotification();\n          NotificationUI.playFailureSound();\n          BluetoothAdvertisingSetupHandler.createAdvert\n\n// Dart imports:\nimport 'dart:async';\n\n// Package imports:\nimport 'package:google_mediapipe_pose_detection/google_mediapipe_pose_detection.dart';\nimport 'package:shared_preferences/shared_preferences.dart';\n\n// Project imports:\nimport 'package:free_move_vr/bluetooth/bluetooth_notification_handler.dart';\nimport 'package:free_move_vr/calibration/average_pose_generator.dart';\nimport 'package:free_move_vr/calibration/calibration_helper.dart';\nimport 'package:free_move_vr/calibration/calibration_ui.dart';\nimport 'package:free_move_vr/calibration/statistical_pose_generator.dart';\nimport 'package:free_move_vr/global.dart';\nimport 'package:free_move_vr/messages/landmark_message_base.dart';\nimport 'package:free_move_vr/messages/pose_message.dart';\nimport 'package:free_move_vr/messages/statistical_message.dart';\nimport 'package:free_move_vr/notification_ui.dart';\n\n/// Calibration is done by having the user stand still for five seconds.\n/// Once complete, we will calculate the average location and\n/// standard deviation of each landmark. If calibration is successful,\n/// send the data to the driver over Bluetooth.\nclass Calibration {\n  /// True if the user is currently calibrating\n  static bool calibrationActive = false;\n\n  /// List of poses recorded during calibration\n  static List<Pose> calibrationPoses = [];\n\n  /// Starts the calibration process\n  static Future<void> runCalibration() a",
        "output": "When a new calibration message is received on mobile, the `BluetoothNotificationHandler.sendCalibrationData()` function is called with the list of messages as an argument. This function is responsible for sending the calibration data to the driver over Bluetooth.\n\nHere's the relevant code snippet:\n```dart\nif (prefs.containsKey(Global.averageLandmarkMessageSave) &&\n    prefs.containsKey(Global.statisticalMessageSave)) {\n  BluetoothNotificationHandler.sendCalibrationData(\n    prefs.getStringList(Global.averageLandmarkMessageSave)!,\n  );\n\n  BluetoothNotificationHandler.sendCalibrationData(\n    prefs.getStringList(Global.statisticalMessageSave)!,\n  );\n}\n```\nIn this code, the `prefs` object is used to retrieve the calibration data from shared preferences, which are stored on the device. The `containsKey()` method is used to check if the calibration data exists in the shared preferences before attempting to send it over Bluetooth. If the calibration data exists, it is retrieved using the `getStringList()` method and passed to the `sendCalibrationData()` function.\n\nThe `sendCalibrationData()` function is responsible for sending the calibration data to the driver over Bluetooth. However, the implementation of this function is not provided in the code snippet you provided. Therefore, I cannot provide more details on what happens when a new calibration message is received on mobile."
    }
]