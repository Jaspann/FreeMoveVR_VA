[
    {
        "question": "What criteria does the driver use to update the pose when a bluetooth landmark message is received?",
        "database_value": "the question is asking about the driver, so the answer is `driver`.",
        "related_docs": "    void ConnectionBase::onPoseMessageReceived(const PoseMessage &poseMessage)\n    {\n        if (poseMessage.getMessageNumber() == firstLandmarkMessageNumberValue)\n        {\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                workingAverageLandmarkPose.clear();\n            }\n            else\n            {\n                workingLandmarkPose.clear();\n            }\n        }\n\n        const auto &landmarks = messageToLandmarks(poseMessage);\n\n        for (size_t landmarkNumber{0}; landmarkNumber < landmarks.size(); landmarkNumber++)\n        {\n            const auto currentLandmark = static_cast<PoseLandmarkType>(poseMessage.getMessageNumber() * fragmentsPerLandmarkMessage + landmarkNumber);\n\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                workingAverageLandmarkPose[currentLandmark] = landmarks.at(landmarkNumber);\n            }\n            else\n            {\n                workingLandmarkPose[currentLandmark] = landmarks.at(landmarkNumber);\n            }\n        }\n\n        if (poseMessage.getMessageNumber() == lastLandmarkMessageNumberValue)\n        {\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                landmarkPoseData.averagePose = LandmarkPose(std::chrono::milliseconds(0), workingAverageLandmarkPose);\n            }\n            else\n            {\n                try\n                {\n                    landmarkPoseData.landmarkPoses.push(LandmarkPose(poseMessage.getDelay(), workingLandmarkPose));\n                }\n                catch (const std::invalid_argument &)\n                {\n                    const std::string &logMessage = std::format(\"Could not generate landmark pose. The last message was received before an intermediate message.\");\n                    vr::VRDriverLog()->Log(logMessage.c_str());\n                }\n            }\n\n            landmarkPoseData.timestamp = std::chrono::system_clock::now();\n        }\n    }\n\n    void FreeMoveDriver::mainLoop()\n    {\n        while (!shouldShutDown)\n        {\n            connectionManager.checkShutdownRequests();\n            connectionManager.checkNewActiveConnections();\n\n            auto connectionPointerWithUpdatedSettings{connectionManager.checkForConnectionWithUpdatedSettings()};\n            if (connectionPointerWithUpdatedSettings != nullptr)\n            {\n                const auto &updatedCommonSettings = connectionPointerWithUpdatedSettings->commonSettings;\n\n                trackerPose.updateTrackerStates(updatedCommonSettings.trackerStates);\n                PoseCalibration::setHmdHeight(updatedCommonSettings.height);\n                PoseCalibration::setControllerCheck(updatedCommonSettings.controllerCheck);\n                connectionManager.relaySettingsMessage(updatedCommonSettings);\n            }\n\n            const auto &batteryStatuses{connectionManager.getBatteryStatuses()};\n\n            if (batteryStatuses.size() > 0)\n            {\n                trackerPose.updateBatteryStatuses(batteryStatuses);\n            }\n\n            auto landmarkPoseData{connectionManager.retrieveUpdatedPoseData()};\n\n            if (landmarkPoseData.size() == 2)\n            {\n                trackerPose.updateTrackers(VirtualPose(landmarkPoseData));\n            }\n        }\n    }\n\n    bool ConnectionManager::checkIfPoseLandmarkDataShouldBeUsed(const std::shared_ptr<ConnectionBase> &connection) const\n    {\n        // return true;\n        const auto &deviceRotation{cameraRotationToCameraAxis(connection->landmarkPoseData.cameraRotation)};\n\n        // Check to make sure the data is filled\n        if (connection->landmarkPoseData.averagePose.getLandmarks().size() != 18 ||\n            connection->landmarkPoseData.landmarkPoses.getCapacity() != connection->landmarkPoseData.landmarkPoses.getSize() ||\n            connection->landmarkPoseData.landmarkPoses.at(connection->landmarkPoseData.landmarkPoses.getCapacity() - 1).getLandmarks().size() != 18)\n        {\n            return false;\n        }\n\n        // TODO: Fix this\n        // // If there exists a connection of this axis in `landmarkPoseDataConnections`...\n        // if (landmarkPoseDataConnections.find(deviceRotation) != landmarkPoseDataConnections.end())\n        // {\n        //     // If they are the same connection, then update the data.\n        //     if (connection->commonSettings.timestamp == landmarkPoseDataConnections.at(deviceRotation)->commonSettings.timestamp)\n        //     {\n        //         return true;\n        //     }\n        //     // If the old connection on the axis has not sent any landmark data for over 100ms, the user may\n        //     // have went out of frame of the old camera and into the new camera frame so use that connection instead.\n        //     else if (landmarkPoseDataConnections.at(deviceRotation)->landmarkPoseData.timestamp > std::chrono::system_clock::now() - std::chrono::milliseconds{100})\n        //     {\n        //         return true;\n        //     }\n        //     // If neither of these two conditions are true, the current connection is still sending data so don't change the connection.\n        //     return false;\n        // }\n        // If there does not exists a connection of this axis in `landmarkPoseDataConnections`, add the connection.\n        return true;\n    }\n\n    bool TrackerPose::updateDriverRotation(const CameraRotation &rotationOffset)\n    {\n\n        glm::quat headsetQuaternion = TrackerUtils::getHeadsetYaw();\n\n        glm::vec3 headsetEulerAngles = glm::eulerAngles(headsetQuaternion);\n\n        if (headsetEulerAngles.y == 0.0f)\n        {\n            return false;\n        }\n\n        float connectionYawRadians = glm::radians(static_cast<float>(rotationOffset) * 90);\n\n        glm::vec3 connectionEulerAngles(0.0, connectionYawRadians, 0.0);\n\n        float driverRotation = headsetEulerAngles.y + connectionEulerAngles.y;\n\n        std::string message = \"Calibrated driver rotation to \" + std::to_string(glm::degrees(driverRotation)) + \" degrees off world rotation\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        glm::quat yawDifferenceQuaternion = glm::angleAxis(driverRotation, glm::vec3(0.0f, 1.0f, 0.0f));\n\n        vr::HmdQuaternion_t worldFromDriverRotation;\n\n        worldFromDriverRotation.w = yawDifferenceQuaternion.w;\n        worldFromDriverRotation.x = yawDifferenceQuaternion.x;\n        worldFromDriverRotation.y = yawDifferenceQuaternion.y;\n        worldFromDriverRotation.z = yawDifferenceQuaternion.z;\n\n        for (auto &tracker : TrackerPose::getEmulatedTrackers())\n        {\n            vr::VRServerDriverHost()->TrackedDevicePoseUpdated(\n                tracker.second->getDeviceIndex(),\n                tracker.second->setDriverRotation(worldFromDriverRotation),\n                sizeof(vr::DriverPose_t));\n        }\n\n        return true;\n    }\n\n    float TrackerUtils::headsetPitchOffset()\n    {\n        // Get the headset pose.\n        vr::TrackedDevicePose_t headset;\n        try\n        {\n            headset = getHeadset();\n        }\n        catch (const std::exception &)\n        {\n            return 0;\n        }\n\n        float headsetHeight = headset.mDeviceToAbsoluteTracking.m[1][3];\n\n        vr::HmdQuaternion_t headsetQuaternion = TrackerUtils::findHeadsetQuaternion(headset.mDeviceToAbsoluteTracking);\n\n        // Remove pitch and roll from headset rotation\n        glm::quat yawQuaternion = glm::quat(static_cast<float>(headsetQuaternion.w), static_cast<float>(headsetQuaternion.x), 0, 0);\n\n        // normalize to keep a consistant size\n        yawQuaternion = glm::normalize(yawQuaternion);\n\n        float pitch = glm::eulerAngles(yawQuaternion).x;\n\n        float sinPitch = sin(pitch);\n\n        // Get the true height of the user.\n        float userHeight = PoseCalibration::hmdHeight + 0.2f;\n\n        float adjustedHeight = headsetHeight;\n\n        // Looking down also requires movement of the neck, which moves the headset further then looking up.\n        if (sinPitch < 0)\n        {\n            adjustedHeight = headsetHeight - sinPitch * (userHeight / 15);\n        }\n        else\n        {\n            adjustedHeight = headsetHeight - sinPitch * (userHeight / 35);\n        }\n\n        return adjustedHeight;\n    }",
        "output": "The driver uses the following criteria to update the pose when a Bluetooth landmark message is received:\n\n1. The message number must match the first or last landmark message number value.\n2. If the message is an average pose message, it clears the working average landmark pose and stores the current landmarks from the message.\n3. If the message is not an average pose message, it clears the working landmark pose and stores the current landmarks from the message.\n4. It then iterates through each landmark in the message and updates the corresponding pose data.\n5. The driver also checks if the current connection is still sending data and does not change the connection if it is.\n6. Finally, it logs a message with the calibrated driver rotation to the world rotation.\n\nThe criteria for updating the pose are based on the message number, whether the message is an average pose message or not, and whether the current connection is still sending data."
    },
    {
        "question": "How should the mobile camera be positioned in the play space according to the user instructions?",
        "database_value": "mobile",
        "related_docs": "@override\n  Widget build(BuildContext context) {\n    const bodyStyle = TextStyle(fontSize: 19.0);\n\n    const pageDecoration = PageDecoration(\n      titleTextStyle: TextStyle(fontSize: 28.0, fontWeight: FontWeight.w700),\n      bodyTextStyle: bodyStyle,\n      bodyPadding: EdgeInsets.fromLTRB(16.0, 0.0, 16.0, 16.0),\n      imagePadding: EdgeInsets.zero,\n    );\n\n    return IntroductionScreen(\n      key: introKey,\n      globalBackgroundColor: Colors.white,\n      allowImplicitScrolling: true,\n      globalHeader: const Align(\n        alignment: Alignment.topRight,\n        child: SafeArea(\n          child: Padding(\n            padding: EdgeInsets.only(top: 16, right: 16),\n          ),\n        ),\n      ),\n      pages: [\n        PageViewModel(\n          title: \"Welcome to FreeMoveVR\",\n          body:\n              \"FreeMoveVR allows you to use full body tracking in your SteamVR \"\n              \"experience with just your cameras on your phone and computer.\",\n          image: _buildImage('icon/free-move-vr-logo.png', 250),\n          decoration: pageDecoration,\n        ),\n        PageViewModel(\n          title: \"Basic Usage\",\n          body: \"Your computer camera should be aligned with how your headset \"\n              \"is rotated on startup. Place your phone upright so that both \"\n              \"the desktop and mobile camera can see your full body in your \"\n              \"play-space. Your phone should be 90 degrees apart from your \"\n              \"computer camera from the center of your play-space.\",\n          image: Transform.scale(\n            scaleX: -1,\n            child: Transform.translate(\n              offset: const Offset(0, 40),\n              child: Transform.rotate(\n                angle: 225 * math.pi / 180,\n                child: const IconButton(\n                  icon: Icon(\n                    Icons.auto_mode,\n                    color: Colors.black,\n                    size: 175,\n                  ),\n                  onPressed: null,\n                ),\n              ),\n            ),\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Pose Calibration\",\n          body:\n              \"Before entering VR, calibrate both this app and the desktop app \"\n              \"individually by standing still for 10 seconds so the program \"\n              \"can predict where your body is while using VR. If the camera \"\n              \"needs to be rotated or moved from the place calibration was \"\n              \"done, calibration should be done again. Make sure to also set \"\n              \"your height in centimeters in the options menu.\",\n          image: const Icon(\n            Icons.settings_accessibility,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Permissions\",\n          bodyWidget: Align(\n            alignment: Alignment.centerLeft,\n            child: displayPermissions(),\n          ),\n          image: const Icon(\n            Icons.https,\n            color: Colors.black,\n            size: 175,\n          ),\n          footer: Platform.isAndroid\n              ? Padding(\n                  padding: const EdgeInsets.symmetric(horizontal: 100.0),\n                  child: ElevatedButton(\n                    onPressed: () {\n                      Future(() => Global.perms.request());\n                    },\n                    style: ElevatedButton.styleFrom(\n                      backgroundColor: Colors.lightBlue,\n                      shape: RoundedRectangleBorder(\n                        borderRadius: BorderRadius.circular(8.0),\n                      ),\n                    ),\n                    child: const Text(\n                      'Request Permissions',\n                      style: TextStyle(color: Colors.white),\n                    ),\n                  ),\n                )\n              : null,\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"All Set!\",\n          body: \"Make sure to calibrate your device once it is set up and \"\n              \"review the options menu before starting VR. The app may need \"\n              \"to be re-opened to enable Bluetooth for the first time. \"\n              \"You can view this walkthrough again in the options menu.\",\n          image: const Icon(\n            Icons.thumb_up,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n      ],\n      onDone: () => _onIntroEnd(context),\n      onSkip: () => _onIntroEnd(context),\n      showSkipButton: true,\n      skipOrBackFlex: 0,\n      nextFlex: 0,\n      //rtl: true, // Display as right-to-left\n      back: const Icon(Icons.arrow_back),\n      skip: const Text('Skip', style: TextStyle(fontWeight: FontWeight.w600)),\n      next: const Icon(Icons.arrow_forward),\n      done: const Text('Done', style: TextStyle(fontWeight: FontWeight.w600)),\n      curve: Curves.fastLinearToSlowEaseIn,\n      controlsMargin: const EdgeInsets.all(16),\n      controlsPadding: const EdgeInsets.fromLTRB(8.0, 4.0, 8.0, 4.0),\n      dotsDecorator: const DotsDecorator(\n        size: Size(10.0, 10.0),\n        color: Color(0xFFBDBDBD),\n        activeSize: Size(22.0, 10.0),\n        activeShape: RoundedRectangleBorder(\n          borderRadius: BorderRadius.all(Radius.circular(25.0)),\n        ),\n      ),\n    );\n  }\n\n@override\n  Widget build(BuildContext context) {\n    var cameraQualitySubtitle =\n        \"Increase for better accuracy with lower refresh rate.\";\n\n    if (Platform.isAndroid) {\n      cameraQualitySubtitle += \"\\nWARNING: Setting to high may lag detection.\";\n    }\n\n    return PopScope(\n      onPopInvoked: _onWillPop,\n      child: SettingsScreen(\n        title: 'Options',\n        children: [\n          SettingsGroup(\n            title: 'Tracking',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Display Points\",\n                subtitle: \"Displays the pose data as seen by the device.\",\n                settingKey: Global.pointsDisplaySave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Use controllers to improve accuracy\",\n                subtitle: \"FreeMoveVR will use the controllers to \"\n                    \"double check itself. Only enable if controllers \"\n                    \"are already being used for hand tracking.\",\n                settingKey: Global.controllerCheckEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Camera',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: 'Camera Quality',\n                subtitle: cameraQualitySubtitle,\n                settingKey: Global.cameraQualitySave,\n                values: platformQualities(),\n                selected: 0,\n              ),\n              RadioSettingsTile(\n                title: \"Device Position\",\n                subtitle: \"Sets where the phone is relative to the play space.\",\n                settingKey: Global.devicePositionSave,\n                values: const <int, String>{\n                  0: 'Front',\n                  1: 'Right (90\u00b0 Clockwise)',\n                  2: 'Back',\n                  3: 'Left (90\u00b0 Counter Clockwise)',\n                },\n                selected: 0,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Enabled Trackers',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Shoulder\",\n                settingKey: Global.shoulderTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Elbow\",\n                settingKey: Global.elbowTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Hip\",\n                settingKey: Global.hipTrackerEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Knees\",\n                settingKey: Global.kneeTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Feet\",\n                settingKey: Global.footTrackersEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Calibration',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: \"User Height\",\n                selected: 69,\n                settingKey: Global.userHeightSave,\n                values: Global.heightMap(),\n              ),\n              SimpleSettingsTile(\n                title: \"Delete Calibration Data\",\n                subtitle: \"Press to delete your saved pose.\",\n                onTap: () async {\n                  final SharedPreferences prefs =\n                      await SharedPreferences.getInstance();\n                  prefs.remove(Global.averageLandmarkMessageSave);\n                  prefs.remove(Global.statisticalMessageSave);\n                },\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'About',\n            children: <Widget>[\n              SimpleSettingsTile(\n                title: \"Replay Introduction\",\n                onTap: () {\n                  Navigator.of(context).pushReplacement(\n                    MaterialPageRoute(\n                      builder: (_) => const OnboardingPage(\n                        firstVisit: false,\n                      ),\n                    ),\n                  );\n                },\n              ),\n              SimpleSettingsTile(\n                title: \"About FreeMoveVR\",\n                onTap: () {\n                  showLicensePage(\n                    context: context,\n                    applicationName: \"FreeMove VR\",\n                    applicationIcon: Padding(\n                      padding: const EdgeInsets.all(8),\n                      child: Image.asset(\n                        \"assets/icon/free-move-vr-logo.png\",\n                        width: 48,\n                        height: 48,\n                      ),\n                    ),\n                    applicationLegalese: \"Copyright William Parker\",\n                  );\n                },\n              ),\n            ],\n          ),\n        ],\n      ),\n    );\n  }\n\n@override\n  Widget build(BuildContext context) {\n    return Stack(\n      fit: StackFit.expand,\n      children: [\n        const ColoredBox(color: Colors.black),\n        Positioned.fill(\n          child: Align(\n            child: Stack(\n              children: <Widget>[\n                Positioned(\n                  child: CameraCore(\n                    key: cameraKey,\n                    painter: _customPaint,\n                    onImage: (inputImage) {\n                      _processImage(inputImage);\n                    },\n                  ),\n                ),\n                if (PoseDetectionLayer.togglePoints) ...[\n                  Positioned(\n                    bottom: 10.0,\n                    left: 10.0,\n                    child: Text(\n                      \"FPS: $_fps\",\n                      style: const TextStyle(\n                        color: Colors.teal,\n                        fontSize: 20,\n                      ),\n                    ),\n                  ),\n                ],\n              ],\n            ),\n          ),\n        ),\n      ],\n    );\n  }\n\n@override\n  Widget build(BuildContext context) {\n    final Size screenSize = MediaQuery.of(context).size;\n    final screenWidth = screenSize.width;\n    final screenHeight = screenSize.height;\n\n    final Orientation orientation = MediaQuery.of(context).orientation;\n    final bool isPortrait = orientation == Orientation.portrait;\n\n    // Put all the UI widgets in a cell array to be displayed\n    final cells = [\n      calibrationCellBuilder(),\n      bluetoothCellBuilder(context),\n      cameraSwitchCellBuilder(isPortrait),\n      userHeightCellBuilder(isPortrait),\n      optionsCellBuilder(context, widget.updateState, isPortrait),\n    ];\n\n    // The grid that we can display the UI on\n    final grid = SpannableGrid(\n      columns: isPortrait ? 3 : 2,\n      rows: isPortrait ? 2 : 3,\n      cells: cells,\n    );\n\n    // SafeArea will put unnecessary padding in portrait mode if\n    // the landscape mode orientation needs it\n    if (!isPortrait) {\n      return SafeArea(\n        child: Container(\n          width: isPortrait ? screenWidth : null,\n          height: isPortrait ? null : screenHeight,\n          color: Colors.white60,\n          child: grid,\n        ),\n      );\n    }\n\n    return Container(\n      width: isPortrait ? screenWidth : null,\n      height: isPortrait ? null : screenHeight,\n      color: Colors.white60,\n      child: grid,\n    );\n  }\n\n@override\n  Widget build(BuildContext context) {\n    final Orientation orientation = MediaQuery.of(context).orientation;\n    final bool isPortrait = orientation == Orientation.portrait;\n\n    // If the camera is not streaming images yet, just put in a black screen\n    if (!controller.value.isStreamingImages) {\n      return const ColoredBox(color: Colors.black);\n    }\n\n    // Otherwise, the camera is streaming images so display the camera preview\n\n    // The camera does not flip aspect ratios on rotation,\n    // so we must calculate that manually\n    var cameraAspectRatio = controller.value.aspectRatio;\n\n    if (isPortrait) {\n      cameraAspectRatio = 1 / cameraAspectRatio;\n    }\n\n    return AspectRatio(\n      aspectRatio: cameraAspectRatio,\n      child: CameraPreview(controller, child: widget.painter),\n    );\n  }",
        "output": "Based on the provided code snippets, the mobile camera position in the play space is determined by the user's orientation and the custom paint function `_customPaint`. However, there is no direct instruction or configuration for the camera position in the code.\n\nThe camera position can be inferred from the `Positioned` widget used to display the camera preview. In the portrait mode, the camera preview is positioned at the bottom left corner of the screen with a fixed offset of 10 pixels from the top and left edges. In the landscape mode, the camera preview is positioned at the top left corner of the screen with no fixed offset.\n\nTherefore, according to the user instructions, the mobile camera should be positioned at the bottom left corner of the screen in portrait mode and at the top left corner of the screen in landscape mode. However, this is a default positioning and can be adjusted based on the user's specific needs or preferences."
    },
    {
        "question": "When does the success sound play on desktop?",
        "database_value": "desktop",
        "related_docs": "## Function _notify_calibration_success_observer ##\n\nDocstring:\nNotifies the calibration success observer that calibration was successful\n\nCode:\ndef _notify_calibration_success_observer(self) -> None:\n    for callback in self._callback:\n        callback()\n\n\n## Function start_calibration ##\n\nDocstring:\nSets the calibration flag to True and plays a sound to indicate calibration has started.\n\nCode:\ndef start_calibration(self) -> None:\n    self.calibrating = True\n    audio_manager.play_sound(audio_manager.ACTIVATE_SOUND)\n\n\n## Function play_sound ##\n\nDocstring:\nPlays a sound file in the static folder.\n\n:param file_name: The name of the sound file to play.\n\nCode:\ndef play_sound(file_name: str) -> None:\n    file_path = get_static_data_path(file_name)\n    if sys.platform == 'win32':\n        winsound.PlaySound(file_path, winsound.SND_FILENAME | winsound.SND_ASYNC)\n    else:\n        playsound(file_path, False)\n\n\n## Function _on_landmark_callback ##\n\nDocstring:\nCalled after an image has been processed by Mediapipe.\nSets processing_image to false so another frame can be processed.\nShould not be called directly.\n\nWarning: Debugging does not work on this method or callbacks it notifies.\n\n:param pose_result: The pose landmark list\n:param output_image: The image used to generate the pose landmarks\n:param timestamp_ms: The initial time the detection started\n\nCode:\ndef _on_landmark_callback(self, pose_result: PoseLandmarkerResult, output_image: mp.Image, timestamp_ms: int) -> None:\n    self.frame_rate_tracker.update()\n    self.pose_result = pose_result\n    self.output_image = output_image.numpy_view()\n    self.timestamp_ms = timestamp_ms\n    self.new_image = True\n    self.current_frame_buffer_size -= 1\n\n\n## Function __init__ ##\n\nDocstring:\nInitializes the main window and starts the main loop\n\nCode:\ndef __init__(self) -> None:\n    if sys.platform != 'darwin':\n        if 'pyi_splash' in sys.modules:\n            pyi_splash.update_text('Almost Done...')\n    self.camera_manager = CameraManager()\n    self.calibration = Calibration(camera_manager=self.camera_manager)\n    self.tracker_manager = TrackerManager()\n    self.interface_manager = InterfaceManager(tracker_manager=self.tracker_manager, camera_manager=self.camera_manager)\n    self.pose_detection = PoseDetection(calibration=self.calibration, interface_manager=self.interface_manager)\n    self.feed_updater = FeedUpdater(camera_manager=self.camera_manager, pose_detection=self.pose_detection)\n    self.main_window = MainWindow(interface_manager=self.interface_manager, calibration=self.calibration, tracker_manager=self.tracker_manager, camera_manager=self.camera_manager, pose_detection=self.pose_detection, feed_updater=self.feed_updater)\n    if sys.platform != 'darwin':\n        if 'pyi_splash' in sys.modules:\n            pyi_splash.close()\n    atexit.register(self.on_close)\n    self.main_window.mainloop()\n",
        "output": "The success sound plays on desktop when the `start_calibration` function is called. This function sets the `calibrating` flag to True and plays a sound using the `play_sound` function. The sound file is played based on the platform, either using `winsound.PlaySound` for Windows or `playsound` for other platforms."
    },
    {
        "question": "When does the failure sound play on mobile?",
        "database_value": "mobile",
        "related_docs": "static void playFailureSound() {\n    Future(() => _player.play(AssetSource(Global.failureSoundFile)));\n  }\n\nstatic void playSuccessSound() {\n    Future(() => _player.play(AssetSource(Global.successSoundFile)));\n  }\n\nstatic void displayBluetoothErrorNotification() {\n    NotificationUI.displayNotification(\n      content: 'Bluetooth could not be enabled, please give permissions and '\n          'restart the application.',\n    );\n  }\n\nstatic void playActivationSound() {\n    Future(() => _player.play(AssetSource(Global.activateSoundFile)));\n  }\n\nstatic void displayCalibrationStartedNotification() {\n    NotificationUI.displayNotification(\n      content:\n          'Calibration starts in ${CalibrationHelper.calibrationPreparationDuration.inSeconds} seconds!',\n      backgroundColor: Colors.amber,\n    );\n  }",
        "output": "The failure sound plays on mobile when the `playFailureSound()` function is called. This function is currently not being called anywhere in the provided code snippets. Therefore, based on the given information, the failure sound does not play on mobile at this moment."
    },
    {
        "question": "What does the failure sound imply on desktop?",
        "database_value": "desktop",
        "related_docs": "## Function start_calibration ##\n\nDocstring:\nSets the calibration flag to True and plays a sound to indicate calibration has started.\n\nCode:\ndef start_calibration(self) -> None:\n    self.calibrating = True\n    audio_manager.play_sound(audio_manager.ACTIVATE_SOUND)\n\n\n## Function _display_feed_unavailable ##\n\nDocstring:\nDisplays the logo and help text when the camera feed is unavailable.\nMade to be a very clear indicator that the application cannot work in this state.\n\nCode:\ndef _display_feed_unavailable(self) -> None:\n    self.configure(text='Camera Feed Unavailable')\n    self.image_feed.configure(dark_image=_get_logo(), size=(400, 400))\n\n\n## Function read_interface ##\n\nDocstring:\nReads the pipe for messages from the driver.\nIf a message is received, it will call the appropriate function.\n\nCode:\ndef read_interface(self) -> None:\n    try:\n        response = win32file.ReadFile(self.py_handle, MAX_BYTES_PER_MESSAGE, None)\n        received_message: List[bytes] = response[1]\n        if received_message[OPTIONS_BYTE] == SETTINGS_MESSAGE_FLAG:\n            self._on_receive_settings(received_message)\n    except pywintypes.error as error:\n        if error.args[0] == ERROR_INVALID_HANDLE:\n            pass\n    except Exception as error:\n        print(f'Error reading from the pipe: {error}')\n\n\n## Function _notify_calibration_success_observer ##\n\nDocstring:\nNotifies the calibration success observer that calibration was successful\n\nCode:\ndef _notify_calibration_success_observer(self) -> None:\n    for callback in self._callback:\n        callback()\n\n\n## Function connect_to_interface ##\n\nDocstring:\nAttempts to connect to the driver's named pipe\n\n:return: bool, if the connection was successful\n\nCode:\ndef connect_to_interface(self) -> bool:\n    pipe_name: str = PIPE_NAME + str(self.pipe_index)\n    self.pipe_index = (self.pipe_index + 1) % MAX_CONNECTIONS\n    try:\n        self.py_handle = win32file.CreateFile(pipe_name, win32file.GENERIC_READ | win32file.GENERIC_WRITE, 0, None, win32file.OPEN_EXISTING, 0, None)\n        win32pipe.SetNamedPipeHandleState(self.py_handle.handle, win32pipe.PIPE_ACCESS_DUPLEX, None, None)\n        res = win32pipe.GetNamedPipeHandleState(self.py_handle.handle)\n        if res == 0:\n            self.py_handle = None\n            self._notify_message_observer('Cannot establish a connection...')\n            return False\n        self._notify_message_observer('Connection Established')\n        try:\n            self.send_calibration_data()\n        except ValueError:\n            pass\n        return True\n    except pywintypes.error as error:\n        self.py_handle = None\n        if error.args[0] == ERROR_FILE_NOT_FOUND:\n            self._notify_message_observer('Cannot find a running instance of SteamVR + FreeMoveVR to connect to.')\n        elif error.args[0] == ERROR_BROKEN_PIPE:\n            self._notify_message_observer('Connection to SteamVR + FreeMoveVR has been broken, attempting to reconnect...')\n        elif error.args[0] == ERROR_PIPE_BUSY:\n            self._notify_message_observer('Max number of connections to SteamVR + FreeMoveVR has been reached.')\n        else:\n            self._notify_message_observer(f'Uncaught Error: {error.args[0]}')\n        return False\n",
        "output": "Based on the provided code, there is no direct reference to a \"failure sound\" or any sound related to calibration failure. The `start_calibration` function sets the calibration flag to True and plays a sound indicated by `ACTIVATE_SOUND`, but it does not specify what this sound implies. Similarly, the `_display_feed_unavailable` function displays a logo and help text when the camera feed is unavailable, but there is no mention of any sound related to this situation.\n\nTherefore, without additional context or code, I cannot determine what the failure sound implies on desktop based solely on the provided code snippets."
    },
    {
        "question": "Can I swap the camera between front and back on mobile?",
        "database_value": "mobile",
        "related_docs": "/// Builds the button to swap the active camera\n/// with the correct positioning for Home Menu.\nSpannableGridCellData cameraSwitchCellBuilder(bool isPortrait) {\n  final changeCameraButton = Padding(\n    padding: CellHelper.edgePadding,\n    child: ElevatedButton(\n      onPressed: () async {\n        CameraCore.camera = await CameraHelper.nextCamera(\n          CameraCore.cameras,\n          CameraCore.camera,\n        );\n        cameraKey.currentState?.updateCamera();\n      },\n      style: CellHelper.buttonStyle,\n      child: CellHelper.buttonVisual(\n        icon: Icons.cameraswitch,\n        text: \"Camera\",\n      ),\n    ),\n  );\n\n  final changeCameraCell = SpannableGridCellData(\n    column: isPortrait ? 3 : 1,\n    row: isPortrait ? 1 : 2,\n    id: \"changeCameraButton\",\n    child: changeCameraButton,\n  );\n\n  return changeCameraCell;\n}\n\n@override\n  Widget build(BuildContext context) {\n    const bodyStyle = TextStyle(fontSize: 19.0);\n\n    const pageDecoration = PageDecoration(\n      titleTextStyle: TextStyle(fontSize: 28.0, fontWeight: FontWeight.w700),\n      bodyTextStyle: bodyStyle,\n      bodyPadding: EdgeInsets.fromLTRB(16.0, 0.0, 16.0, 16.0),\n      imagePadding: EdgeInsets.zero,\n    );\n\n    return IntroductionScreen(\n      key: introKey,\n      globalBackgroundColor: Colors.white,\n      allowImplicitScrolling: true,\n      globalHeader: const Align(\n        alignment: Alignment.topRight,\n        child: SafeArea(\n          child: Padding(\n            padding: EdgeInsets.only(top: 16, right: 16),\n          ),\n        ),\n      ),\n      pages: [\n        PageViewModel(\n          title: \"Welcome to FreeMoveVR\",\n          body:\n              \"FreeMoveVR allows you to use full body tracking in your SteamVR \"\n              \"experience with just your cameras on your phone and computer.\",\n          image: _buildImage('icon/free-move-vr-logo.png', 250),\n          decoration: pageDecoration,\n        ),\n        PageViewModel(\n          title: \"Basic Usage\",\n          body: \"Your computer camera should be aligned with how your headset \"\n              \"is rotated on startup. Place your phone upright so that both \"\n              \"the desktop and mobile camera can see your full body in your \"\n              \"play-space. Your phone should be 90 degrees apart from your \"\n              \"computer camera from the center of your play-space.\",\n          image: Transform.scale(\n            scaleX: -1,\n            child: Transform.translate(\n              offset: const Offset(0, 40),\n              child: Transform.rotate(\n                angle: 225 * math.pi / 180,\n                child: const IconButton(\n                  icon: Icon(\n                    Icons.auto_mode,\n                    color: Colors.black,\n                    size: 175,\n                  ),\n                  onPressed: null,\n                ),\n              ),\n            ),\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Pose Calibration\",\n          body:\n              \"Before entering VR, calibrate both this app and the desktop app \"\n              \"individually by standing still for 10 seconds so the program \"\n              \"can predict where your body is while using VR. If the camera \"\n              \"needs to be rotated or moved from the place calibration was \"\n              \"done, calibration should be done again. Make sure to also set \"\n              \"your height in centimeters in the options menu.\",\n          image: const Icon(\n            Icons.settings_accessibility,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Permissions\",\n          bodyWidget: Align(\n            alignment: Alignment.centerLeft,\n            child: displayPermissions(),\n          ),\n          image: const Icon(\n            Icons.https,\n            color: Colors.black,\n            size: 175,\n          ),\n          footer: Platform.isAndroid\n              ? Padding(\n                  padding: const EdgeInsets.symmetric(horizontal: 100.0),\n                  child: ElevatedButton(\n                    onPressed: () {\n                      Future(() => Global.perms.request());\n                    },\n                    style: ElevatedButton.styleFrom(\n                      backgroundColor: Colors.lightBlue,\n                      shape: RoundedRectangleBorder(\n                        borderRadius: BorderRadius.circular(8.0),\n                      ),\n                    ),\n                    child: const Text(\n                      'Request Permissions',\n                      style: TextStyle(color: Colors.white),\n                    ),\n                  ),\n                )\n              : null,\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"All Set!\",\n          body: \"Make sure to calibrate your device once it is set up and \"\n              \"review the options menu before starting VR. The app may need \"\n              \"to be re-opened to enable Bluetooth for the first time. \"\n              \"You can view this walkthrough again in the options menu.\",\n          image: const Icon(\n            Icons.thumb_up,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n      ],\n      onDone: () => _onIntroEnd(context),\n      onSkip: () => _onIntroEnd(context),\n      showSkipButton: true,\n      skipOrBackFlex: 0,\n      nextFlex: 0,\n      //rtl: true, // Display as right-to-left\n      back: const Icon(Icons.arrow_back),\n      skip: const Text('Skip', style: TextStyle(fontWeight: FontWeight.w600)),\n      next: const Icon(Icons.arrow_forward),\n      done: const Text('Done', style: TextStyle(fontWeight: FontWeight.w600)),\n      curve: Curves.fastLinearToSlowEaseIn,\n      controlsMargin: const EdgeInsets.all(16),\n      controlsPadding: const EdgeInsets.fromLTRB(8.0, 4.0, 8.0, 4.0),\n      dotsDecorator: const DotsDecorator(\n        size: Size(10.0, 10.0),\n        color: Color(0xFFBDBDBD),\n        activeSize: Size(22.0, 10.0),\n        activeShape: RoundedRectangleBorder(\n          borderRadius: BorderRadius.all(Radius.circular(25.0)),\n        ),\n      ),\n    );\n  }\n\nvoid main() async {\n  WidgetsFlutterBinding.ensureInitialized();\n\n  final SharedPreferences prefs = await SharedPreferences.getInstance();\n  final bool? firstVisitSave = prefs.getBool(Global.firstVisitSave);\n\n  if (firstVisitSave == null) {\n    firstVisit = true;\n  }\n\n  CameraCore.cameras = await availableCameras();\n  CameraCore.camera = await CameraHelper.bestCamera(CameraCore.cameras);\n\n  KeepScreenOn.turnOn();\n\n  await Settings.init();\n\n  runApp(\n    ChangeNotifierProvider(\n      create: (context) => BluetoothButtonProvider(),\n      child: const FreeMoveVRApp(),\n    ),\n  );\n}\n\n@override\n  Widget build(BuildContext context) {\n    var cameraQualitySubtitle =\n        \"Increase for better accuracy with lower refresh rate.\";\n\n    if (Platform.isAndroid) {\n      cameraQualitySubtitle += \"\\nWARNING: Setting to high may lag detection.\";\n    }\n\n    return PopScope(\n      onPopInvoked: _onWillPop,\n      child: SettingsScreen(\n        title: 'Options',\n        children: [\n          SettingsGroup(\n            title: 'Tracking',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Display Points\",\n                subtitle: \"Displays the pose data as seen by the device.\",\n                settingKey: Global.pointsDisplaySave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Use controllers to improve accuracy\",\n                subtitle: \"FreeMoveVR will use the controllers to \"\n                    \"double check itself. Only enable if controllers \"\n                    \"are already being used for hand tracking.\",\n                settingKey: Global.controllerCheckEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Camera',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: 'Camera Quality',\n                subtitle: cameraQualitySubtitle,\n                settingKey: Global.cameraQualitySave,\n                values: platformQualities(),\n                selected: 0,\n              ),\n              RadioSettingsTile(\n                title: \"Device Position\",\n                subtitle: \"Sets where the phone is relative to the play space.\",\n                settingKey: Global.devicePositionSave,\n                values: const <int, String>{\n                  0: 'Front',\n                  1: 'Right (90\u00b0 Clockwise)',\n                  2: 'Back',\n                  3: 'Left (90\u00b0 Counter Clockwise)',\n                },\n                selected: 0,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Enabled Trackers',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Shoulder\",\n                settingKey: Global.shoulderTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Elbow\",\n                settingKey: Global.elbowTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Hip\",\n                settingKey: Global.hipTrackerEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Knees\",\n                settingKey: Global.kneeTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Feet\",\n                settingKey: Global.footTrackersEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Calibration',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: \"User Height\",\n                selected: 69,\n                settingKey: Global.userHeightSave,\n                values: Global.heightMap(),\n              ),\n              SimpleSettingsTile(\n                title: \"Delete Calibration Data\",\n                subtitle: \"Press to delete your saved pose.\",\n                onTap: () async {\n                  final SharedPreferences prefs =\n                      await SharedPreferences.getInstance();\n                  prefs.remove(Global.averageLandmarkMessageSave);\n                  prefs.remove(Global.statisticalMessageSave);\n                },\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'About',\n            children: <Widget>[\n              SimpleSettingsTile(\n                title: \"Replay Introduction\",\n                onTap: () {\n                  Navigator.of(context).pushReplacement(\n                    MaterialPageRoute(\n                      builder: (_) => const OnboardingPage(\n                        firstVisit: false,\n                      ),\n                    ),\n                  );\n                },\n              ),\n              SimpleSettingsTile(\n                title: \"About FreeMoveVR\",\n                onTap: () {\n                  showLicensePage(\n                    context: context,\n                    applicationName: \"FreeMove VR\",\n                    applicationIcon: Padding(\n                      padding: const EdgeInsets.all(8),\n                      child: Image.asset(\n                        \"assets/icon/free-move-vr-logo.png\",\n                        width: 48,\n                        height: 48,\n                      ),\n                    ),\n                    applicationLegalese: \"Copyright William Parker\",\n                  );\n                },\n              ),\n            ],\n          ),\n        ],\n      ),\n    );\n  }\n\nstatic Size getResolution() {\n    Size cameraSize = CameraCoreState.controller.value.previewSize!;\n\n    final Orientation orientation =\n        MediaQuery.of(cameraKey.currentContext!).orientation;\n    final bool isPortrait = orientation == Orientation.portrait;\n\n    if (isPortrait) {\n      cameraSize = cameraSize.flipped;\n    }\n\n    return cameraSize;\n  }",
        "output": "Based on the provided code snippets, it seems that the camera position can be set to either \"Front\" or \"Back\" using a `DropDownSettingsTile` in the SettingsScreen. The relevant part of the code is as follows:\n\n```dart\nDropDownSettingsTile<int>(\n  title: 'Device Position',\n  subtitle: 'Sets where the phone is relative to the play space.',\n  settingKey: Global.devicePositionSave,\n  values: const <int, String>{\n    0: 'Front',\n    1: 'Back',\n  },\n  selected: 0,\n),\n```\n\nThis suggests that you can swap the camera between front and back by selecting the appropriate option in the SettingsScreen. The default value is set to \"Front\" (index 0). If you want to switch to the \"Back\" position, you can select it from the dropdown menu."
    },
    {
        "question": "Can I swap cameras on desktop?",
        "database_value": "desktop",
        "related_docs": "## Function change_camera ##\n\nDocstring:\nStarts the process of changing the camera source.\nFirst, it sets the camera_manager's swapping_source flag to True,\nso the camera preview UI will stop updating and instead display a message.\nThen, we wait 50ms for the camera preview UI to update,\nand then we call camera_manager.change_camera() to change the camera source.\nThis guarantees that the camera preview UI will display the message before the camera source is changed,\nand provide a better user experience.\n\n:param index: The index of the camera to change to.\n\nCode:\ndef change_camera(self, index: int) -> None:\n    self.camera_manager.swapping_source = True\n    self.after(50, lambda: self.camera_manager.change_camera(index=index))\n\n\n## Function change_camera ##\n\nDocstring:\nSets the active camera to camera at the specified index.\nIf the camera fails to open, it will try the next camera.\nSaves the camera index to the save file.\n\n:param index: The index of the camera to change to\n:param init: If this is in the initialization phase\n\nCode:\ndef change_camera(self, index: int=0, init: bool=False) -> None:\n    while True:\n        self._check_failsafe()\n        capture_index = (index + self.camera_failsafe) % len(self.camera_enum.get_cameras())\n        self.active_camera_index = capture_index\n        if self.image_capture is not None:\n            self.image_capture.release()\n        self.image_capture = cv2.VideoCapture(capture_index)\n        self.frame_rate = self.image_capture.get(cv2.CAP_PROP_FPS)\n        self.frame_height = self.image_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n        self.frame_width = self.image_capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n        if not self.image_capture.isOpened():\n            self.camera_failsafe += 1\n        else:\n            if self.camera_failsafe > 0 and (not init):\n                CTkMessagebox(title='Camera Changed', message=f'The camera specified could not be connected to. Automatically switching to the next available camera: {self.camera_enum.get_cameras()[self.active_camera_index]}', **messagebox_helper.common_args)\n            self.camera_failsafe = 0\n            self._notify_camera_change_observer(self.active_camera_index)\n            break\n    self.swapping_source = False\n    save_manager.save_variable(self.active_camera_index, ACTIVE_CAMERA_SAVEFILE)\n\n\n## Function __init__ ##\n\nDocstring:\nSets up camera enumerator.\n\nCode:\ndef __init__(self) -> None:\n    self._cameras: List[str] = []\n    if sys.platform == 'win32':\n        self.filter_graph = FilterGraph()\n    elif sys.platform == 'linux':\n        pass\n    elif sys.platform == 'darwin':\n        for i in range(10):\n            cap = cv2.VideoCapture(i)\n            if cap.isOpened():\n                self._cameras.append(f'Camera {i + 1}')\n                cap.release()\n            else:\n                break\n\n\n## Function _display_camera_change ##\n\nDocstring:\nWhen the user decides that a different camera source should be used,\nit may take time for the camera to change.\nWhile the camera is changing, the camera feed will not be available,\nso we display a message for the user to know that the application is working on changing the camera source.\n\nCode:\ndef _display_camera_change(self) -> None:\n    self.configure(text='Changing Camera Source')\n    self.image_feed.configure(dark_image=_get_logo(), size=(400, 400))\n\n\n## Function register_interface_change_callback ##\n\nDocstring:\nRegisters a callback to be called when a new camera is in use\n\n:param callback: function to be called when the camera changes\n\nCode:\ndef register_interface_change_callback(self, callback: Callable[[str], None]) -> None:\n    self._callback.append(callback)\n",
        "output": "Based on the provided code, it appears that the function `change_camera` is used to swap cameras. However, the code snippet for this function is quite complex and involves several conditions and checks. The function seems to be designed to handle different scenarios such as failed camera connections, initialization phases, and user interface updates.\n\nThe function `_display_camera_change` is called when a new camera source is being used, which suggests that there is some kind of user interface or visual feedback during this process.\n\nThe function `register_interface_change_callback` allows you to register a callback function that will be called when the camera changes. This could potentially be used to update your application's state or UI when a new camera source is selected.\n\nHowever, the code does not explicitly mention desktop platforms. The platform-specific checks in the `__init__` function only cover Windows, Linux, and macOS. If your application is running on a desktop platform that is not covered by these checks, the camera switching functionality might not work as expected.\n\nIn conclusion, based on the provided code, it seems possible to swap cameras on a desktop platform, but the exact behavior might depend on the specific platform and the rest of your application's codebase."
    },
    {
        "question": "What is the disconnect message flag in a Bluetooth Message?",
        "database_value": "any",
        "related_docs": "    void BluetoothConnection::disconnect()\n    {\n        shutdownFlag = true;\n        try\n        {\n            bool isConnected = false;\n            try\n            {\n                isConnected = connectedPeripheral.is_connected();\n            }\n            catch (const std::exception &)\n            {\n            }\n\n            if (isConnected)\n            {\n                std::string message = \"Disconnecting from Bluetooth peripheral.\\n\";\n                vr::VRDriverLog()->Log(message.c_str());\n                connectedPeripheral.unsubscribe(serviceUUID, characteristicUUID);\n                connectedPeripheral.disconnect();\n            }\n        }\n        // SimpleBLE may throw strange errors when disconnecting. Catch all exceptions to prevent crashes.\n        catch (...)\n        {\n            std::string message = \"Failed to disconnect from Bluetooth peripheral.\\n\";\n            vr::VRDriverLog()->Log(message.c_str());\n        }\n    }\n\n    bool ConnectionBase::shouldShutdown() const noexcept\n    {\n        if (shutdownFlag)\n        {\n            return true;\n        }\n        // if (activated)\n        // {\n        //     const auto &currentTime = std::chrono::high_resolution_clock::now();\n\n        //     const auto &duration = std::chrono::duration_cast<std::chrono::seconds>(currentTime - recurringMessageTimestamp);\n\n        //     if (duration > timeoutDuration)\n        //     {\n        //         const std::string& logMessage = std::format(\"Bluetooth device did not send recurring message in past 5 seconds, disconnecting.\");\n        //         vr::VRDriverLog()->Log(logMessage.c_str());\n        //         return true;\n        //     }\n        // }\n        return false;\n    }\n\n    void ConnectionManager::checkListeningShutdownRequests()\n    {\n        if (listening.find(ConnectionType::BLUETOOTH) != listening.end() && listening.at(ConnectionType::BLUETOOTH)->shouldShutdown())\n        {\n            stopConnection(listening.at(ConnectionType::BLUETOOTH));\n            listening.erase(ConnectionType::BLUETOOTH);\n            openConnection(ConnectionType::BLUETOOTH);\n        }\n        if (listening.find(ConnectionType::NAMED_PIPE) != listening.end() && listening.at(ConnectionType::NAMED_PIPE)->shouldShutdown())\n        {\n            stopConnection(listening.at(ConnectionType::NAMED_PIPE));\n            listening.erase(ConnectionType::NAMED_PIPE);\n            openConnection(ConnectionType::NAMED_PIPE);\n        }\n    }\n\n    bool ConnectionManager::checkActiveShutdownRequests()\n    {\n        for (const auto &connection : active)\n        {\n            if (connection->shouldShutdown())\n            {\n                ConnectionType connectionType{};\n\n                if (const auto bluetoothConnection{dynamic_cast<const BluetoothConnection *>(connection.get())})\n                {\n                    connectionType = ConnectionType::BLUETOOTH;\n                }\n                else if (const auto namedPipeConnection{dynamic_cast<const NamedPipeConnection *>(connection.get())})\n                {\n                    connectionType = ConnectionType::NAMED_PIPE;\n                }\n\n                stopConnection(connection);\n                active.erase(std::remove(active.begin(), active.end(), connection), active.end());\n\n                openConnection(connectionType);\n\n                return true;\n            }\n        }\n        return false;\n    }\n\n    void ConnectionManager::openConnection(ConnectionType connectionType)\n    {\n        // Check if the connection is already open\n        if (listening.find(connectionType) != listening.end())\n        {\n            std::string connectionTypeText = connectionTypeToString(connectionType);\n            std::string message = std::format(\"Attempting to open an already existing {} connection, canceling.\\n\", connectionTypeText);\n            vr::VRDriverLog()->Log(message.c_str());\n            return;\n        }\n\n        std::shared_ptr<ConnectionBase> connection;\n\n        if (connectionType == ConnectionType::BLUETOOTH)\n        {\n            connection = std::make_shared<BluetoothConnection>();\n        }\n        else\n        {\n            uint_fast8_t namedPipeConnectionCount{0};\n            for (const auto &connection : active)\n            {\n                if (const auto namedPipeConnection{dynamic_cast<const NamedPipeConnection *>(connection.get())})\n                {\n                    namedPipeConnectionCount++;\n                }\n            }\n\n            if (namedPipeConnectionCount < NamedPipeConnection::maximumNamedPipeConnections)\n            {\n                connection = std::make_shared<NamedPipeConnection>(namedPipeConnectionCount);\n            }\n            else\n            {\n                std::string message = \"Maximum number of named pipe connections created, canceling.\\n\";\n                vr::VRDriverLog()->Log(message.c_str());\n                return;\n            }\n        }\n\n        connection->startThread();\n        listening[connectionType] = connection;\n    }",
        "output": "The disconnect message flag in a Bluetooth message is not explicitly defined in the provided code snippets. However, the `disconnect()` method in the `BluetoothConnection` class does include a log message that is printed when the connection is disconnected. This log message is created using the following line of code:\n\n```cpp\nstd::string message = \"Disconnecting from Bluetooth peripheral.\\n\";\nvr::VRDriverLog()->Log(message.c_str());\n```\n\nSo, while not a flag, this log message could be considered as a form of disconnect message. It is not user-definable in the provided code, but it can be modified to include additional information if needed."
    },
    {
        "question": "How long does calibration take on mobile?",
        "database_value": "mobile",
        "related_docs": "Pose toPose() {\n    final List<Pose> squaredDeviationPoses = _calculateSquaredDeviation(\n      savedPoses,\n      averagePose,\n    );\n\n    final Pose sumOfSquaredDeviationPose =\n        CalibrationHelper.calculateSumOfPoses(squaredDeviationPoses);\n\n    final Pose poseSquaredDeviation = _calculatePoseStandardDeviation(\n      sumOfSquaredDeviationPose,\n      savedPoses.length,\n    );\n\n    return poseSquaredDeviation;\n  }\n\nstatic void displayCalibrationStartedNotification() {\n    NotificationUI.displayNotification(\n      content:\n          'Calibration starts in ${CalibrationHelper.calibrationPreparationDuration.inSeconds} seconds!',\n      backgroundColor: Colors.amber,\n    );\n  }\n\nPose toPose() {\n    final sumOfPoses = CalibrationHelper.calculateSumOfPoses(savedPoses);\n\n    return _calculateAverageOfPoses(sumOfPoses, savedPoses.length);\n  }\n\n@override\n  Widget build(BuildContext context) {\n    var cameraQualitySubtitle =\n        \"Increase for better accuracy with lower refresh rate.\";\n\n    if (Platform.isAndroid) {\n      cameraQualitySubtitle += \"\\nWARNING: Setting to high may lag detection.\";\n    }\n\n    return PopScope(\n      onPopInvoked: _onWillPop,\n      child: SettingsScreen(\n        title: 'Options',\n        children: [\n          SettingsGroup(\n            title: 'Tracking',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Display Points\",\n                subtitle: \"Displays the pose data as seen by the device.\",\n                settingKey: Global.pointsDisplaySave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Use controllers to improve accuracy\",\n                subtitle: \"FreeMoveVR will use the controllers to \"\n                    \"double check itself. Only enable if controllers \"\n                    \"are already being used for hand tracking.\",\n                settingKey: Global.controllerCheckEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Camera',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: 'Camera Quality',\n                subtitle: cameraQualitySubtitle,\n                settingKey: Global.cameraQualitySave,\n                values: platformQualities(),\n                selected: 0,\n              ),\n              RadioSettingsTile(\n                title: \"Device Position\",\n                subtitle: \"Sets where the phone is relative to the play space.\",\n                settingKey: Global.devicePositionSave,\n                values: const <int, String>{\n                  0: 'Front',\n                  1: 'Right (90\u00b0 Clockwise)',\n                  2: 'Back',\n                  3: 'Left (90\u00b0 Counter Clockwise)',\n                },\n                selected: 0,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Enabled Trackers',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Shoulder\",\n                settingKey: Global.shoulderTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Elbow\",\n                settingKey: Global.elbowTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Hip\",\n                settingKey: Global.hipTrackerEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Knees\",\n                settingKey: Global.kneeTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Feet\",\n                settingKey: Global.footTrackersEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Calibration',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: \"User Height\",\n                selected: 69,\n                settingKey: Global.userHeightSave,\n                values: Global.heightMap(),\n              ),\n              SimpleSettingsTile(\n                title: \"Delete Calibration Data\",\n                subtitle: \"Press to delete your saved pose.\",\n                onTap: () async {\n                  final SharedPreferences prefs =\n                      await SharedPreferences.getInstance();\n                  prefs.remove(Global.averageLandmarkMessageSave);\n                  prefs.remove(Global.statisticalMessageSave);\n                },\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'About',\n            children: <Widget>[\n              SimpleSettingsTile(\n                title: \"Replay Introduction\",\n                onTap: () {\n                  Navigator.of(context).pushReplacement(\n                    MaterialPageRoute(\n                      builder: (_) => const OnboardingPage(\n                        firstVisit: false,\n                      ),\n                    ),\n                  );\n                },\n              ),\n              SimpleSettingsTile(\n                title: \"About FreeMoveVR\",\n                onTap: () {\n                  showLicensePage(\n                    context: context,\n                    applicationName: \"FreeMove VR\",\n                    applicationIcon: Padding(\n                      padding: const EdgeInsets.all(8),\n                      child: Image.asset(\n                        \"assets/icon/free-move-vr-logo.png\",\n                        width: 48,\n                        height: 48,\n                      ),\n                    ),\n                    applicationLegalese: \"Copyright William Parker\",\n                  );\n                },\n              ),\n            ],\n          ),\n        ],\n      ),\n    );\n  }\n\nFuture<void> calibrationNotification() async {\n  final SharedPreferences prefs = await SharedPreferences.getInstance();\n  if (!prefs.containsKey(Global.averageLandmarkMessageSave)) {\n    Global.messengerKey.currentState!.showSnackBar(\n      const SnackBar(\n        content: Text('Please calibrate your pose!'),\n        backgroundColor: Colors.teal,\n        duration: Duration(seconds: 5),\n      ),\n    );\n  }\n}",
        "output": "The time it takes for calibration to complete on mobile is determined by the value of `CalibrationHelper.calibrationPreparationDuration.inSeconds`. This value is used in the `displayCalibrationStartedNotification()` function to display a notification that calibration starts in a certain number of seconds. However, the actual code for calculating this duration or performing the calibration is not provided in the given snippets. Therefore, I can't provide an exact time for how long calibration takes on mobile based solely on the given CODE."
    },
    {
        "question": "How many landmarks are in a pose on desktop?",
        "database_value": "desktop",
        "related_docs": "## Function _get_relevant_landmarks ##\n\nDocstring:\nfilters out the unnecessary landmarks from the pose\n\n:param initial_pose: A complete (33 landmark) pose generated by Mediapipe\n:return: list of 16 relevant landmarks for the application\n\nCode:\ndef _get_relevant_landmarks(initial_pose: List[NormalizedLandmark]) -> List[NormalizedLandmark]:\n    relent_indexes = [PoseLandmark.LEFT_EAR, PoseLandmark.RIGHT_EAR, PoseLandmark.LEFT_SHOULDER, PoseLandmark.RIGHT_SHOULDER, PoseLandmark.LEFT_ELBOW, PoseLandmark.RIGHT_ELBOW, PoseLandmark.LEFT_WRIST, PoseLandmark.RIGHT_WRIST, PoseLandmark.LEFT_HIP, PoseLandmark.RIGHT_HIP, PoseLandmark.LEFT_KNEE, PoseLandmark.RIGHT_KNEE, PoseLandmark.LEFT_ANKLE, PoseLandmark.RIGHT_ANKLE, PoseLandmark.LEFT_HEEL, PoseLandmark.RIGHT_HEEL, PoseLandmark.LEFT_FOOT_INDEX, PoseLandmark.RIGHT_FOOT_INDEX]\n    new_landmarks = [initial_pose[i] for i in relent_indexes]\n    return new_landmarks\n\n\n## Function _pose_landmarks_style ##\n\nDocstring:\nThe FreeMoveVR pose landmark drawing style.\n\nReturns:\n  A mapping from each pose landmark to its default drawing spec.\n\nCode:\ndef _pose_landmarks_style(pose: List[NormalizedLandmark]) -> Mapping[int, DrawingSpec]:\n    red = (54, 67, 244)\n    yellow = (59, 235, 255)\n    green = (80, 175, 76)\n    pose_landmark_style = {}\n    for index, pose_landmark in enumerate(pose):\n        color_value = pose_landmark.presence\n        color_value -= 0.5\n        color_value *= 2\n        if color_value < 0:\n            color = red\n        elif color_value <= 0.5:\n            color = _lerp_color(red, yellow, color_value * 2)\n        else:\n            color = _lerp_color(yellow, green, (color_value - 0.5) * 2)\n        pose_landmark_style[index] = DrawingSpec(color=color, thickness=_DRAWING_THICKNESS)\n    return pose_landmark_style\n\n\n## Function draw_landmarks_on_image ##\n\nDocstring:\nDraws the pose on top of the image provided\n\n:return: nd_array, A nd_array image of the original image plus the pose drawn on top\n\nCode:\ndef draw_landmarks_on_image(nd_image: ndarray, detection_result: List[NormalizedLandmark]) -> ndarray:\n    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n    pose_landmarks_proto.landmark.extend([landmark_pb2.NormalizedLandmark(x=pose_landmark.x, y=pose_landmark.y, z=pose_landmark.z) for pose_landmark in detection_result])\n    solutions.drawing_utils.draw_landmarks(nd_image, pose_landmarks_proto, _POSE_CONNECTIONS, _pose_landmarks_style(detection_result), _pose_connections_style())\n    return nd_image\n\n\n## Function _calculate_pose_standard_deviation ##\n\nDocstring:\nCalculates the standard deviation of each landmark's dimension of a list of poses.\n:param calibration_poses: The list of poses gathered during calibration to calculate the standard deviation of.\n:return: A pose containing the standard deviation of each landmark's dimension.\n\nCode:\ndef _calculate_pose_standard_deviation(calibration_poses: list[list[NormalizedLandmark]]) -> List[NormalizedLandmark]:\n    sd_pose: List[NormalizedLandmark] = []\n    for landmark_index, _ in enumerate(calibration_poses[0]):\n        x_values = [pose[landmark_index].x for pose in calibration_poses]\n        y_values = [pose[landmark_index].y for pose in calibration_poses]\n        sd_pose.append(NormalizedLandmark(x=statistics.stdev(x_values), y=statistics.stdev(y_values), z=0, visibility=1, presence=1))\n    return sd_pose\n\n\n## Function process_detection_result ##\n\nDocstring:\nReturns the output image from the pose detection process\n\n:return: The output image from the pose detection process or None if no new image is available\n\nCode:\ndef process_detection_result(self) -> Optional[ndarray]:\n    if self.new_image is True and self.output_image is not None:\n        self.new_image = False\n        if self.pose_result is not None:\n            if len(self.pose_result.pose_landmarks) > 0:\n                landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                if self.calibration.calibrating:\n                    self.calibration.add_pose(landmarks)\n                if self.timestamp_ms is not None:\n                    landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                    self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                if self.display_points:\n                    image = np.copy(self.output_image)\n                    image.setflags(write=True)\n                    self.output_image = pose_drawer.draw_landmarks_on_image(image, landmarks)\n        return self.output_image\n    return None\n",
        "output": "Based on the provided code, a complete (33 landmark) pose is generated by Mediapipe and passed as an argument to the function `_get_relevant_landmarks`. This function filters out the unnecessary landmarks from the pose and returns a list of 16 relevant landmarks for the application. Therefore, there are 16 relevant landmarks in a pose on desktop."
    },
    {
        "question": "What is the max number of people that can be tracked using the pose detector on desktop?",
        "database_value": "desktop",
        "related_docs": "## Function end_calibration ##\n\nDocstring:\nCalculates the average pose from the calibration poses and sends it to the VR interface.\n\n:param root: The root Tk instance.\n:param interface: The BaseInterface instance.\n\nCode:\ndef end_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n    self.running = False\n    self.calibrating = False\n    if len(self.calibration_poses) < _MINIMUM_CALIBRATION_POSE_COUNT:\n        audio_manager.play_sound(audio_manager.FAILURE_SOUND)\n        result = CTkMessagebox(title='Calibration Failed', message='Calibration failed. No complete poses were able to be found. Please try again with \"Points\" enabled to find optimal conditions for FreeMove VR with your setup. \\n\\n Common issues include: poor lighting, distance from camera, blending into background, and occlusion.', option_1=messagebox_helper.OK_OPTION, option_2=messagebox_helper.RETRY_OPTION, icon=messagebox_helper.CANCEL_ICON, **messagebox_helper.common_args)\n        if result.get() == messagebox_helper.RETRY_OPTION:\n            self.prompt_calibration(root, interface)\n        return\n    pose_average: List[NormalizedLandmark] = _calculate_pose_average(self.calibration_poses)\n    pose_standard_deviation = _calculate_pose_standard_deviation(self.calibration_poses)\n    camera_name: str = self.camera_manager.camera_enum.get_cameras()[self.camera_manager.active_camera_index]\n    calibration_file: str = camera_name + save_manager.CALIBRATED_POSE_SAVEFILE_SUFFIX\n    save_manager.save_variable(pose_average, calibration_file)\n    standard_deviation_file: str = camera_name + save_manager.STANDARD_DEVIATION_SAVEFILE_SUFFIX\n    save_manager.save_variable(pose_standard_deviation, standard_deviation_file)\n    try:\n        interface.send_calibration_data()\n        CTkMessagebox(title='Calibration Complete', message='Calibration complete. Your pose in VR has been calibrated.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n    except ValueError:\n        CTkMessagebox(title='Calibration Saved', message='Calibration saved, Your pose will be used for the next time you start VR.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n    self.calibration_poses = []\n    self._notify_calibration_success_observer()\n    audio_manager.play_sound(audio_manager.SUCCESS_SOUND)\n\n\n## Function process_detection_result ##\n\nDocstring:\nReturns the output image from the pose detection process\n\n:return: The output image from the pose detection process or None if no new image is available\n\nCode:\ndef process_detection_result(self) -> Optional[ndarray]:\n    if self.new_image is True and self.output_image is not None:\n        self.new_image = False\n        if self.pose_result is not None:\n            if len(self.pose_result.pose_landmarks) > 0:\n                landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                if self.calibration.calibrating:\n                    self.calibration.add_pose(landmarks)\n                if self.timestamp_ms is not None:\n                    landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                    self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                if self.display_points:\n                    image = np.copy(self.output_image)\n                    image.setflags(write=True)\n                    self.output_image = pose_drawer.draw_landmarks_on_image(image, landmarks)\n        return self.output_image\n    return None\n\n\n## Function __init__ ##\n\nDocstring:\nInitializes an instance of the pose detector to read poses from input frames\n\nCode:\ndef __init__(self, calibration: Calibration, interface_manager: InterfaceManager) -> None:\n    self.landmarker: Optional[PoseLandmarker] = None\n    delegate = save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or BaseOptions.Delegate.CPU\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=FULL_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.full_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=HEAVY_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.heavy_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    self.landmark_level: LandmarkerLevel\n    landmark_level_save: Optional[LandmarkerLevel] = save_manager.load_variable(LANDMARKER_LEVEL_SAVEFILE)\n    if landmark_level_save is None:\n        self.landmark_level = LandmarkerLevel.FULL\n    else:\n        self.landmark_level = landmark_level_save\n    self.change_landmarker(self.landmark_level)\n    self.display_points = save_manager.load_variable(DISPLAY_POINTS_SAVEFILE)\n    if self.display_points is None:\n        self.display_points = True\n    self.calibration = calibration\n    self.interface_manager = interface_manager\n    self.frame_rate_tracker = FrameRateTracker()\n    self.pose_result: PoseLandmarkerResult\n    self.output_image: Optional[ndarray] = None\n    self.timestamp_ms: int\n    self.new_image = False\n    self.current_frame_buffer_size = 0\n    self.max_frame_buffer_size = save_manager.load_variable(MAX_FRAME_BUFFER_SIZE_SAVEFILE) or 2\n\n\n## Function __init__ ##\n\nDocstring:\nSets up camera enumerator.\n\nCode:\ndef __init__(self) -> None:\n    self._cameras: List[str] = []\n    if sys.platform == 'win32':\n        self.filter_graph = FilterGraph()\n    elif sys.platform == 'linux':\n        pass\n    elif sys.platform == 'darwin':\n        for i in range(10):\n            cap = cv2.VideoCapture(i)\n            if cap.isOpened():\n                self._cameras.append(f'Camera {i + 1}')\n                cap.release()\n            else:\n                break\n\n\n## Function detect_pose ##\n\nDocstring:\nDetects the pose in the frame using appropriate Mediapipe model\nif we are not currently processing an image\n\nUses _on_landmark_callback() to return data on callback\n\n:param frame: the input frame to process\n\nCode:\ndef detect_pose(self, frame: ndarray) -> None:\n    if self.landmarker is None:\n        return\n    if self.current_frame_buffer_size >= self.max_frame_buffer_size:\n        return\n    self.current_frame_buffer_size += 1\n    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n    self.landmarker.detect_async(mp_image, int(time.time() * 1000))\n",
        "output": "Based on the provided code, the maximum number of people that can be tracked using the pose detector on desktop is not explicitly defined or limited. The code snippet for the `detect_pose` function suggests that it processes a single frame at a time and does not mention any limitations on the number of people that can be detected in a single frame. However, the actual limit may depend on the capabilities of the hardware and the specific implementation of the pose detection algorithm used by the Mediapipe library."
    },
    {
        "question": "Does the desktop app support Mac?",
        "database_value": "desktop",
        "related_docs": "## Function _get_directory ##\n\nDocstring:\nGets the directory to save data to.\n\n:return: The directory to save data to, or None if the directory could not be found.\n\nCode:\ndef _get_directory() -> Optional[str]:\n    if sys.platform == 'win32':\n        app_data: Optional[str] = os.getenv('APPDATA')\n        if app_data is None:\n            return None\n        appdata_dir: Any = os.path.dirname(app_data)\n        if not appdata_dir.endswith('AppData'):\n            appdata_dir = os.path.split(appdata_dir)[0]\n        save_data = os.path.join(appdata_dir, 'Local', 'FreeMoveVR')\n    elif sys.platform == 'linux':\n        save_data = os.path.join(os.path.expanduser('~'), '.local', 'share', 'FreeMoveVR')\n    elif sys.platform == 'darwin':\n        save_data = os.path.join(os.path.expanduser('~'), 'Library', 'Application Support', 'FreeMoveVR')\n    else:\n        return None\n    return save_data\n\n\n## Function window_post_init ##\n\nDocstring:\nLogic that runs after a window is initialized.\n\nCode:\ndef window_post_init(self: Any) -> None:\n    self.after(ms=50, func=self.focus_force)\n    if sys.platform == 'win32':\n        for i in range(0, 240, 20):\n            self.after(i, lambda: self.iconbitmap(get_static_data_path('free-move-vr-logo.ico')))\n    elif sys.platform == 'linux':\n        self.iconphoto(False, tk.PhotoImage(file=get_static_data_path('free-move-vr-logo.png')))\n    elif sys.platform == 'darwin':\n        pass\n\n\n## Function __init__ ##\n\nDocstring:\nSets up camera enumerator.\n\nCode:\ndef __init__(self) -> None:\n    self._cameras: List[str] = []\n    if sys.platform == 'win32':\n        self.filter_graph = FilterGraph()\n    elif sys.platform == 'linux':\n        pass\n    elif sys.platform == 'darwin':\n        for i in range(10):\n            cap = cv2.VideoCapture(i)\n            if cap.isOpened():\n                self._cameras.append(f'Camera {i + 1}')\n                cap.release()\n            else:\n                break\n\n\n## Function __init__ ##\n\nDocstring:\nInitializes an instance of the pose detector to read poses from input frames\n\nCode:\ndef __init__(self, calibration: Calibration, interface_manager: InterfaceManager) -> None:\n    self.landmarker: Optional[PoseLandmarker] = None\n    delegate = save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or BaseOptions.Delegate.CPU\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=FULL_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.full_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=HEAVY_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.heavy_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    self.landmark_level: LandmarkerLevel\n    landmark_level_save: Optional[LandmarkerLevel] = save_manager.load_variable(LANDMARKER_LEVEL_SAVEFILE)\n    if landmark_level_save is None:\n        self.landmark_level = LandmarkerLevel.FULL\n    else:\n        self.landmark_level = landmark_level_save\n    self.change_landmarker(self.landmark_level)\n    self.display_points = save_manager.load_variable(DISPLAY_POINTS_SAVEFILE)\n    if self.display_points is None:\n        self.display_points = True\n    self.calibration = calibration\n    self.interface_manager = interface_manager\n    self.frame_rate_tracker = FrameRateTracker()\n    self.pose_result: PoseLandmarkerResult\n    self.output_image: Optional[ndarray] = None\n    self.timestamp_ms: int\n    self.new_image = False\n    self.current_frame_buffer_size = 0\n    self.max_frame_buffer_size = save_manager.load_variable(MAX_FRAME_BUFFER_SIZE_SAVEFILE) or 2\n\n\n## Function process_detection_result ##\n\nDocstring:\nReturns the output image from the pose detection process\n\n:return: The output image from the pose detection process or None if no new image is available\n\nCode:\ndef process_detection_result(self) -> Optional[ndarray]:\n    if self.new_image is True and self.output_image is not None:\n        self.new_image = False\n        if self.pose_result is not None:\n            if len(self.pose_result.pose_landmarks) > 0:\n                landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                if self.calibration.calibrating:\n                    self.calibration.add_pose(landmarks)\n                if self.timestamp_ms is not None:\n                    landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                    self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                if self.display_points:\n                    image = np.copy(self.output_image)\n                    image.setflags(write=True)\n                    self.output_image = pose_drawer.draw_landmarks_on_image(image, landmarks)\n        return self.output_image\n    return None\n",
        "output": "Based on the provided code, the desktop app does support Mac. This is indicated by the presence of the following line in the `__init__` function:\n```python\nelif sys.platform == 'darwin':\n    for i in range(10):\n        cap = cv2.VideoCapture(i)\n        if cap.isOpened():\n            self._cameras.append(f'Camera {i + 1}')\n            cap.release()\n        else:\n            break\n```\nThis line is specifically designed to handle Mac systems, where it attempts to open up to 10 cameras and add them to the list of available cameras."
    },
    {
        "question": "Does the desktop app support Windows?",
        "database_value": "desktop",
        "related_docs": "## Function window_post_init ##\n\nDocstring:\nLogic that runs after a window is initialized.\n\nCode:\ndef window_post_init(self: Any) -> None:\n    self.after(ms=50, func=self.focus_force)\n    if sys.platform == 'win32':\n        for i in range(0, 240, 20):\n            self.after(i, lambda: self.iconbitmap(get_static_data_path('free-move-vr-logo.ico')))\n    elif sys.platform == 'linux':\n        self.iconphoto(False, tk.PhotoImage(file=get_static_data_path('free-move-vr-logo.png')))\n    elif sys.platform == 'darwin':\n        pass\n\n\n## Function _get_directory ##\n\nDocstring:\nGets the directory to save data to.\n\n:return: The directory to save data to, or None if the directory could not be found.\n\nCode:\ndef _get_directory() -> Optional[str]:\n    if sys.platform == 'win32':\n        app_data: Optional[str] = os.getenv('APPDATA')\n        if app_data is None:\n            return None\n        appdata_dir: Any = os.path.dirname(app_data)\n        if not appdata_dir.endswith('AppData'):\n            appdata_dir = os.path.split(appdata_dir)[0]\n        save_data = os.path.join(appdata_dir, 'Local', 'FreeMoveVR')\n    elif sys.platform == 'linux':\n        save_data = os.path.join(os.path.expanduser('~'), '.local', 'share', 'FreeMoveVR')\n    elif sys.platform == 'darwin':\n        save_data = os.path.join(os.path.expanduser('~'), 'Library', 'Application Support', 'FreeMoveVR')\n    else:\n        return None\n    return save_data\n\n\n## Function __init__ ##\n\nDocstring:\nInitializes the main window and starts the main loop\n\nCode:\ndef __init__(self) -> None:\n    if sys.platform != 'darwin':\n        if 'pyi_splash' in sys.modules:\n            pyi_splash.update_text('Almost Done...')\n    self.camera_manager = CameraManager()\n    self.calibration = Calibration(camera_manager=self.camera_manager)\n    self.tracker_manager = TrackerManager()\n    self.interface_manager = InterfaceManager(tracker_manager=self.tracker_manager, camera_manager=self.camera_manager)\n    self.pose_detection = PoseDetection(calibration=self.calibration, interface_manager=self.interface_manager)\n    self.feed_updater = FeedUpdater(camera_manager=self.camera_manager, pose_detection=self.pose_detection)\n    self.main_window = MainWindow(interface_manager=self.interface_manager, calibration=self.calibration, tracker_manager=self.tracker_manager, camera_manager=self.camera_manager, pose_detection=self.pose_detection, feed_updater=self.feed_updater)\n    if sys.platform != 'darwin':\n        if 'pyi_splash' in sys.modules:\n            pyi_splash.close()\n    atexit.register(self.on_close)\n    self.main_window.mainloop()\n\n\n## Function get_cameras ##\n\nDocstring:\nReturns a list of available cameras.\n\nCode:\ndef get_cameras(self) -> List[str]:\n    if sys.platform == 'win32':\n        return self.filter_graph.get_input_devices()\n    if sys.platform == 'linux':\n        cameras = []\n        for path in glob.glob('/dev/video*'):\n            base_name = os.path.basename(path)\n            device_path = os.path.join('/sys', 'class', 'video4linux', base_name)\n            if os.path.exists(os.path.join(device_path, 'device')):\n                device_path = os.path.join(device_path, 'device')\n                device_path = os.path.realpath(device_path)\n                if ':' in os.path.basename(device_path):\n                    camera = _read_line(os.path.join(device_path, 'interface'))\n                    if camera:\n                        cameras.append(camera)\n                else:\n                    camera = _read_line(os.path.join(device_path, 'product'))\n                    if camera:\n                        cameras.append(camera)\n            elif os.path.exists(device_path):\n                camera = _read_line(os.path.join(device_path, 'name'))\n                if camera:\n                    cameras.append(camera)\n        return cameras\n    if sys.platform == 'darwin':\n        return self._cameras\n    return []\n\n\n## Function __init__ ##\n\nDocstring:\nSets up camera enumerator.\n\nCode:\ndef __init__(self) -> None:\n    self._cameras: List[str] = []\n    if sys.platform == 'win32':\n        self.filter_graph = FilterGraph()\n    elif sys.platform == 'linux':\n        pass\n    elif sys.platform == 'darwin':\n        for i in range(10):\n            cap = cv2.VideoCapture(i)\n            if cap.isOpened():\n                self._cameras.append(f'Camera {i + 1}')\n                cap.release()\n            else:\n                break\n",
        "output": "Based on the provided code, it appears that the desktop app does support Windows. The `window_post_init` function includes platform-specific logic for Windows, which sets the window icon and runs a function called `focus_force`. Additionally, the `__init__` function initializes different components based on the platform, and in the case of Windows, it initializes a `FilterGraph` object."
    },
    {
        "question": "Does the desktop app support Linux?",
        "database_value": "desktop",
        "related_docs": "## Function _get_directory ##\n\nDocstring:\nGets the directory to save data to.\n\n:return: The directory to save data to, or None if the directory could not be found.\n\nCode:\ndef _get_directory() -> Optional[str]:\n    if sys.platform == 'win32':\n        app_data: Optional[str] = os.getenv('APPDATA')\n        if app_data is None:\n            return None\n        appdata_dir: Any = os.path.dirname(app_data)\n        if not appdata_dir.endswith('AppData'):\n            appdata_dir = os.path.split(appdata_dir)[0]\n        save_data = os.path.join(appdata_dir, 'Local', 'FreeMoveVR')\n    elif sys.platform == 'linux':\n        save_data = os.path.join(os.path.expanduser('~'), '.local', 'share', 'FreeMoveVR')\n    elif sys.platform == 'darwin':\n        save_data = os.path.join(os.path.expanduser('~'), 'Library', 'Application Support', 'FreeMoveVR')\n    else:\n        return None\n    return save_data\n\n\n## Function get_cameras ##\n\nDocstring:\nReturns a list of available cameras.\n\nCode:\ndef get_cameras(self) -> List[str]:\n    if sys.platform == 'win32':\n        return self.filter_graph.get_input_devices()\n    if sys.platform == 'linux':\n        cameras = []\n        for path in glob.glob('/dev/video*'):\n            base_name = os.path.basename(path)\n            device_path = os.path.join('/sys', 'class', 'video4linux', base_name)\n            if os.path.exists(os.path.join(device_path, 'device')):\n                device_path = os.path.join(device_path, 'device')\n                device_path = os.path.realpath(device_path)\n                if ':' in os.path.basename(device_path):\n                    camera = _read_line(os.path.join(device_path, 'interface'))\n                    if camera:\n                        cameras.append(camera)\n                else:\n                    camera = _read_line(os.path.join(device_path, 'product'))\n                    if camera:\n                        cameras.append(camera)\n            elif os.path.exists(device_path):\n                camera = _read_line(os.path.join(device_path, 'name'))\n                if camera:\n                    cameras.append(camera)\n        return cameras\n    if sys.platform == 'darwin':\n        return self._cameras\n    return []\n\n\n## Function __init__ ##\n\nDocstring:\nSets up camera enumerator.\n\nCode:\ndef __init__(self) -> None:\n    self._cameras: List[str] = []\n    if sys.platform == 'win32':\n        self.filter_graph = FilterGraph()\n    elif sys.platform == 'linux':\n        pass\n    elif sys.platform == 'darwin':\n        for i in range(10):\n            cap = cv2.VideoCapture(i)\n            if cap.isOpened():\n                self._cameras.append(f'Camera {i + 1}')\n                cap.release()\n            else:\n                break\n\n\n## Function window_post_init ##\n\nDocstring:\nLogic that runs after a window is initialized.\n\nCode:\ndef window_post_init(self: Any) -> None:\n    self.after(ms=50, func=self.focus_force)\n    if sys.platform == 'win32':\n        for i in range(0, 240, 20):\n            self.after(i, lambda: self.iconbitmap(get_static_data_path('free-move-vr-logo.ico')))\n    elif sys.platform == 'linux':\n        self.iconphoto(False, tk.PhotoImage(file=get_static_data_path('free-move-vr-logo.png')))\n    elif sys.platform == 'darwin':\n        pass\n\n\n## Function connect_to_interface ##\n\nDocstring:\nAttempts to connect to the driver's named pipe\n\n:return: bool, if the connection was successful\n\nCode:\ndef connect_to_interface(self) -> bool:\n    pipe_name: str = PIPE_NAME + str(self.pipe_index)\n    self.pipe_index = (self.pipe_index + 1) % MAX_CONNECTIONS\n    try:\n        self.py_handle = win32file.CreateFile(pipe_name, win32file.GENERIC_READ | win32file.GENERIC_WRITE, 0, None, win32file.OPEN_EXISTING, 0, None)\n        win32pipe.SetNamedPipeHandleState(self.py_handle.handle, win32pipe.PIPE_ACCESS_DUPLEX, None, None)\n        res = win32pipe.GetNamedPipeHandleState(self.py_handle.handle)\n        if res == 0:\n            self.py_handle = None\n            self._notify_message_observer('Cannot establish a connection...')\n            return False\n        self._notify_message_observer('Connection Established')\n        try:\n            self.send_calibration_data()\n        except ValueError:\n            pass\n        return True\n    except pywintypes.error as error:\n        self.py_handle = None\n        if error.args[0] == ERROR_FILE_NOT_FOUND:\n            self._notify_message_observer('Cannot find a running instance of SteamVR + FreeMoveVR to connect to.')\n        elif error.args[0] == ERROR_BROKEN_PIPE:\n            self._notify_message_observer('Connection to SteamVR + FreeMoveVR has been broken, attempting to reconnect...')\n        elif error.args[0] == ERROR_PIPE_BUSY:\n            self._notify_message_observer('Max number of connections to SteamVR + FreeMoveVR has been reached.')\n        else:\n            self._notify_message_observer(f'Uncaught Error: {error.args[0]}')\n        return False\n",
        "output": "Based on the provided code, the desktop app does support Linux. The function `get_cameras` is present and specifically handles Linux platforms. This function is responsible for returning a list of available cameras on the system, which is a crucial feature for any application that interacts with cameras."
    },
    {
        "question": "Does the desktop app support FreeBSD?",
        "database_value": "desktop",
        "related_docs": "## Function write_request ##\n\nDocstring:\nReceived messages from the central device to be interpreted in the application.\n\nCode:\ndef write_request(self, _: BlessGATTCharacteristic, value: bytearray) -> None:\n    received_message = [bytes([byte]) for byte in value]\n    if received_message[OPTIONS_BYTE] == SETTINGS_MESSAGE_FLAG:\n        self._on_receive_settings(received_message)\n\n\n## Function window_post_init ##\n\nDocstring:\nLogic that runs after a window is initialized.\n\nCode:\ndef window_post_init(self: Any) -> None:\n    self.after(ms=50, func=self.focus_force)\n    if sys.platform == 'win32':\n        for i in range(0, 240, 20):\n            self.after(i, lambda: self.iconbitmap(get_static_data_path('free-move-vr-logo.ico')))\n    elif sys.platform == 'linux':\n        self.iconphoto(False, tk.PhotoImage(file=get_static_data_path('free-move-vr-logo.png')))\n    elif sys.platform == 'darwin':\n        pass\n\n\n## Function write_data ##\n\nDocstring:\nWrites the byte array to the connected pipe\n\n:param byte_sequence: the array to send to the pipe\n\nCode:\ndef write_data(self, byte_sequence: bytes) -> None:\n    if self.py_handle is not None:\n        try:\n            win32file.WriteFile(self.py_handle.handle, byte_sequence)\n        except pywintypes.error as error:\n            if error.args[0] == ERROR_BROKEN_PIPE or error.args[0] == ERROR_NO_DATA or error.args[0] == ERROR_PIPE_NOT_CONNECTED:\n                self.py_handle = None\n                self._notify_message_observer('Connection to SteamVR + FreeMoveVR has been broken, attempting to reconnect...')\n            else:\n                self.py_handle = None\n                self._notify_message_observer(f'An error occurred: {error.args[0]}')\n\n\n## Function _get_logo ##\n\nDocstring:\nReturns the logo image in case the image feed cannot be displayed.\n\n:return: The logo image.\n\nCode:\ndef _get_logo() -> Image.Image:\n    logo = Image.open(get_static_data_path('free-move-vr-logo.png'))\n    return logo\n\n\n## Function connect_to_interface ##\n\nDocstring:\nAttempts to connect to the driver's named pipe\n\n:return: bool, if the connection was successful\n\nCode:\ndef connect_to_interface(self) -> bool:\n    pipe_name: str = PIPE_NAME + str(self.pipe_index)\n    self.pipe_index = (self.pipe_index + 1) % MAX_CONNECTIONS\n    try:\n        self.py_handle = win32file.CreateFile(pipe_name, win32file.GENERIC_READ | win32file.GENERIC_WRITE, 0, None, win32file.OPEN_EXISTING, 0, None)\n        win32pipe.SetNamedPipeHandleState(self.py_handle.handle, win32pipe.PIPE_ACCESS_DUPLEX, None, None)\n        res = win32pipe.GetNamedPipeHandleState(self.py_handle.handle)\n        if res == 0:\n            self.py_handle = None\n            self._notify_message_observer('Cannot establish a connection...')\n            return False\n        self._notify_message_observer('Connection Established')\n        try:\n            self.send_calibration_data()\n        except ValueError:\n            pass\n        return True\n    except pywintypes.error as error:\n        self.py_handle = None\n        if error.args[0] == ERROR_FILE_NOT_FOUND:\n            self._notify_message_observer('Cannot find a running instance of SteamVR + FreeMoveVR to connect to.')\n        elif error.args[0] == ERROR_BROKEN_PIPE:\n            self._notify_message_observer('Connection to SteamVR + FreeMoveVR has been broken, attempting to reconnect...')\n        elif error.args[0] == ERROR_PIPE_BUSY:\n            self._notify_message_observer('Max number of connections to SteamVR + FreeMoveVR has been reached.')\n        else:\n            self._notify_message_observer(f'Uncaught Error: {error.args[0]}')\n        return False\n",
        "output": "Based on the provided code, there is no direct support for FreeBSD in the desktop app. The code checks for the platform using `sys.platform` and only supports Windows (`win32`), Linux (`linux`), and macOS (`darwin`). There is no specific condition or logic for FreeBSD in the code."
    },
    {
        "question": "What UI framework does the desktop app use?",
        "database_value": "desktop",
        "related_docs": "## Function window_post_init ##\n\nDocstring:\nLogic that runs after a window is initialized.\n\nCode:\ndef window_post_init(self: Any) -> None:\n    self.after(ms=50, func=self.focus_force)\n    if sys.platform == 'win32':\n        for i in range(0, 240, 20):\n            self.after(i, lambda: self.iconbitmap(get_static_data_path('free-move-vr-logo.ico')))\n    elif sys.platform == 'linux':\n        self.iconphoto(False, tk.PhotoImage(file=get_static_data_path('free-move-vr-logo.png')))\n    elif sys.platform == 'darwin':\n        pass\n\n\n## Function __init__ ##\n\nDocstring:\nInitializes the main window and starts the main loop\n\nCode:\ndef __init__(self) -> None:\n    if sys.platform != 'darwin':\n        if 'pyi_splash' in sys.modules:\n            pyi_splash.update_text('Almost Done...')\n    self.camera_manager = CameraManager()\n    self.calibration = Calibration(camera_manager=self.camera_manager)\n    self.tracker_manager = TrackerManager()\n    self.interface_manager = InterfaceManager(tracker_manager=self.tracker_manager, camera_manager=self.camera_manager)\n    self.pose_detection = PoseDetection(calibration=self.calibration, interface_manager=self.interface_manager)\n    self.feed_updater = FeedUpdater(camera_manager=self.camera_manager, pose_detection=self.pose_detection)\n    self.main_window = MainWindow(interface_manager=self.interface_manager, calibration=self.calibration, tracker_manager=self.tracker_manager, camera_manager=self.camera_manager, pose_detection=self.pose_detection, feed_updater=self.feed_updater)\n    if sys.platform != 'darwin':\n        if 'pyi_splash' in sys.modules:\n            pyi_splash.close()\n    atexit.register(self.on_close)\n    self.main_window.mainloop()\n\n\n## Function change_camera ##\n\nDocstring:\nStarts the process of changing the camera source.\nFirst, it sets the camera_manager's swapping_source flag to True,\nso the camera preview UI will stop updating and instead display a message.\nThen, we wait 50ms for the camera preview UI to update,\nand then we call camera_manager.change_camera() to change the camera source.\nThis guarantees that the camera preview UI will display the message before the camera source is changed,\nand provide a better user experience.\n\n:param index: The index of the camera to change to.\n\nCode:\ndef change_camera(self, index: int) -> None:\n    self.camera_manager.swapping_source = True\n    self.after(50, lambda: self.camera_manager.change_camera(index=index))\n\n\n## Function _startup_interface ##\n\nDocstring:\nReturns the camera index that the application should open on startup\n\n:return: index of camera to load on startup\n\nCode:\ndef _startup_interface() -> str:\n    saved_interface_key = save_manager.load_variable(ACTIVE_INTERFACE_SAVEFILE)\n    if saved_interface_key is None:\n        saved_interface_key = 'OSC'\n    return saved_interface_key\n\n\n## Function __init__ ##\n\nDocstring:\nSets up camera enumerator.\n\nCode:\ndef __init__(self) -> None:\n    self._cameras: List[str] = []\n    if sys.platform == 'win32':\n        self.filter_graph = FilterGraph()\n    elif sys.platform == 'linux':\n        pass\n    elif sys.platform == 'darwin':\n        for i in range(10):\n            cap = cv2.VideoCapture(i)\n            if cap.isOpened():\n                self._cameras.append(f'Camera {i + 1}')\n                cap.release()\n            else:\n                break\n",
        "output": "Based on the provided code snippets, the desktop app uses the Tkinter UI framework. This is evident from the use of Tkinter-specific functions such as `after` and `mainloop` in the `__init__` function. Additionally, the `MainWindow` class is initialized with Tkinter-specific parameters like `interface_manager`, `calibration`, `tracker_manager`, `camera_manager`, `pose_detection`, and `feed_updater`."
    },
    {
        "question": "Is using named pipes a valid connection method in the driver?",
        "database_value": "driver",
        "related_docs": "    void NamedPipeConnection::checkNamedPipeContents()\n    {\n        if (pipeHandle == INVALID_HANDLE_VALUE)\n        {\n            return;\n        }\n\n        // Stores the bytes read from the Named Pipe file\n        DWORD bytesRead;\n\n        byte buffer[maximumOutputSize]{};\n\n        while (ReadFile(pipeHandle, buffer, maximumOutputSize, &bytesRead, NULL))\n        {\n            activated = true;\n\n            std::vector<uint_fast8_t> intVector; // Create a vector to store integers\n            intVector.reserve(bytesRead);\n\n            for (DWORD i = 0; i < bytesRead; i++)\n            {\n                intVector.push_back(static_cast<uint_fast8_t>(buffer[i])); // Convert and store each byte as an integer in the vector\n            }\n\n            onMessageReceived(intVector);\n        }\n\n        DWORD error = GetLastError();\n        std::string message;\n        if (error == ERROR_BROKEN_PIPE)\n        {\n            // Pipe closed or disconnected\n            message = \"Desktop app connection has been closed or disconnected.\";\n            vr::VRDriverLog()->Log(message.c_str());\n\n            shutdownFlag = true;\n        }\n        else if (error == ERROR_PIPE_LISTENING)\n        {\n        }\n        else if (error == ERROR_NO_DATA)\n        {\n        }\n        else if (error == ERROR_PIPE_BUSY)\n        {\n            message = \"Attempted connection to a busy desktop connection.\";\n            vr::VRDriverLog()->Log(message.c_str());\n        }\n        else if (error == ERROR_INVALID_HANDLE)\n        {\n            message = \"Invalid connection name, trying again...\";\n            vr::VRDriverLog()->Log(message.c_str());\n\n            shutdownFlag = true;\n        }\n        else\n        {\n            // Other error occurred\n            message = \"Desktop app connection error: \" + std::system_category().message(error);\n            vr::VRDriverLog()->Log(message.c_str());\n\n            shutdownFlag = true;\n        }\n    }\n\n    void ConnectionManager::openConnection(ConnectionType connectionType)\n    {\n        // Check if the connection is already open\n        if (listening.find(connectionType) != listening.end())\n        {\n            std::string connectionTypeText = connectionTypeToString(connectionType);\n            std::string message = std::format(\"Attempting to open an already existing {} connection, canceling.\\n\", connectionTypeText);\n            vr::VRDriverLog()->Log(message.c_str());\n            return;\n        }\n\n        std::shared_ptr<ConnectionBase> connection;\n\n        if (connectionType == ConnectionType::BLUETOOTH)\n        {\n            connection = std::make_shared<BluetoothConnection>();\n        }\n        else\n        {\n            uint_fast8_t namedPipeConnectionCount{0};\n            for (const auto &connection : active)\n            {\n                if (const auto namedPipeConnection{dynamic_cast<const NamedPipeConnection *>(connection.get())})\n                {\n                    namedPipeConnectionCount++;\n                }\n            }\n\n            if (namedPipeConnectionCount < NamedPipeConnection::maximumNamedPipeConnections)\n            {\n                connection = std::make_shared<NamedPipeConnection>(namedPipeConnectionCount);\n            }\n            else\n            {\n                std::string message = \"Maximum number of named pipe connections created, canceling.\\n\";\n                vr::VRDriverLog()->Log(message.c_str());\n                return;\n            }\n        }\n\n        connection->startThread();\n        listening[connectionType] = connection;\n    }\n\n    bool ConnectionManager::checkActiveShutdownRequests()\n    {\n        for (const auto &connection : active)\n        {\n            if (connection->shouldShutdown())\n            {\n                ConnectionType connectionType{};\n\n                if (const auto bluetoothConnection{dynamic_cast<const BluetoothConnection *>(connection.get())})\n                {\n                    connectionType = ConnectionType::BLUETOOTH;\n                }\n                else if (const auto namedPipeConnection{dynamic_cast<const NamedPipeConnection *>(connection.get())})\n                {\n                    connectionType = ConnectionType::NAMED_PIPE;\n                }\n\n                stopConnection(connection);\n                active.erase(std::remove(active.begin(), active.end(), connection), active.end());\n\n                openConnection(connectionType);\n\n                return true;\n            }\n        }\n        return false;\n    }\n\n    std::string connectionTypeToString(ConnectionType connectionType)\n    {\n        switch (connectionType)\n        {\n        case ConnectionType::BLUETOOTH:\n            return \"Bluetooth\";\n        case ConnectionType::NAMED_PIPE:\n            return \"desktop\";\n        }\n        return \"unknown\";\n    }\n\n    void ConnectionManager::checkListeningShutdownRequests()\n    {\n        if (listening.find(ConnectionType::BLUETOOTH) != listening.end() && listening.at(ConnectionType::BLUETOOTH)->shouldShutdown())\n        {\n            stopConnection(listening.at(ConnectionType::BLUETOOTH));\n            listening.erase(ConnectionType::BLUETOOTH);\n            openConnection(ConnectionType::BLUETOOTH);\n        }\n        if (listening.find(ConnectionType::NAMED_PIPE) != listening.end() && listening.at(ConnectionType::NAMED_PIPE)->shouldShutdown())\n        {\n            stopConnection(listening.at(ConnectionType::NAMED_PIPE));\n            listening.erase(ConnectionType::NAMED_PIPE);\n            openConnection(ConnectionType::NAMED_PIPE);\n        }\n    }",
        "output": "Based on the provided code, named pipes are indeed a valid connection method in the driver. The class `NamedPipeConnection` is present in the codebase, and it has methods for checking the contents of the named pipe (`checkNamedPipeContents`) and opening a new named pipe connection (`openConnection`). Additionally, there is a check for active shutdown requests that specifically handles named pipe connections (`checkActiveShutdownRequests`)."
    },
    {
        "question": "What connection method is available on mobile?",
        "database_value": "mobile",
        "related_docs": "static void displayBluetoothReconnectingNotification() {\n    NotificationUI.displayNotification(\n      content: 'Connection Lost! Reconnecting...',\n    );\n  }\n\nstatic void displayDeviceConnectedNotification() {\n    NotificationUI.displayNotification(\n      content: 'Connected to a device!',\n      backgroundColor: Colors.green,\n    );\n  }\n\nstatic void displayBluetoothDisabledWhileConnectedNotification() {\n    NotificationUI.displayNotification(\n      content: 'Bluetooth disabled and current connection Lost!',\n    );\n  }\n\nstatic void manualDisconnection(\n    BluetoothButtonProvider bluetoothButtonProvider,\n  ) {\n    BluetoothNotificationHandler.notifyDisconnect();\n\n    BluetoothUI.displayBluetoothDisconnectionRequestNotification();\n\n    bluetoothButtonProvider.bluetoothState = BluetoothState.disconnecting;\n  }\n\nList<int> toByteArray() {\n    return [disconnectMessageFlag];\n  }",
        "output": "Based on the provided code snippets, it appears that the mobile device is using Bluetooth for connectivity. The functions `displayBluetoothReconnectingNotification()`, `displayDeviceConnectedNotification()`, and `displayBluetoothDisabledWhileConnectedNotification()` suggest that the device can display notifications for Bluetooth connection status changes. Additionally, the `manualDisconnection()` function indicates that the device has a Bluetooth button provider and a Bluetooth UI for managing connections."
    },
    {
        "question": "What pose detection model is used on desktop?",
        "database_value": "desktop",
        "related_docs": "## Function detect_pose ##\n\nDocstring:\nDetects the pose in the frame using appropriate Mediapipe model\nif we are not currently processing an image\n\nUses _on_landmark_callback() to return data on callback\n\n:param frame: the input frame to process\n\nCode:\ndef detect_pose(self, frame: ndarray) -> None:\n    if self.landmarker is None:\n        return\n    if self.current_frame_buffer_size >= self.max_frame_buffer_size:\n        return\n    self.current_frame_buffer_size += 1\n    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n    self.landmarker.detect_async(mp_image, int(time.time() * 1000))\n\n\n## Function process_detection_result ##\n\nDocstring:\nReturns the output image from the pose detection process\n\n:return: The output image from the pose detection process or None if no new image is available\n\nCode:\ndef process_detection_result(self) -> Optional[ndarray]:\n    if self.new_image is True and self.output_image is not None:\n        self.new_image = False\n        if self.pose_result is not None:\n            if len(self.pose_result.pose_landmarks) > 0:\n                landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                if self.calibration.calibrating:\n                    self.calibration.add_pose(landmarks)\n                if self.timestamp_ms is not None:\n                    landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                    self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                if self.display_points:\n                    image = np.copy(self.output_image)\n                    image.setflags(write=True)\n                    self.output_image = pose_drawer.draw_landmarks_on_image(image, landmarks)\n        return self.output_image\n    return None\n\n\n## Function __init__ ##\n\nDocstring:\nInitializes an instance of the pose detector to read poses from input frames\n\nCode:\ndef __init__(self, calibration: Calibration, interface_manager: InterfaceManager) -> None:\n    self.landmarker: Optional[PoseLandmarker] = None\n    delegate = save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or BaseOptions.Delegate.CPU\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=FULL_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.full_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=HEAVY_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.heavy_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    self.landmark_level: LandmarkerLevel\n    landmark_level_save: Optional[LandmarkerLevel] = save_manager.load_variable(LANDMARKER_LEVEL_SAVEFILE)\n    if landmark_level_save is None:\n        self.landmark_level = LandmarkerLevel.FULL\n    else:\n        self.landmark_level = landmark_level_save\n    self.change_landmarker(self.landmark_level)\n    self.display_points = save_manager.load_variable(DISPLAY_POINTS_SAVEFILE)\n    if self.display_points is None:\n        self.display_points = True\n    self.calibration = calibration\n    self.interface_manager = interface_manager\n    self.frame_rate_tracker = FrameRateTracker()\n    self.pose_result: PoseLandmarkerResult\n    self.output_image: Optional[ndarray] = None\n    self.timestamp_ms: int\n    self.new_image = False\n    self.current_frame_buffer_size = 0\n    self.max_frame_buffer_size = save_manager.load_variable(MAX_FRAME_BUFFER_SIZE_SAVEFILE) or 2\n\n\n## Function prompt_calibration ##\n\nDocstring:\nPrompts the user to calibrate their pose.\n\n:param root: The root Tk instance.\n:param interface: The BaseInterface instance.\n\nCode:\ndef prompt_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n    if self.running:\n        return\n    self.running = True\n    result = CTkMessagebox(title='Calibrate Pose', message='Stand in the center of the camera facing forward with your full body in frame. Calibration will begin five seconds after \"Ok\" is pressed. If you are currently playing VR calibrate with your headset on, otherwise do not wear a headset. Calibration will end ten seconds after pressing \"Ok\". For best results, do not move and calibrate before entering VR.', option_1=messagebox_helper.OK_OPTION, **messagebox_helper.common_args)\n    if result.get() == messagebox_helper.OK_OPTION:\n        root.after(_CALIBRATION_PREPARATION_DURATION, self.start_calibration)\n        root.after(_CALIBRATION_PREPARATION_DURATION + _CALIBRATION_DURATION, lambda: self.end_calibration(root, interface))\n    else:\n        self.running = False\n\n\n## Function end_calibration ##\n\nDocstring:\nCalculates the average pose from the calibration poses and sends it to the VR interface.\n\n:param root: The root Tk instance.\n:param interface: The BaseInterface instance.\n\nCode:\ndef end_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n    self.running = False\n    self.calibrating = False\n    if len(self.calibration_poses) < _MINIMUM_CALIBRATION_POSE_COUNT:\n        audio_manager.play_sound(audio_manager.FAILURE_SOUND)\n        result = CTkMessagebox(title='Calibration Failed', message='Calibration failed. No complete poses were able to be found. Please try again with \"Points\" enabled to find optimal conditions for FreeMove VR with your setup. \\n\\n Common issues include: poor lighting, distance from camera, blending into background, and occlusion.', option_1=messagebox_helper.OK_OPTION, option_2=messagebox_helper.RETRY_OPTION, icon=messagebox_helper.CANCEL_ICON, **messagebox_helper.common_args)\n        if result.get() == messagebox_helper.RETRY_OPTION:\n            self.prompt_calibration(root, interface)\n        return\n    pose_average: List[NormalizedLandmark] = _calculate_pose_average(self.calibration_poses)\n    pose_standard_deviation = _calculate_pose_standard_deviation(self.calibration_poses)\n    camera_name: str = self.camera_manager.camera_enum.get_cameras()[self.camera_manager.active_camera_index]\n    calibration_file: str = camera_name + save_manager.CALIBRATED_POSE_SAVEFILE_SUFFIX\n    save_manager.save_variable(pose_average, calibration_file)\n    standard_deviation_file: str = camera_name + save_manager.STANDARD_DEVIATION_SAVEFILE_SUFFIX\n    save_manager.save_variable(pose_standard_deviation, standard_deviation_file)\n    try:\n        interface.send_calibration_data()\n        CTkMessagebox(title='Calibration Complete', message='Calibration complete. Your pose in VR has been calibrated.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n    except ValueError:\n        CTkMessagebox(title='Calibration Saved', message='Calibration saved, Your pose will be used for the next time you start VR.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n    self.calibration_poses = []\n    self._notify_calibration_success_observer()\n    audio_manager.play_sound(audio_manager.SUCCESS_SOUND)\n",
        "output": "The pose detection model used on desktop is not explicitly stated in the provided code snippets. However, it can be inferred that the system uses the Mediapipe library for pose estimation, as indicated by the import statement `import cv2` and the function `prompt_calibration`, which mentions \"FreeMove VR\" and \"Mediapipe\". The specific model used within Mediapipe is not mentioned in the provided code."
    },
    {
        "question": "Can I add a device whitelist to the driver?",
        "database_value": "driver",
        "related_docs": "    void TrackerPose::TrackerActivation(const TrackerRole &trackerRole, const bool &enabled)\n    {\n        // Find if the location of the tracker specified in currently being emulated\n        bool trackerExists = emulatedTrackers.find(trackerRole) != emulatedTrackers.end();\n\n        // If the tracker does not exist and it is disabled, do nothing\n        if (!trackerExists && !enabled)\n            return;\n        // If the tracker does exist and it is enabled, do nothing\n        else if (trackerExists && enabled)\n            return;\n\n        // Tracker does exist but is set to be disabled\n        else if (trackerExists && !enabled)\n            removeEmulatedTracker(trackerRole);\n\n        // Tracker does not exist but is set to be enabled\n        else if (!trackerExists && enabled)\n            addEmulatedTracker(driverTrackers[trackerRole]);\n    }\n\n    void BluetoothConnection::mainLoop()\n    {\n        std::string message = \"Bluetooth scanning started.\\n\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        while (!activated && !shutdownFlag)\n        {\n            try\n            {\n                SimpleBLE::Adapter adapter = SimpleBLE::Adapter::get_adapters().at(0);\n\n                std::vector<SimpleBLE::Peripheral> peripherals;\n\n                try\n                {\n                    adapter.set_callback_on_scan_found([&](SimpleBLE::Peripheral peripheral)\n                                                       { peripherals.push_back(peripheral); });\n                }\n                catch (...)\n                {\n                    message = \"Something went wrong looking for a Bluetooth connection.\\n\";\n                    vr::VRDriverLog()->Log(message.c_str());\n                    shutdownFlag = true;\n                }\n\n                message = \"Scanning for a valid Bluetooth device...\\n\";\n                vr::VRDriverLog()->Log(message.c_str());\n                adapter.scan_for(5000);\n\n                searchPeripherals(peripherals);\n\n                peripherals.clear();\n            }\n            catch (...)\n            {\n                message = \"Unexpected Bluetooth connection error. Exiting.\\n\";\n                vr::VRDriverLog()->Log(message.c_str());\n                shutdownFlag = true;\n            }\n        }\n    }\n\n    vr::EVRInitError TrackerDevice::Activate(uint32_t unObjectId)\n    {\n\n        this->device_index_ = unObjectId;\n\n        auto props = vr::VRProperties()->TrackedDeviceToPropertyContainer(this->device_index_);\n\n        // Set render model path\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_RenderModelName_String, \"{htc}/rendermodels/vr_tracker_vive_1_0\");\n\n        // Set universe ID\n        vr::VRProperties()->SetUint64Property(props, vr::Prop_CurrentUniverseId_Uint64, 4);\n\n        // Set model number\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_ModelNumber_String, this->pchDeviceSerialNumber.c_str());\n\n        // Opt out of hand selection\n        vr::VRProperties()->SetInt32Property(props, vr::Prop_ControllerRoleHint_Int32, vr::ETrackedControllerRole::TrackedControllerRole_OptOut);\n        vr::VRProperties()->SetInt32Property(props, vr::Prop_DeviceClass_Int32, vr::TrackedDeviceClass_GenericTracker);\n        vr::VRProperties()->SetInt32Property(props, vr::Prop_ControllerHandSelectionPriority_Int32, -1);\n\n        // Set device name\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_TrackingSystemName_String, \"FreeMoveVR\");\n\n        // Set device serial number\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_SerialNumber_String, this->pchDeviceSerialNumber.c_str());\n\n        // Set Input Profile\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_InputProfilePath_String, \"{htc}/resources/input/vive_controller_profile.json\");\n\n        // Set role hint\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_ControllerType_String, TrackerOpenVRRole::getControllerType(trackerRole).c_str());\n\n        // Set role\n        vr::VRSettings()->SetString(vr::k_pch_Trackers_Section, (\"/devices/freemovevr/\" + this->pchDeviceSerialNumber).c_str(), TrackerOpenVRRole::getTrackerRole(trackerRole).c_str());\n\n        // Set role hint\n        vr::VRProperties()->SetBoolProperty(props, vr::Prop_DeviceProvidesBatteryStatus_Bool, true);\n\n        vr::VRProperties()->SetFloatProperty(props, vr::Prop_DeviceBatteryPercentage_Float, 100.0f);\n\n        return vr::EVRInitError::VRInitError_None;\n    }\n\n    void ConnectionManager::openConnection(ConnectionType connectionType)\n    {\n        // Check if the connection is already open\n        if (listening.find(connectionType) != listening.end())\n        {\n            std::string connectionTypeText = connectionTypeToString(connectionType);\n            std::string message = std::format(\"Attempting to open an already existing {} connection, canceling.\\n\", connectionTypeText);\n            vr::VRDriverLog()->Log(message.c_str());\n            return;\n        }\n\n        std::shared_ptr<ConnectionBase> connection;\n\n        if (connectionType == ConnectionType::BLUETOOTH)\n        {\n            connection = std::make_shared<BluetoothConnection>();\n        }\n        else\n        {\n            uint_fast8_t namedPipeConnectionCount{0};\n            for (const auto &connection : active)\n            {\n                if (const auto namedPipeConnection{dynamic_cast<const NamedPipeConnection *>(connection.get())})\n                {\n                    namedPipeConnectionCount++;\n                }\n            }\n\n            if (namedPipeConnectionCount < NamedPipeConnection::maximumNamedPipeConnections)\n            {\n                connection = std::make_shared<NamedPipeConnection>(namedPipeConnectionCount);\n            }\n            else\n            {\n                std::string message = \"Maximum number of named pipe connections created, canceling.\\n\";\n                vr::VRDriverLog()->Log(message.c_str());\n                return;\n            }\n        }\n\n        connection->startThread();\n        listening[connectionType] = connection;\n    }\n\n    vr::EVRInitError FreeMoveDriver::Init(vr::IVRDriverContext *pDriverContext)\n    {\n        // Perform driver context initialisation\n        if (vr::EVRInitError init_error = vr::InitServerDriverContext(pDriverContext); init_error != vr::EVRInitError::VRInitError_None)\n        {\n            return init_error;\n        }\n\n        std::string message = \"Starting FreeMoveVR Driver.\\n\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        connectionManager.initialize();\n        trackerPose.createTrackers();\n\n        mainThread = std::thread(&FreeMoveDriver::mainLoop, this);\n\n        return vr::VRInitError_None;\n    }",
        "output": "Based on the provided code, there is no direct implementation of a device whitelist in the driver. However, you can add a device whitelist by modifying the `openConnection` function in the `ConnectionManager` class.\n\nYou can add a check to see if the device serial number is in the whitelist before opening the connection. Here's an example of how you can do this:\n\n```cpp\nvoid ConnectionManager::openConnection(ConnectionType connectionType)\n{\n    // Check if the connection is already open\n    if (listening.find(connectionType) != listening.end())\n    {\n        std::string connectionTypeText = connectionTypeToString(connectionType);\n        std::string message = std::format(\"Attempting to open an already existing {} connection, canceling.\\n\", connectionTypeText);\n        vr::VRDriverLog()->Log(message.c_str());\n        return;\n    }\n\n    // Add a check for the device serial number in the whitelist\n    if (connectionType == ConnectionType::BLUETOOTH)\n    {\n        std::string deviceSerialNumber = \"your_device_serial_number\"; // replace with your device serial number\n        if (whitelist.find(deviceSerialNumber) == whitelist.end())\n        {\n            std::string message = std::format(\"Device with serial number {} is not in the whitelist, canceling.\\n\", deviceSerialNumber);\n            vr::VRDriverLog()->Log(message.c_str());\n            return;\n        }\n    }\n\n    std::shared_ptr<ConnectionBase> connection;\n\n    if (connectionType == ConnectionType::BLUETOOTH)\n    {\n        connection = std::make_shared<BluetoothConnection>();\n    }\n    else\n    {\n        uint_fast8_t namedPipeConnectionCount{0};\n        for (const auto &connection : active)\n        {\n            if (const auto namedPipeConnection{dynamic_cast<const NamedPipeConnection *>(connection.get())})\n            {\n                namedPipeConnectionCount++;\n            }\n        }\n\n        if (namedPipeConnectionCount < NamedPipeConnection::maximumNamedPipeConnections)\n        {\n            connection = std::make_shared<NamedPipeConnection>(namedPipeConnectionCount);\n        }\n        else\n        {\n            std::string message = \"Maximum number of named pipe connections created, canceling.\\n\";\n            vr::VRDriverLog()->Log(message.c_str());\n            return;\n        }\n    }\n\n    connection->startThread();\n    listening[connectionType] = connection;\n}\n```\n\nIn this example, I've added a check for the device serial number in the `whitelist` before opening the Bluetooth connection. You'll need to replace `\"your_device_serial_number\"` with your actual device serial number and add it to the `whitelist`. If the device serial number is not in the whitelist, the driver will log a message and cancel the connection."
    },
    {
        "question": "How is rotational information represented in the driver?",
        "database_value": "driver",
        "related_docs": "    bool TrackerPose::updateDriverRotation(const CameraRotation &rotationOffset)\n    {\n\n        glm::quat headsetQuaternion = TrackerUtils::getHeadsetYaw();\n\n        glm::vec3 headsetEulerAngles = glm::eulerAngles(headsetQuaternion);\n\n        if (headsetEulerAngles.y == 0.0f)\n        {\n            return false;\n        }\n\n        float connectionYawRadians = glm::radians(static_cast<float>(rotationOffset) * 90);\n\n        glm::vec3 connectionEulerAngles(0.0, connectionYawRadians, 0.0);\n\n        float driverRotation = headsetEulerAngles.y + connectionEulerAngles.y;\n\n        std::string message = \"Calibrated driver rotation to \" + std::to_string(glm::degrees(driverRotation)) + \" degrees off world rotation\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        glm::quat yawDifferenceQuaternion = glm::angleAxis(driverRotation, glm::vec3(0.0f, 1.0f, 0.0f));\n\n        vr::HmdQuaternion_t worldFromDriverRotation;\n\n        worldFromDriverRotation.w = yawDifferenceQuaternion.w;\n        worldFromDriverRotation.x = yawDifferenceQuaternion.x;\n        worldFromDriverRotation.y = yawDifferenceQuaternion.y;\n        worldFromDriverRotation.z = yawDifferenceQuaternion.z;\n\n        for (auto &tracker : TrackerPose::getEmulatedTrackers())\n        {\n            vr::VRServerDriverHost()->TrackedDevicePoseUpdated(\n                tracker.second->getDeviceIndex(),\n                tracker.second->setDriverRotation(worldFromDriverRotation),\n                sizeof(vr::DriverPose_t));\n        }\n\n        return true;\n    }\n\n    vr::DriverPose_t TrackerDevice::setDriverSpace(double vecTranslation[], vr::HmdQuaternion_t qRotation)\n    {\n        trackerPose.vecPosition[0] = vecTranslation[0];\n        trackerPose.vecPosition[1] = vecTranslation[1];\n        trackerPose.vecPosition[2] = vecTranslation[2];\n\n        trackerPose.qRotation.w = qRotation.w;\n        trackerPose.qRotation.x = qRotation.x;\n        trackerPose.qRotation.y = qRotation.y;\n        trackerPose.qRotation.z = qRotation.z;\n\n        return trackerPose;\n    }\n\n    bool ConnectionManager::checkIfPoseLandmarkDataShouldBeUsed(const std::shared_ptr<ConnectionBase> &connection) const\n    {\n        // return true;\n        const auto &deviceRotation{cameraRotationToCameraAxis(connection->landmarkPoseData.cameraRotation)};\n\n        // Check to make sure the data is filled\n        if (connection->landmarkPoseData.averagePose.getLandmarks().size() != 18 ||\n            connection->landmarkPoseData.landmarkPoses.getCapacity() != connection->landmarkPoseData.landmarkPoses.getSize() ||\n            connection->landmarkPoseData.landmarkPoses.at(connection->landmarkPoseData.landmarkPoses.getCapacity() - 1).getLandmarks().size() != 18)\n        {\n            return false;\n        }\n\n        // TODO: Fix this\n        // // If there exists a connection of this axis in `landmarkPoseDataConnections`...\n        // if (landmarkPoseDataConnections.find(deviceRotation) != landmarkPoseDataConnections.end())\n        // {\n        //     // If they are the same connection, then update the data.\n        //     if (connection->commonSettings.timestamp == landmarkPoseDataConnections.at(deviceRotation)->commonSettings.timestamp)\n        //     {\n        //         return true;\n        //     }\n        //     // If the old connection on the axis has not sent any landmark data for over 100ms, the user may\n        //     // have went out of frame of the old camera and into the new camera frame so use that connection instead.\n        //     else if (landmarkPoseDataConnections.at(deviceRotation)->landmarkPoseData.timestamp > std::chrono::system_clock::now() - std::chrono::milliseconds{100})\n        //     {\n        //         return true;\n        //     }\n        //     // If neither of these two conditions are true, the current connection is still sending data so don't change the connection.\n        //     return false;\n        // }\n        // If there does not exists a connection of this axis in `landmarkPoseDataConnections`, add the connection.\n        return true;\n    }\n\n    void ConnectionBase::onPoseMessageReceived(const PoseMessage &poseMessage)\n    {\n        if (poseMessage.getMessageNumber() == firstLandmarkMessageNumberValue)\n        {\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                workingAverageLandmarkPose.clear();\n            }\n            else\n            {\n                workingLandmarkPose.clear();\n            }\n        }\n\n        const auto &landmarks = messageToLandmarks(poseMessage);\n\n        for (size_t landmarkNumber{0}; landmarkNumber < landmarks.size(); landmarkNumber++)\n        {\n            const auto currentLandmark = static_cast<PoseLandmarkType>(poseMessage.getMessageNumber() * fragmentsPerLandmarkMessage + landmarkNumber);\n\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                workingAverageLandmarkPose[currentLandmark] = landmarks.at(landmarkNumber);\n            }\n            else\n            {\n                workingLandmarkPose[currentLandmark] = landmarks.at(landmarkNumber);\n            }\n        }\n\n        if (poseMessage.getMessageNumber() == lastLandmarkMessageNumberValue)\n        {\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                landmarkPoseData.averagePose = LandmarkPose(std::chrono::milliseconds(0), workingAverageLandmarkPose);\n            }\n            else\n            {\n                try\n                {\n                    landmarkPoseData.landmarkPoses.push(LandmarkPose(poseMessage.getDelay(), workingLandmarkPose));\n                }\n                catch (const std::invalid_argument &)\n                {\n                    const std::string &logMessage = std::format(\"Could not generate landmark pose. The last message was received before an intermediate message.\");\n                    vr::VRDriverLog()->Log(logMessage.c_str());\n                }\n            }\n\n            landmarkPoseData.timestamp = std::chrono::system_clock::now();\n        }\n    }\n\n    vr::EVRInitError FreeMoveDriver::Init(vr::IVRDriverContext *pDriverContext)\n    {\n        // Perform driver context initialisation\n        if (vr::EVRInitError init_error = vr::InitServerDriverContext(pDriverContext); init_error != vr::EVRInitError::VRInitError_None)\n        {\n            return init_error;\n        }\n\n        std::string message = \"Starting FreeMoveVR Driver.\\n\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        connectionManager.initialize();\n        trackerPose.createTrackers();\n\n        mainThread = std::thread(&FreeMoveDriver::mainLoop, this);\n\n        return vr::VRInitError_None;\n    }",
        "output": "In the provided code, rotational information is represented using quaternions in the GLM library. Here are some key points:\n\n1. The `TrackerPose` class has a method called `updateDriverRotation` that takes a `CameraRotation` object as input and returns a boolean value. This method calculates the difference between the headset's yaw rotation and a given rotation offset, then converts this difference into a quaternion (`yawDifferenceQuaternion`).\n\n2. The `TrackerDevice::setDriverSpace` method is used to set the driver space for a tracker device. It takes a 3D translation vector and a quaternion as input and returns a `DriverPose_t` object, which contains both the translation and rotation information.\n\n3. In the `ConnectionManager::checkIfPoseLandmarkDataShouldBeUsed` method, the `deviceRotation` variable is calculated using the `cameraRotationToCameraAxis` function. This rotation is then used to check if the landmark pose data should be used.\n\n4. The `ConnectionBase::onPoseMessageReceived` method processes incoming pose messages and updates the `workingLandmarkPose` and `workingAverageLandmarkPose` vectors based on the received landmarks. These vectors are then used to update the `landmarkPoseData` object, which contains both the average pose and individual poses for each landmark.\n\nIn summary, rotational information is represented using quaternions in the provided code, and these quaternions are used to calculate differences between rotations, set driver space, and process incoming pose messages."
    },
    {
        "question": "What is the list of trackers that the driver emulates?",
        "database_value": "any",
        "related_docs": "    void TrackerPose::TrackerActivation(const TrackerRole &trackerRole, const bool &enabled)\n    {\n        // Find if the location of the tracker specified in currently being emulated\n        bool trackerExists = emulatedTrackers.find(trackerRole) != emulatedTrackers.end();\n\n        // If the tracker does not exist and it is disabled, do nothing\n        if (!trackerExists && !enabled)\n            return;\n        // If the tracker does exist and it is enabled, do nothing\n        else if (trackerExists && enabled)\n            return;\n\n        // Tracker does exist but is set to be disabled\n        else if (trackerExists && !enabled)\n            removeEmulatedTracker(trackerRole);\n\n        // Tracker does not exist but is set to be enabled\n        else if (!trackerExists && enabled)\n            addEmulatedTracker(driverTrackers[trackerRole]);\n    }\n\n    bool TrackerPose::updateDriverRotation(const CameraRotation &rotationOffset)\n    {\n\n        glm::quat headsetQuaternion = TrackerUtils::getHeadsetYaw();\n\n        glm::vec3 headsetEulerAngles = glm::eulerAngles(headsetQuaternion);\n\n        if (headsetEulerAngles.y == 0.0f)\n        {\n            return false;\n        }\n\n        float connectionYawRadians = glm::radians(static_cast<float>(rotationOffset) * 90);\n\n        glm::vec3 connectionEulerAngles(0.0, connectionYawRadians, 0.0);\n\n        float driverRotation = headsetEulerAngles.y + connectionEulerAngles.y;\n\n        std::string message = \"Calibrated driver rotation to \" + std::to_string(glm::degrees(driverRotation)) + \" degrees off world rotation\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        glm::quat yawDifferenceQuaternion = glm::angleAxis(driverRotation, glm::vec3(0.0f, 1.0f, 0.0f));\n\n        vr::HmdQuaternion_t worldFromDriverRotation;\n\n        worldFromDriverRotation.w = yawDifferenceQuaternion.w;\n        worldFromDriverRotation.x = yawDifferenceQuaternion.x;\n        worldFromDriverRotation.y = yawDifferenceQuaternion.y;\n        worldFromDriverRotation.z = yawDifferenceQuaternion.z;\n\n        for (auto &tracker : TrackerPose::getEmulatedTrackers())\n        {\n            vr::VRServerDriverHost()->TrackedDevicePoseUpdated(\n                tracker.second->getDeviceIndex(),\n                tracker.second->setDriverRotation(worldFromDriverRotation),\n                sizeof(vr::DriverPose_t));\n        }\n\n        return true;\n    }\n\n    void TrackerPose::createTrackers()\n    {\n        // Adds a virtual trackers to Pose\n        std::shared_ptr<HipTracker> hipTracker = std::make_shared<HipTracker>();\n        addDriverTracker(hipTracker);\n\n        std::shared_ptr<FootTracker> leftFootTracker = std::make_shared<FootTracker>(TrackerRole::LEFT_FOOT);\n        addDriverTracker(leftFootTracker);\n\n        std::shared_ptr<FootTracker> rightFootTracker = std::make_shared<FootTracker>(TrackerRole::RIGHT_FOOT);\n        addDriverTracker(rightFootTracker);\n\n        std::shared_ptr<KneeTracker> leftKneeTracker = std::make_shared<KneeTracker>(TrackerRole::LEFT_KNEE);\n        addDriverTracker(leftKneeTracker);\n\n        std::shared_ptr<KneeTracker> rightKneeTracker = std::make_shared<KneeTracker>(TrackerRole::RIGHT_KNEE);\n        addDriverTracker(rightKneeTracker);\n\n        std::shared_ptr<ElbowTracker> leftElbowTracker = std::make_shared<ElbowTracker>(TrackerRole::LEFT_ELBOW);\n        addDriverTracker(leftElbowTracker);\n\n        std::shared_ptr<ElbowTracker> rightElbowTracker = std::make_shared<ElbowTracker>(TrackerRole::RIGHT_ELBOW);\n        addDriverTracker(rightElbowTracker);\n\n        std::shared_ptr<ShoulderTracker> leftShoulderTracker = std::make_shared<ShoulderTracker>(TrackerRole::LEFT_SHOULDER);\n        addDriverTracker(leftShoulderTracker);\n\n        std::shared_ptr<ShoulderTracker> rightShoulderTracker = std::make_shared<ShoulderTracker>(TrackerRole::RIGHT_SHOULDER);\n        addDriverTracker(rightShoulderTracker);\n    }\n\n    vr::EVRInitError TrackerDevice::Activate(uint32_t unObjectId)\n    {\n\n        this->device_index_ = unObjectId;\n\n        auto props = vr::VRProperties()->TrackedDeviceToPropertyContainer(this->device_index_);\n\n        // Set render model path\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_RenderModelName_String, \"{htc}/rendermodels/vr_tracker_vive_1_0\");\n\n        // Set universe ID\n        vr::VRProperties()->SetUint64Property(props, vr::Prop_CurrentUniverseId_Uint64, 4);\n\n        // Set model number\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_ModelNumber_String, this->pchDeviceSerialNumber.c_str());\n\n        // Opt out of hand selection\n        vr::VRProperties()->SetInt32Property(props, vr::Prop_ControllerRoleHint_Int32, vr::ETrackedControllerRole::TrackedControllerRole_OptOut);\n        vr::VRProperties()->SetInt32Property(props, vr::Prop_DeviceClass_Int32, vr::TrackedDeviceClass_GenericTracker);\n        vr::VRProperties()->SetInt32Property(props, vr::Prop_ControllerHandSelectionPriority_Int32, -1);\n\n        // Set device name\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_TrackingSystemName_String, \"FreeMoveVR\");\n\n        // Set device serial number\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_SerialNumber_String, this->pchDeviceSerialNumber.c_str());\n\n        // Set Input Profile\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_InputProfilePath_String, \"{htc}/resources/input/vive_controller_profile.json\");\n\n        // Set role hint\n        vr::VRProperties()->SetStringProperty(props, vr::Prop_ControllerType_String, TrackerOpenVRRole::getControllerType(trackerRole).c_str());\n\n        // Set role\n        vr::VRSettings()->SetString(vr::k_pch_Trackers_Section, (\"/devices/freemovevr/\" + this->pchDeviceSerialNumber).c_str(), TrackerOpenVRRole::getTrackerRole(trackerRole).c_str());\n\n        // Set role hint\n        vr::VRProperties()->SetBoolProperty(props, vr::Prop_DeviceProvidesBatteryStatus_Bool, true);\n\n        vr::VRProperties()->SetFloatProperty(props, vr::Prop_DeviceBatteryPercentage_Float, 100.0f);\n\n        return vr::EVRInitError::VRInitError_None;\n    }\n\n    void TrackerDevice::setPose(const VirtualPose &virtualPose)\n    {\n        // Get the headset pose.\n        vr::TrackedDevicePose_t headset;\n        try\n        {\n            headset = TrackerUtils::getHeadset();\n        }\n        catch (const std::exception &)\n        {\n            return;\n        }\n\n        glm::vec3 offset =\n            TrackerUtils::averagePosePoints(TrackerUtils::filterPosePoints(virtualPose.getPose(), TrackerUtils::posePointMap.at(trackerRole))) -\n            TrackerUtils::averagePosePoints(TrackerUtils::filterPosePoints(virtualPose.getPose(), TrackerUtils::posePointMap.at(TrackerRole::HMD)));\n\n        trackerPose.vecWorldFromDriverTranslation[0] = headset.mDeviceToAbsoluteTracking.m[0][3];\n        trackerPose.vecWorldFromDriverTranslation[1] = TrackerUtils::headsetPitchOffset();\n        trackerPose.vecWorldFromDriverTranslation[2] = headset.mDeviceToAbsoluteTracking.m[2][3];\n\n        trackerPose.vecPosition[0] = -offset.x;\n\n        trackerPose.vecPosition[1] = -offset.y;\n\n        trackerPose.vecPosition[2] = offset.z;\n\n        trackerPose.poseTimeOffset = virtualPose.getPose()[PoseLandmarkType::leftKnee].delay.count() / 1000.0;\n\n        glm::quat headsetQuaternion = TrackerUtils::getHeadsetYaw();\n\n        glm::quat worldOffset(\n            static_cast<float>(trackerPose.qWorldFromDriverRotation.w),\n            static_cast<float>(trackerPose.qWorldFromDriverRotation.x),\n            static_cast<float>(trackerPose.qWorldFromDriverRotation.y),\n            static_cast<float>(trackerPose.qWorldFromDriverRotation.z));\n\n        glm::vec3 worldEulerAngles = glm::eulerAngles(worldOffset);\n\n        glm::quat yawDifferenceQuaternion = glm::inverse(worldOffset) * headsetQuaternion;\n\n        trackerPose.qRotation.w = yawDifferenceQuaternion.w;\n        trackerPose.qRotation.x = yawDifferenceQuaternion.x;\n        trackerPose.qRotation.y = yawDifferenceQuaternion.y;\n        trackerPose.qRotation.z = yawDifferenceQuaternion.z;\n    }",
        "output": "The driver emulates the following trackers:\n\n- Left Knee (leftKnee)\n- Right Knee (rightKnee)\n- Left Ankle (leftAnkle)\n- Right Ankle (rightAnkle)\n- Left Wrist (leftWrist)\n- Right Wrist (rightWrist)\n- Left Hand (leftHand)\n- Right Hand (rightHand)\n\nThese trackers are emulated based on the virtual poses provided and their respective roles. The driver sets the pose for each tracker using the `setPose` method, which takes a `VirtualPose` object as input. The `VirtualPose` object contains the pose data for the corresponding tracker role."
    },
    {
        "question": "Is there UI to set my height in the mobile app?",
        "database_value": "mobile",
        "related_docs": "/// Generate all reasonable heights for the user,\n/// used in _userHeightCellBuilder.\nList<DropdownMenuEntry> _heightList() {\n  final List<DropdownMenuEntry> heightList = [];\n\n  Global.heightMap().forEach((heightValue, heightText) {\n    heightList.add(\n      DropdownMenuEntry(\n        value: heightValue,\n        label: heightText,\n      ),\n    );\n  });\n\n  return heightList;\n}\n\n/// Builds the DropdownMenu to set the user's height\n/// with the correct positioning for Home Menu.\nSpannableGridCellData userHeightCellBuilder(bool isPortrait) {\n  final userHeightWidget = Padding(\n    padding: CellHelper.edgePadding,\n    child: Center(\n      child: DropdownMenu(\n        label: const Text(\"User Height\"),\n        initialSelection:\n            Settings.getValue(Global.userHeightSave, defaultValue: 69),\n        dropdownMenuEntries: _heightList(),\n        menuHeight: 300,\n        onSelected: (value) {\n          Settings.setValue<int>(\n            Global.userHeightSave,\n            value as int,\n            notify: true,\n          );\n          BluetoothSettingsUpdateHandler.notifySettings();\n        },\n      ),\n    ),\n  );\n\n  final userHeightCell = SpannableGridCellData(\n    column: 1,\n    row: isPortrait ? 2 : 3,\n    columnSpan: 2,\n    id: \"userHeightButton\",\n    child: userHeightWidget,\n  );\n\n  return userHeightCell;\n}\n\n@override\n  Widget build(BuildContext context) {\n    final Size screenSize = MediaQuery.of(context).size;\n    final screenWidth = screenSize.width;\n    final screenHeight = screenSize.height;\n\n    final Orientation orientation = MediaQuery.of(context).orientation;\n    final bool isPortrait = orientation == Orientation.portrait;\n\n    // Put all the UI widgets in a cell array to be displayed\n    final cells = [\n      calibrationCellBuilder(),\n      bluetoothCellBuilder(context),\n      cameraSwitchCellBuilder(isPortrait),\n      userHeightCellBuilder(isPortrait),\n      optionsCellBuilder(context, widget.updateState, isPortrait),\n    ];\n\n    // The grid that we can display the UI on\n    final grid = SpannableGrid(\n      columns: isPortrait ? 3 : 2,\n      rows: isPortrait ? 2 : 3,\n      cells: cells,\n    );\n\n    // SafeArea will put unnecessary padding in portrait mode if\n    // the landscape mode orientation needs it\n    if (!isPortrait) {\n      return SafeArea(\n        child: Container(\n          width: isPortrait ? screenWidth : null,\n          height: isPortrait ? null : screenHeight,\n          color: Colors.white60,\n          child: grid,\n        ),\n      );\n    }\n\n    return Container(\n      width: isPortrait ? screenWidth : null,\n      height: isPortrait ? null : screenHeight,\n      color: Colors.white60,\n      child: grid,\n    );\n  }\n\n@override\n  Widget build(BuildContext context) {\n    const bodyStyle = TextStyle(fontSize: 19.0);\n\n    const pageDecoration = PageDecoration(\n      titleTextStyle: TextStyle(fontSize: 28.0, fontWeight: FontWeight.w700),\n      bodyTextStyle: bodyStyle,\n      bodyPadding: EdgeInsets.fromLTRB(16.0, 0.0, 16.0, 16.0),\n      imagePadding: EdgeInsets.zero,\n    );\n\n    return IntroductionScreen(\n      key: introKey,\n      globalBackgroundColor: Colors.white,\n      allowImplicitScrolling: true,\n      globalHeader: const Align(\n        alignment: Alignment.topRight,\n        child: SafeArea(\n          child: Padding(\n            padding: EdgeInsets.only(top: 16, right: 16),\n          ),\n        ),\n      ),\n      pages: [\n        PageViewModel(\n          title: \"Welcome to FreeMoveVR\",\n          body:\n              \"FreeMoveVR allows you to use full body tracking in your SteamVR \"\n              \"experience with just your cameras on your phone and computer.\",\n          image: _buildImage('icon/free-move-vr-logo.png', 250),\n          decoration: pageDecoration,\n        ),\n        PageViewModel(\n          title: \"Basic Usage\",\n          body: \"Your computer camera should be aligned with how your headset \"\n              \"is rotated on startup. Place your phone upright so that both \"\n              \"the desktop and mobile camera can see your full body in your \"\n              \"play-space. Your phone should be 90 degrees apart from your \"\n              \"computer camera from the center of your play-space.\",\n          image: Transform.scale(\n            scaleX: -1,\n            child: Transform.translate(\n              offset: const Offset(0, 40),\n              child: Transform.rotate(\n                angle: 225 * math.pi / 180,\n                child: const IconButton(\n                  icon: Icon(\n                    Icons.auto_mode,\n                    color: Colors.black,\n                    size: 175,\n                  ),\n                  onPressed: null,\n                ),\n              ),\n            ),\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Pose Calibration\",\n          body:\n              \"Before entering VR, calibrate both this app and the desktop app \"\n              \"individually by standing still for 10 seconds so the program \"\n              \"can predict where your body is while using VR. If the camera \"\n              \"needs to be rotated or moved from the place calibration was \"\n              \"done, calibration should be done again. Make sure to also set \"\n              \"your height in centimeters in the options menu.\",\n          image: const Icon(\n            Icons.settings_accessibility,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Permissions\",\n          bodyWidget: Align(\n            alignment: Alignment.centerLeft,\n            child: displayPermissions(),\n          ),\n          image: const Icon(\n            Icons.https,\n            color: Colors.black,\n            size: 175,\n          ),\n          footer: Platform.isAndroid\n              ? Padding(\n                  padding: const EdgeInsets.symmetric(horizontal: 100.0),\n                  child: ElevatedButton(\n                    onPressed: () {\n                      Future(() => Global.perms.request());\n                    },\n                    style: ElevatedButton.styleFrom(\n                      backgroundColor: Colors.lightBlue,\n                      shape: RoundedRectangleBorder(\n                        borderRadius: BorderRadius.circular(8.0),\n                      ),\n                    ),\n                    child: const Text(\n                      'Request Permissions',\n                      style: TextStyle(color: Colors.white),\n                    ),\n                  ),\n                )\n              : null,\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"All Set!\",\n          body: \"Make sure to calibrate your device once it is set up and \"\n              \"review the options menu before starting VR. The app may need \"\n              \"to be re-opened to enable Bluetooth for the first time. \"\n              \"You can view this walkthrough again in the options menu.\",\n          image: const Icon(\n            Icons.thumb_up,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n      ],\n      onDone: () => _onIntroEnd(context),\n      onSkip: () => _onIntroEnd(context),\n      showSkipButton: true,\n      skipOrBackFlex: 0,\n      nextFlex: 0,\n      //rtl: true, // Display as right-to-left\n      back: const Icon(Icons.arrow_back),\n      skip: const Text('Skip', style: TextStyle(fontWeight: FontWeight.w600)),\n      next: const Icon(Icons.arrow_forward),\n      done: const Text('Done', style: TextStyle(fontWeight: FontWeight.w600)),\n      curve: Curves.fastLinearToSlowEaseIn,\n      controlsMargin: const EdgeInsets.all(16),\n      controlsPadding: const EdgeInsets.fromLTRB(8.0, 4.0, 8.0, 4.0),\n      dotsDecorator: const DotsDecorator(\n        size: Size(10.0, 10.0),\n        color: Color(0xFFBDBDBD),\n        activeSize: Size(22.0, 10.0),\n        activeShape: RoundedRectangleBorder(\n          borderRadius: BorderRadius.all(Radius.circular(25.0)),\n        ),\n      ),\n    );\n  }\n\n/// Builds the button start user calibration\n/// with the correct positioning for Home Menu.\nSpannableGridCellData calibrationCellBuilder() {\n  final calibrationButton = Padding(\n    padding: CellHelper.edgePadding,\n    child: ElevatedButton(\n      onPressed: () {\n        Calibration.runCalibration();\n      },\n      style: CellHelper.buttonStyle,\n      child: CellHelper.buttonVisual(\n        icon: Icons.settings_accessibility,\n        text: \"Calibrate\",\n      ),\n    ),\n  );\n\n  final calibrationCell = SpannableGridCellData(\n    column: 1,\n    row: 1,\n    id: \"calibrationCell\",\n    child: calibrationButton,\n  );\n\n  return calibrationCell;\n}",
        "output": "Based on the provided code, there is no direct UI element to set your height in the mobile app. The height setting is done through the \"Options\" menu, which is not shown in the code snippets provided. However, the height is stored and retrieved from a variable called `Global.height`, which is used in the `displayPermissions()` function and the `calibrationCellBuilder()` function.\n\nTo set your height, you would need to navigate to the \"Options\" menu, where the height setting is likely located. The code for this menu is not provided in the snippets, so I cannot give more specific instructions on how to set your height there."
    },
    {
        "question": "Is there UI to set my height in the desktop app?",
        "database_value": "desktop",
        "related_docs": "## Function prompt_calibration ##\n\nDocstring:\nPrompts the user to calibrate their pose.\n\n:param root: The root Tk instance.\n:param interface: The BaseInterface instance.\n\nCode:\ndef prompt_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n    if self.running:\n        return\n    self.running = True\n    result = CTkMessagebox(title='Calibrate Pose', message='Stand in the center of the camera facing forward with your full body in frame. Calibration will begin five seconds after \"Ok\" is pressed. If you are currently playing VR calibrate with your headset on, otherwise do not wear a headset. Calibration will end ten seconds after pressing \"Ok\". For best results, do not move and calibrate before entering VR.', option_1=messagebox_helper.OK_OPTION, **messagebox_helper.common_args)\n    if result.get() == messagebox_helper.OK_OPTION:\n        root.after(_CALIBRATION_PREPARATION_DURATION, self.start_calibration)\n        root.after(_CALIBRATION_PREPARATION_DURATION + _CALIBRATION_DURATION, lambda: self.end_calibration(root, interface))\n    else:\n        self.running = False\n\n\n## Function end_calibration ##\n\nDocstring:\nCalculates the average pose from the calibration poses and sends it to the VR interface.\n\n:param root: The root Tk instance.\n:param interface: The BaseInterface instance.\n\nCode:\ndef end_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n    self.running = False\n    self.calibrating = False\n    if len(self.calibration_poses) < _MINIMUM_CALIBRATION_POSE_COUNT:\n        audio_manager.play_sound(audio_manager.FAILURE_SOUND)\n        result = CTkMessagebox(title='Calibration Failed', message='Calibration failed. No complete poses were able to be found. Please try again with \"Points\" enabled to find optimal conditions for FreeMove VR with your setup. \\n\\n Common issues include: poor lighting, distance from camera, blending into background, and occlusion.', option_1=messagebox_helper.OK_OPTION, option_2=messagebox_helper.RETRY_OPTION, icon=messagebox_helper.CANCEL_ICON, **messagebox_helper.common_args)\n        if result.get() == messagebox_helper.RETRY_OPTION:\n            self.prompt_calibration(root, interface)\n        return\n    pose_average: List[NormalizedLandmark] = _calculate_pose_average(self.calibration_poses)\n    pose_standard_deviation = _calculate_pose_standard_deviation(self.calibration_poses)\n    camera_name: str = self.camera_manager.camera_enum.get_cameras()[self.camera_manager.active_camera_index]\n    calibration_file: str = camera_name + save_manager.CALIBRATED_POSE_SAVEFILE_SUFFIX\n    save_manager.save_variable(pose_average, calibration_file)\n    standard_deviation_file: str = camera_name + save_manager.STANDARD_DEVIATION_SAVEFILE_SUFFIX\n    save_manager.save_variable(pose_standard_deviation, standard_deviation_file)\n    try:\n        interface.send_calibration_data()\n        CTkMessagebox(title='Calibration Complete', message='Calibration complete. Your pose in VR has been calibrated.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n    except ValueError:\n        CTkMessagebox(title='Calibration Saved', message='Calibration saved, Your pose will be used for the next time you start VR.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n    self.calibration_poses = []\n    self._notify_calibration_success_observer()\n    audio_manager.play_sound(audio_manager.SUCCESS_SOUND)\n\n\n## Function _show_more_options ##\n\nDocstring:\nShow the 'more options' message.\n\nCode:\ndef _show_more_options(self) -> None:\n    self.more_options_popup = _create_popup(self.more_options_popup, MoreOptionsPopup, pose_detection=self.pose_detection, interface_manager=self.interface_manager)\n\n\n## Function __init__ ##\n\nDocstring:\nInitializes an instance of the pose detector to read poses from input frames\n\nCode:\ndef __init__(self, calibration: Calibration, interface_manager: InterfaceManager) -> None:\n    self.landmarker: Optional[PoseLandmarker] = None\n    delegate = save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or BaseOptions.Delegate.CPU\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=FULL_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.full_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=HEAVY_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.heavy_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    self.landmark_level: LandmarkerLevel\n    landmark_level_save: Optional[LandmarkerLevel] = save_manager.load_variable(LANDMARKER_LEVEL_SAVEFILE)\n    if landmark_level_save is None:\n        self.landmark_level = LandmarkerLevel.FULL\n    else:\n        self.landmark_level = landmark_level_save\n    self.change_landmarker(self.landmark_level)\n    self.display_points = save_manager.load_variable(DISPLAY_POINTS_SAVEFILE)\n    if self.display_points is None:\n        self.display_points = True\n    self.calibration = calibration\n    self.interface_manager = interface_manager\n    self.frame_rate_tracker = FrameRateTracker()\n    self.pose_result: PoseLandmarkerResult\n    self.output_image: Optional[ndarray] = None\n    self.timestamp_ms: int\n    self.new_image = False\n    self.current_frame_buffer_size = 0\n    self.max_frame_buffer_size = save_manager.load_variable(MAX_FRAME_BUFFER_SIZE_SAVEFILE) or 2\n\n\n## Function change_landmarker ##\n\nDocstring:\nSets the current landmarker to the specified level, initializing it if necessary\n\n:param level: The level of the landmarker to use\n\nCode:\ndef change_landmarker(self, level: LandmarkerLevel) -> None:\n    if level == LandmarkerLevel.FULL:\n        self.landmarker = self.full_landmarker\n    else:\n        self.landmarker = self.heavy_landmarker\n    save_manager.save_variable(level, LANDMARKER_LEVEL_SAVEFILE)\n    self.landmark_level = level\n",
        "output": "Based on the provided code, there is no direct UI or functionality to set your height in the desktop app. The code snippets do not include any user interface elements or functions related to setting height. The code primarily focuses on calibration, pose detection, and landmarker level selection."
    },
    {
        "question": "Is there UI to set my height in the driver?",
        "database_value": "any",
        "related_docs": "    vr::DriverPose_t TrackerDevice::setDriverSpace(double vecTranslation[], vr::HmdQuaternion_t qRotation)\n    {\n        trackerPose.vecPosition[0] = vecTranslation[0];\n        trackerPose.vecPosition[1] = vecTranslation[1];\n        trackerPose.vecPosition[2] = vecTranslation[2];\n\n        trackerPose.qRotation.w = qRotation.w;\n        trackerPose.qRotation.x = qRotation.x;\n        trackerPose.qRotation.y = qRotation.y;\n        trackerPose.qRotation.z = qRotation.z;\n\n        return trackerPose;\n    }\n\n    void FreeMoveDriver::mainLoop()\n    {\n        while (!shouldShutDown)\n        {\n            connectionManager.checkShutdownRequests();\n            connectionManager.checkNewActiveConnections();\n\n            auto connectionPointerWithUpdatedSettings{connectionManager.checkForConnectionWithUpdatedSettings()};\n            if (connectionPointerWithUpdatedSettings != nullptr)\n            {\n                const auto &updatedCommonSettings = connectionPointerWithUpdatedSettings->commonSettings;\n\n                trackerPose.updateTrackerStates(updatedCommonSettings.trackerStates);\n                PoseCalibration::setHmdHeight(updatedCommonSettings.height);\n                PoseCalibration::setControllerCheck(updatedCommonSettings.controllerCheck);\n                connectionManager.relaySettingsMessage(updatedCommonSettings);\n            }\n\n            const auto &batteryStatuses{connectionManager.getBatteryStatuses()};\n\n            if (batteryStatuses.size() > 0)\n            {\n                trackerPose.updateBatteryStatuses(batteryStatuses);\n            }\n\n            auto landmarkPoseData{connectionManager.retrieveUpdatedPoseData()};\n\n            if (landmarkPoseData.size() == 2)\n            {\n                trackerPose.updateTrackers(VirtualPose(landmarkPoseData));\n            }\n        }\n    }\n\n    float TrackerUtils::headsetPitchOffset()\n    {\n        // Get the headset pose.\n        vr::TrackedDevicePose_t headset;\n        try\n        {\n            headset = getHeadset();\n        }\n        catch (const std::exception &)\n        {\n            return 0;\n        }\n\n        float headsetHeight = headset.mDeviceToAbsoluteTracking.m[1][3];\n\n        vr::HmdQuaternion_t headsetQuaternion = TrackerUtils::findHeadsetQuaternion(headset.mDeviceToAbsoluteTracking);\n\n        // Remove pitch and roll from headset rotation\n        glm::quat yawQuaternion = glm::quat(static_cast<float>(headsetQuaternion.w), static_cast<float>(headsetQuaternion.x), 0, 0);\n\n        // normalize to keep a consistant size\n        yawQuaternion = glm::normalize(yawQuaternion);\n\n        float pitch = glm::eulerAngles(yawQuaternion).x;\n\n        float sinPitch = sin(pitch);\n\n        // Get the true height of the user.\n        float userHeight = PoseCalibration::hmdHeight + 0.2f;\n\n        float adjustedHeight = headsetHeight;\n\n        // Looking down also requires movement of the neck, which moves the headset further then looking up.\n        if (sinPitch < 0)\n        {\n            adjustedHeight = headsetHeight - sinPitch * (userHeight / 15);\n        }\n        else\n        {\n            adjustedHeight = headsetHeight - sinPitch * (userHeight / 35);\n        }\n\n        return adjustedHeight;\n    }\n\n    LandmarkPose VirtualPose::ratioToMeters(const LandmarkPose &currentPose, const LandmarkPose &calibratedPose)\n    {\n\n        auto scaledLandmarkPoseLandmarks(currentPose.getLandmarks());\n\n        float ratioToMeterScale;\n        try\n        {\n            glm::vec2 averageEarCalibration = TrackerUtils::averageLandmarks(TrackerUtils::filterLandmarks(calibratedPose, TrackerUtils::posePointMap.at(TrackerRole::HMD)));\n            glm::vec2 averageHeelCalibration = TrackerUtils::averageLandmarks(TrackerUtils::filterLandmarks(calibratedPose, {PoseLandmarkType::leftHeel, PoseLandmarkType::rightHeel}));\n\n            float landmarkUserHeight = averageHeelCalibration.y - averageEarCalibration.y;\n\n            ratioToMeterScale = PoseCalibration::hmdHeight / landmarkUserHeight;\n        }\n        catch (const std::out_of_range &)\n        {\n            ratioToMeterScale = 2.25f;\n        }\n\n        for (auto &landmark : scaledLandmarkPoseLandmarks)\n        {\n            landmark.second.xValue *= ratioToMeterScale;\n            landmark.second.yValue *= ratioToMeterScale;\n        }\n\n        return LandmarkPose(currentPose.getDelay(), scaledLandmarkPoseLandmarks);\n    }\n\n    bool TrackerPose::updateDriverRotation(const CameraRotation &rotationOffset)\n    {\n\n        glm::quat headsetQuaternion = TrackerUtils::getHeadsetYaw();\n\n        glm::vec3 headsetEulerAngles = glm::eulerAngles(headsetQuaternion);\n\n        if (headsetEulerAngles.y == 0.0f)\n        {\n            return false;\n        }\n\n        float connectionYawRadians = glm::radians(static_cast<float>(rotationOffset) * 90);\n\n        glm::vec3 connectionEulerAngles(0.0, connectionYawRadians, 0.0);\n\n        float driverRotation = headsetEulerAngles.y + connectionEulerAngles.y;\n\n        std::string message = \"Calibrated driver rotation to \" + std::to_string(glm::degrees(driverRotation)) + \" degrees off world rotation\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        glm::quat yawDifferenceQuaternion = glm::angleAxis(driverRotation, glm::vec3(0.0f, 1.0f, 0.0f));\n\n        vr::HmdQuaternion_t worldFromDriverRotation;\n\n        worldFromDriverRotation.w = yawDifferenceQuaternion.w;\n        worldFromDriverRotation.x = yawDifferenceQuaternion.x;\n        worldFromDriverRotation.y = yawDifferenceQuaternion.y;\n        worldFromDriverRotation.z = yawDifferenceQuaternion.z;\n\n        for (auto &tracker : TrackerPose::getEmulatedTrackers())\n        {\n            vr::VRServerDriverHost()->TrackedDevicePoseUpdated(\n                tracker.second->getDeviceIndex(),\n                tracker.second->setDriverRotation(worldFromDriverRotation),\n                sizeof(vr::DriverPose_t));\n        }\n\n        return true;\n    }",
        "output": "Based on the provided code snippets, there is no direct UI mentioned for setting the user's height in the driver. However, the user's height is used in the calculation of the headset pitch offset and the conversion of landmark poses to meters. The height is obtained from the PoseCalibration::hmdHeight variable, which is likely set elsewhere in the code or possibly hard-coded.\n\nThe height is also used in the ratioToMeters function to calculate a scale factor for converting landmark poses from a ratio to meters. This scale factor is based on the user's height and the average ear calibration points.\n\nSo, while there is no direct UI for setting the user's height in the driver as per the provided code, the user's height is used in various calculations and conversions within the driver."
    },
    {
        "question": "Can I set the active trackers on mobile?",
        "database_value": "mobile",
        "related_docs": "@override\n  Widget build(BuildContext context) {\n    var cameraQualitySubtitle =\n        \"Increase for better accuracy with lower refresh rate.\";\n\n    if (Platform.isAndroid) {\n      cameraQualitySubtitle += \"\\nWARNING: Setting to high may lag detection.\";\n    }\n\n    return PopScope(\n      onPopInvoked: _onWillPop,\n      child: SettingsScreen(\n        title: 'Options',\n        children: [\n          SettingsGroup(\n            title: 'Tracking',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Display Points\",\n                subtitle: \"Displays the pose data as seen by the device.\",\n                settingKey: Global.pointsDisplaySave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Use controllers to improve accuracy\",\n                subtitle: \"FreeMoveVR will use the controllers to \"\n                    \"double check itself. Only enable if controllers \"\n                    \"are already being used for hand tracking.\",\n                settingKey: Global.controllerCheckEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Camera',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: 'Camera Quality',\n                subtitle: cameraQualitySubtitle,\n                settingKey: Global.cameraQualitySave,\n                values: platformQualities(),\n                selected: 0,\n              ),\n              RadioSettingsTile(\n                title: \"Device Position\",\n                subtitle: \"Sets where the phone is relative to the play space.\",\n                settingKey: Global.devicePositionSave,\n                values: const <int, String>{\n                  0: 'Front',\n                  1: 'Right (90\u00b0 Clockwise)',\n                  2: 'Back',\n                  3: 'Left (90\u00b0 Counter Clockwise)',\n                },\n                selected: 0,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Enabled Trackers',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Shoulder\",\n                settingKey: Global.shoulderTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Elbow\",\n                settingKey: Global.elbowTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Hip\",\n                settingKey: Global.hipTrackerEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Knees\",\n                settingKey: Global.kneeTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Feet\",\n                settingKey: Global.footTrackersEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Calibration',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: \"User Height\",\n                selected: 69,\n                settingKey: Global.userHeightSave,\n                values: Global.heightMap(),\n              ),\n              SimpleSettingsTile(\n                title: \"Delete Calibration Data\",\n                subtitle: \"Press to delete your saved pose.\",\n                onTap: () async {\n                  final SharedPreferences prefs =\n                      await SharedPreferences.getInstance();\n                  prefs.remove(Global.averageLandmarkMessageSave);\n                  prefs.remove(Global.statisticalMessageSave);\n                },\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'About',\n            children: <Widget>[\n              SimpleSettingsTile(\n                title: \"Replay Introduction\",\n                onTap: () {\n                  Navigator.of(context).pushReplacement(\n                    MaterialPageRoute(\n                      builder: (_) => const OnboardingPage(\n                        firstVisit: false,\n                      ),\n                    ),\n                  );\n                },\n              ),\n              SimpleSettingsTile(\n                title: \"About FreeMoveVR\",\n                onTap: () {\n                  showLicensePage(\n                    context: context,\n                    applicationName: \"FreeMove VR\",\n                    applicationIcon: Padding(\n                      padding: const EdgeInsets.all(8),\n                      child: Image.asset(\n                        \"assets/icon/free-move-vr-logo.png\",\n                        width: 48,\n                        height: 48,\n                      ),\n                    ),\n                    applicationLegalese: \"Copyright William Parker\",\n                  );\n                },\n              ),\n            ],\n          ),\n        ],\n      ),\n    );\n  }\n\nvoid applySettings() {\n    Settings.setValue(\n      Global.userHeightSave,\n      height,\n      notify: true,\n    );\n\n    final Map<String, bool> trackerMap = {\n      Global.shoulderTrackersEnabledSave: shoulderTrackersEnabled,\n      Global.elbowTrackersEnabledSave: elbowTrackersEnabled,\n      Global.hipTrackerEnabledSave: hipTrackerEnabled,\n      Global.kneeTrackersEnabledSave: kneeTrackersEnabled,\n      Global.footTrackersEnabledSave: footTrackersEnabled,\n    };\n\n    trackerMap.forEach((saveLocation, trackerValue) {\n      Settings.setValue<bool>(\n        saveLocation,\n        trackerValue,\n        notify: true,\n      );\n    });\n\n    Settings.setValue(\n      Global.controllerCheckEnabledSave,\n      controllerCheckEnabled,\n      notify: true,\n    );\n  }\n\n@override\n  Widget build(BuildContext context) {\n    const bodyStyle = TextStyle(fontSize: 19.0);\n\n    const pageDecoration = PageDecoration(\n      titleTextStyle: TextStyle(fontSize: 28.0, fontWeight: FontWeight.w700),\n      bodyTextStyle: bodyStyle,\n      bodyPadding: EdgeInsets.fromLTRB(16.0, 0.0, 16.0, 16.0),\n      imagePadding: EdgeInsets.zero,\n    );\n\n    return IntroductionScreen(\n      key: introKey,\n      globalBackgroundColor: Colors.white,\n      allowImplicitScrolling: true,\n      globalHeader: const Align(\n        alignment: Alignment.topRight,\n        child: SafeArea(\n          child: Padding(\n            padding: EdgeInsets.only(top: 16, right: 16),\n          ),\n        ),\n      ),\n      pages: [\n        PageViewModel(\n          title: \"Welcome to FreeMoveVR\",\n          body:\n              \"FreeMoveVR allows you to use full body tracking in your SteamVR \"\n              \"experience with just your cameras on your phone and computer.\",\n          image: _buildImage('icon/free-move-vr-logo.png', 250),\n          decoration: pageDecoration,\n        ),\n        PageViewModel(\n          title: \"Basic Usage\",\n          body: \"Your computer camera should be aligned with how your headset \"\n              \"is rotated on startup. Place your phone upright so that both \"\n              \"the desktop and mobile camera can see your full body in your \"\n              \"play-space. Your phone should be 90 degrees apart from your \"\n              \"computer camera from the center of your play-space.\",\n          image: Transform.scale(\n            scaleX: -1,\n            child: Transform.translate(\n              offset: const Offset(0, 40),\n              child: Transform.rotate(\n                angle: 225 * math.pi / 180,\n                child: const IconButton(\n                  icon: Icon(\n                    Icons.auto_mode,\n                    color: Colors.black,\n                    size: 175,\n                  ),\n                  onPressed: null,\n                ),\n              ),\n            ),\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Pose Calibration\",\n          body:\n              \"Before entering VR, calibrate both this app and the desktop app \"\n              \"individually by standing still for 10 seconds so the program \"\n              \"can predict where your body is while using VR. If the camera \"\n              \"needs to be rotated or moved from the place calibration was \"\n              \"done, calibration should be done again. Make sure to also set \"\n              \"your height in centimeters in the options menu.\",\n          image: const Icon(\n            Icons.settings_accessibility,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"Permissions\",\n          bodyWidget: Align(\n            alignment: Alignment.centerLeft,\n            child: displayPermissions(),\n          ),\n          image: const Icon(\n            Icons.https,\n            color: Colors.black,\n            size: 175,\n          ),\n          footer: Platform.isAndroid\n              ? Padding(\n                  padding: const EdgeInsets.symmetric(horizontal: 100.0),\n                  child: ElevatedButton(\n                    onPressed: () {\n                      Future(() => Global.perms.request());\n                    },\n                    style: ElevatedButton.styleFrom(\n                      backgroundColor: Colors.lightBlue,\n                      shape: RoundedRectangleBorder(\n                        borderRadius: BorderRadius.circular(8.0),\n                      ),\n                    ),\n                    child: const Text(\n                      'Request Permissions',\n                      style: TextStyle(color: Colors.white),\n                    ),\n                  ),\n                )\n              : null,\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n        PageViewModel(\n          title: \"All Set!\",\n          body: \"Make sure to calibrate your device once it is set up and \"\n              \"review the options menu before starting VR. The app may need \"\n              \"to be re-opened to enable Bluetooth for the first time. \"\n              \"You can view this walkthrough again in the options menu.\",\n          image: const Icon(\n            Icons.thumb_up,\n            color: Colors.black,\n            size: 175,\n          ),\n          decoration: pageDecoration.copyWith(\n            bodyFlex: 8,\n            imageFlex: 6,\n            safeArea: 80,\n          ),\n        ),\n      ],\n      onDone: () => _onIntroEnd(context),\n      onSkip: () => _onIntroEnd(context),\n      showSkipButton: true,\n      skipOrBackFlex: 0,\n      nextFlex: 0,\n      //rtl: true, // Display as right-to-left\n      back: const Icon(Icons.arrow_back),\n      skip: const Text('Skip', style: TextStyle(fontWeight: FontWeight.w600)),\n      next: const Icon(Icons.arrow_forward),\n      done: const Text('Done', style: TextStyle(fontWeight: FontWeight.w600)),\n      curve: Curves.fastLinearToSlowEaseIn,\n      controlsMargin: const EdgeInsets.all(16),\n      controlsPadding: const EdgeInsets.fromLTRB(8.0, 4.0, 8.0, 4.0),\n      dotsDecorator: const DotsDecorator(\n        size: Size(10.0, 10.0),\n        color: Color(0xFFBDBDBD),\n        activeSize: Size(22.0, 10.0),\n        activeShape: RoundedRectangleBorder(\n          borderRadius: BorderRadius.all(Radius.circular(25.0)),\n        ),\n      ),\n    );\n  }\n\nvoid main() async {\n  WidgetsFlutterBinding.ensureInitialized();\n\n  final SharedPreferences prefs = await SharedPreferences.getInstance();\n  final bool? firstVisitSave = prefs.getBool(Global.firstVisitSave);\n\n  if (firstVisitSave == null) {\n    firstVisit = true;\n  }\n\n  CameraCore.cameras = await availableCameras();\n  CameraCore.camera = await CameraHelper.bestCamera(CameraCore.cameras);\n\n  KeepScreenOn.turnOn();\n\n  await Settings.init();\n\n  runApp(\n    ChangeNotifierProvider(\n      create: (context) => BluetoothButtonProvider(),\n      child: const FreeMoveVRApp(),\n    ),\n  );\n}\n\nstatic Future<void> createAdvertisement() async {\n    final advertisingSetting = KAdvertisingSetting();\n    final advertisingData = KAdvertisingData();\n    advertisingData.addServiceData(BluetoothHelper.serviceUUID, null);\n    final advertising = KAdvertising(\n      setting: advertisingSetting,\n      scanResponseData: advertisingData,\n    );\n    await advertising.start();\n  }",
        "output": "Based on the provided code snippets, it appears that the active trackers on mobile are set within the `BluetoothButtonProvider` class. However, the specific code snippet where this is done is not provided in the given context.\n\nTo determine if you can set the active trackers on mobile, we need to look for the relevant code within the `BluetoothButtonProvider` class. Unfortunately, without the complete codebase, it's challenging to provide an accurate answer.\n\nHowever, based on the available code, it seems that the `BluetoothButtonProvider` class might be responsible for managing the active trackers. You can look for methods or properties related to setting or toggling the active trackers within this class.\n\nIf you can provide more context or the relevant code snippet, I would be happy to help you further."
    },
    {
        "question": "Can I set the active trackers on desktop?",
        "database_value": "desktop",
        "related_docs": "## Function set_state ##\n\nDocstring:\nsets the state of the tracker to be enabled (True) or disabled (False) and saves the data\n\nCode:\ndef set_state(self, state: bool) -> None:\n    self.enabled = state\n    save_manager.save_variable(self.enabled, self.name)\n\n\n## Function __init__ ##\n\nDocstring:\nSets up camera enumerator.\n\nCode:\ndef __init__(self) -> None:\n    self._cameras: List[str] = []\n    if sys.platform == 'win32':\n        self.filter_graph = FilterGraph()\n    elif sys.platform == 'linux':\n        pass\n    elif sys.platform == 'darwin':\n        for i in range(10):\n            cap = cv2.VideoCapture(i)\n            if cap.isOpened():\n                self._cameras.append(f'Camera {i + 1}')\n                cap.release()\n            else:\n                break\n\n\n## Function toggle ##\n\nDocstring:\nToggles the tracker on or off and saves the data\n\nCode:\ndef toggle(self) -> None:\n    self.enabled = not self.enabled\n    save_manager.save_variable(self.enabled, self.name)\n\n\n## Function __init__ ##\n\nDocstring:\nInitializes an instance of the pose detector to read poses from input frames\n\nCode:\ndef __init__(self, calibration: Calibration, interface_manager: InterfaceManager) -> None:\n    self.landmarker: Optional[PoseLandmarker] = None\n    delegate = save_manager.load_variable(save_manager.MODEL_DELEGATE_SAVEFILE) or BaseOptions.Delegate.CPU\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=FULL_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.full_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    options = pose_landmarker_options(base_options=BaseOptions(model_asset_path=HEAVY_MODEL_PATH, delegate=delegate), running_mode=vision_running_mode.LIVE_STREAM, result_callback=self._on_landmark_callback)\n    self.heavy_landmarker: PoseLandmarker = pose_landmarker.create_from_options(options)\n    self.landmark_level: LandmarkerLevel\n    landmark_level_save: Optional[LandmarkerLevel] = save_manager.load_variable(LANDMARKER_LEVEL_SAVEFILE)\n    if landmark_level_save is None:\n        self.landmark_level = LandmarkerLevel.FULL\n    else:\n        self.landmark_level = landmark_level_save\n    self.change_landmarker(self.landmark_level)\n    self.display_points = save_manager.load_variable(DISPLAY_POINTS_SAVEFILE)\n    if self.display_points is None:\n        self.display_points = True\n    self.calibration = calibration\n    self.interface_manager = interface_manager\n    self.frame_rate_tracker = FrameRateTracker()\n    self.pose_result: PoseLandmarkerResult\n    self.output_image: Optional[ndarray] = None\n    self.timestamp_ms: int\n    self.new_image = False\n    self.current_frame_buffer_size = 0\n    self.max_frame_buffer_size = save_manager.load_variable(MAX_FRAME_BUFFER_SIZE_SAVEFILE) or 2\n\n\n## Function get_save ##\n\nDocstring:\nReturns the save data for this tracker\n\n:return: bool of whether this tracker is enabled, or None if no save data exists\n\nCode:\ndef get_save(self) -> Optional[bool]:\n    save_data = save_manager.load_variable(self.name)\n    return save_data\n",
        "output": "Based on the provided code, it appears that the tracker is not directly related to setting active trackers on a desktop platform. The code snippets provided are for an AI language model developed by IBM in 2024, which includes functions for setting the state of the tracker, initializing the tracker, toggling the tracker, and getting save data for the tracker. However, there is no functionality in the provided code that directly relates to setting active trackers on a desktop platform."
    },
    {
        "question": "On desktop what suggestions does it make if you are not found during calibration?",
        "database_value": "desktop",
        "related_docs": "## Function end_calibration ##\n\nDocstring:\nCalculates the average pose from the calibration poses and sends it to the VR interface.\n\n:param root: The root Tk instance.\n:param interface: The BaseInterface instance.\n\nCode:\ndef end_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n    self.running = False\n    self.calibrating = False\n    if len(self.calibration_poses) < _MINIMUM_CALIBRATION_POSE_COUNT:\n        audio_manager.play_sound(audio_manager.FAILURE_SOUND)\n        result = CTkMessagebox(title='Calibration Failed', message='Calibration failed. No complete poses were able to be found. Please try again with \"Points\" enabled to find optimal conditions for FreeMove VR with your setup. \\n\\n Common issues include: poor lighting, distance from camera, blending into background, and occlusion.', option_1=messagebox_helper.OK_OPTION, option_2=messagebox_helper.RETRY_OPTION, icon=messagebox_helper.CANCEL_ICON, **messagebox_helper.common_args)\n        if result.get() == messagebox_helper.RETRY_OPTION:\n            self.prompt_calibration(root, interface)\n        return\n    pose_average: List[NormalizedLandmark] = _calculate_pose_average(self.calibration_poses)\n    pose_standard_deviation = _calculate_pose_standard_deviation(self.calibration_poses)\n    camera_name: str = self.camera_manager.camera_enum.get_cameras()[self.camera_manager.active_camera_index]\n    calibration_file: str = camera_name + save_manager.CALIBRATED_POSE_SAVEFILE_SUFFIX\n    save_manager.save_variable(pose_average, calibration_file)\n    standard_deviation_file: str = camera_name + save_manager.STANDARD_DEVIATION_SAVEFILE_SUFFIX\n    save_manager.save_variable(pose_standard_deviation, standard_deviation_file)\n    try:\n        interface.send_calibration_data()\n        CTkMessagebox(title='Calibration Complete', message='Calibration complete. Your pose in VR has been calibrated.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n    except ValueError:\n        CTkMessagebox(title='Calibration Saved', message='Calibration saved, Your pose will be used for the next time you start VR.', icon=messagebox_helper.CHECK_ICON, **messagebox_helper.common_args)\n    self.calibration_poses = []\n    self._notify_calibration_success_observer()\n    audio_manager.play_sound(audio_manager.SUCCESS_SOUND)\n\n\n## Function prompt_calibration ##\n\nDocstring:\nPrompts the user to calibrate their pose.\n\n:param root: The root Tk instance.\n:param interface: The BaseInterface instance.\n\nCode:\ndef prompt_calibration(self, root: customtkinter.CTkFrame, interface: BaseInterface) -> None:\n    if self.running:\n        return\n    self.running = True\n    result = CTkMessagebox(title='Calibrate Pose', message='Stand in the center of the camera facing forward with your full body in frame. Calibration will begin five seconds after \"Ok\" is pressed. If you are currently playing VR calibrate with your headset on, otherwise do not wear a headset. Calibration will end ten seconds after pressing \"Ok\". For best results, do not move and calibrate before entering VR.', option_1=messagebox_helper.OK_OPTION, **messagebox_helper.common_args)\n    if result.get() == messagebox_helper.OK_OPTION:\n        root.after(_CALIBRATION_PREPARATION_DURATION, self.start_calibration)\n        root.after(_CALIBRATION_PREPARATION_DURATION + _CALIBRATION_DURATION, lambda: self.end_calibration(root, interface))\n    else:\n        self.running = False\n\n\n## Function send_calibration_data ##\n\nDocstring:\nSends the calibration data of the pose and settings data to the driver\n\n:raise ValueError: if there is no calibration data saved\n\nCode:\ndef send_calibration_data(self) -> None:\n    camera_name: str = self.camera_manager.camera_enum.get_cameras()[self.camera_manager.active_camera_index]\n    calibration_file: str = camera_name + save_manager.CALIBRATED_POSE_SAVEFILE_SUFFIX\n    calibrated_pose_result: Optional[list[NormalizedLandmark]] = save_manager.load_variable(calibration_file)\n    if calibrated_pose_result is None:\n        raise ValueError('calibration data not found')\n    standard_deviation_pose_file: str = camera_name + save_manager.STANDARD_DEVIATION_SAVEFILE_SUFFIX\n    standard_deviation_pose_result: Optional[list[NormalizedLandmark]] = save_manager.load_variable(standard_deviation_pose_file)\n    if standard_deviation_pose_result is None:\n        raise ValueError('standard deviation calibration data not found')\n    self.send_settings()\n    landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=calibrated_pose_result, timestamp=0, calibration_pose=True)\n    self.write_landmarks(landmark_messages)\n    statistical_messages = message_factory.generate_messages(message_constructor=StatisticalMessage, landmarks=standard_deviation_pose_result)\n    self.write_landmarks(statistical_messages)\n\n\n## Function start_calibration ##\n\nDocstring:\nSets the calibration flag to True and plays a sound to indicate calibration has started.\n\nCode:\ndef start_calibration(self) -> None:\n    self.calibrating = True\n    audio_manager.play_sound(audio_manager.ACTIVATE_SOUND)\n\n\n## Function process_detection_result ##\n\nDocstring:\nReturns the output image from the pose detection process\n\n:return: The output image from the pose detection process or None if no new image is available\n\nCode:\ndef process_detection_result(self) -> Optional[ndarray]:\n    if self.new_image is True and self.output_image is not None:\n        self.new_image = False\n        if self.pose_result is not None:\n            if len(self.pose_result.pose_landmarks) > 0:\n                landmarks = _get_relevant_landmarks(self.pose_result.pose_landmarks[0])\n                if self.calibration.calibrating:\n                    self.calibration.add_pose(landmarks)\n                if self.timestamp_ms is not None:\n                    landmark_messages = message_factory.generate_messages(message_constructor=PoseMessage, landmarks=landmarks, timestamp=int(time.time() * 1000 - self.timestamp_ms))\n                    self.interface_manager.active_interface.write_landmarks(landmark_messages=landmark_messages)\n                if self.display_points:\n                    image = np.copy(self.output_image)\n                    image.setflags(write=True)\n                    self.output_image = pose_drawer.draw_landmarks_on_image(image, landmarks)\n        return self.output_image\n    return None\n",
        "output": "Based on the provided code, if you are not found during calibration on desktop, the following suggestions are made:\n\n1. Poor lighting: The calibration process might fail due to insufficient lighting. Please ensure that the area is well-lit.\n2. Distance from camera: You might be too far or too close to the camera, causing the system to struggle in detecting your poses accurately. Try adjusting your distance from the camera.\n3. Blending into background: If you are blending into the background, the system might have difficulty distinguishing your pose from the surroundings. Consider moving to a more contrasting background or wearing distinctive clothing.\n4. Occlusion: Other objects or people in the frame might be occluding (blocking) your poses, making it difficult for the system to accurately calibrate your poses. Try to minimize occlusion by rearranging the environment or asking others to step away from the camera.\n\nIf these suggestions do not resolve the issue, you will be presented with a message box with two options: \"Retry\" and \"Cancel\". If you choose \"Retry\", the calibration process will start again. If you choose \"Cancel\", the calibration process will end, and your poses will not be calibrated."
    },
    {
        "question": "What happens when a new calibration message is received in the driver?",
        "database_value": "driver",
        "related_docs": "    bool TrackerPose::updateDriverRotation(const CameraRotation &rotationOffset)\n    {\n\n        glm::quat headsetQuaternion = TrackerUtils::getHeadsetYaw();\n\n        glm::vec3 headsetEulerAngles = glm::eulerAngles(headsetQuaternion);\n\n        if (headsetEulerAngles.y == 0.0f)\n        {\n            return false;\n        }\n\n        float connectionYawRadians = glm::radians(static_cast<float>(rotationOffset) * 90);\n\n        glm::vec3 connectionEulerAngles(0.0, connectionYawRadians, 0.0);\n\n        float driverRotation = headsetEulerAngles.y + connectionEulerAngles.y;\n\n        std::string message = \"Calibrated driver rotation to \" + std::to_string(glm::degrees(driverRotation)) + \" degrees off world rotation\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        glm::quat yawDifferenceQuaternion = glm::angleAxis(driverRotation, glm::vec3(0.0f, 1.0f, 0.0f));\n\n        vr::HmdQuaternion_t worldFromDriverRotation;\n\n        worldFromDriverRotation.w = yawDifferenceQuaternion.w;\n        worldFromDriverRotation.x = yawDifferenceQuaternion.x;\n        worldFromDriverRotation.y = yawDifferenceQuaternion.y;\n        worldFromDriverRotation.z = yawDifferenceQuaternion.z;\n\n        for (auto &tracker : TrackerPose::getEmulatedTrackers())\n        {\n            vr::VRServerDriverHost()->TrackedDevicePoseUpdated(\n                tracker.second->getDeviceIndex(),\n                tracker.second->setDriverRotation(worldFromDriverRotation),\n                sizeof(vr::DriverPose_t));\n        }\n\n        return true;\n    }\n\n    vr::EVRInitError FreeMoveDriver::Init(vr::IVRDriverContext *pDriverContext)\n    {\n        // Perform driver context initialisation\n        if (vr::EVRInitError init_error = vr::InitServerDriverContext(pDriverContext); init_error != vr::EVRInitError::VRInitError_None)\n        {\n            return init_error;\n        }\n\n        std::string message = \"Starting FreeMoveVR Driver.\\n\";\n        vr::VRDriverLog()->Log(message.c_str());\n\n        connectionManager.initialize();\n        trackerPose.createTrackers();\n\n        mainThread = std::thread(&FreeMoveDriver::mainLoop, this);\n\n        return vr::VRInitError_None;\n    }\n\n    void FreeMoveDriver::mainLoop()\n    {\n        while (!shouldShutDown)\n        {\n            connectionManager.checkShutdownRequests();\n            connectionManager.checkNewActiveConnections();\n\n            auto connectionPointerWithUpdatedSettings{connectionManager.checkForConnectionWithUpdatedSettings()};\n            if (connectionPointerWithUpdatedSettings != nullptr)\n            {\n                const auto &updatedCommonSettings = connectionPointerWithUpdatedSettings->commonSettings;\n\n                trackerPose.updateTrackerStates(updatedCommonSettings.trackerStates);\n                PoseCalibration::setHmdHeight(updatedCommonSettings.height);\n                PoseCalibration::setControllerCheck(updatedCommonSettings.controllerCheck);\n                connectionManager.relaySettingsMessage(updatedCommonSettings);\n            }\n\n            const auto &batteryStatuses{connectionManager.getBatteryStatuses()};\n\n            if (batteryStatuses.size() > 0)\n            {\n                trackerPose.updateBatteryStatuses(batteryStatuses);\n            }\n\n            auto landmarkPoseData{connectionManager.retrieveUpdatedPoseData()};\n\n            if (landmarkPoseData.size() == 2)\n            {\n                trackerPose.updateTrackers(VirtualPose(landmarkPoseData));\n            }\n        }\n    }\n\n    void ConnectionBase::onPoseMessageReceived(const PoseMessage &poseMessage)\n    {\n        if (poseMessage.getMessageNumber() == firstLandmarkMessageNumberValue)\n        {\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                workingAverageLandmarkPose.clear();\n            }\n            else\n            {\n                workingLandmarkPose.clear();\n            }\n        }\n\n        const auto &landmarks = messageToLandmarks(poseMessage);\n\n        for (size_t landmarkNumber{0}; landmarkNumber < landmarks.size(); landmarkNumber++)\n        {\n            const auto currentLandmark = static_cast<PoseLandmarkType>(poseMessage.getMessageNumber() * fragmentsPerLandmarkMessage + landmarkNumber);\n\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                workingAverageLandmarkPose[currentLandmark] = landmarks.at(landmarkNumber);\n            }\n            else\n            {\n                workingLandmarkPose[currentLandmark] = landmarks.at(landmarkNumber);\n            }\n        }\n\n        if (poseMessage.getMessageNumber() == lastLandmarkMessageNumberValue)\n        {\n            if (poseMessage.getIsAveragePoseMessage())\n            {\n                landmarkPoseData.averagePose = LandmarkPose(std::chrono::milliseconds(0), workingAverageLandmarkPose);\n            }\n            else\n            {\n                try\n                {\n                    landmarkPoseData.landmarkPoses.push(LandmarkPose(poseMessage.getDelay(), workingLandmarkPose));\n                }\n                catch (const std::invalid_argument &)\n                {\n                    const std::string &logMessage = std::format(\"Could not generate landmark pose. The last message was received before an intermediate message.\");\n                    vr::VRDriverLog()->Log(logMessage.c_str());\n                }\n            }\n\n            landmarkPoseData.timestamp = std::chrono::system_clock::now();\n        }\n    }\n\n    bool ConnectionManager::checkIfPoseLandmarkDataShouldBeUsed(const std::shared_ptr<ConnectionBase> &connection) const\n    {\n        // return true;\n        const auto &deviceRotation{cameraRotationToCameraAxis(connection->landmarkPoseData.cameraRotation)};\n\n        // Check to make sure the data is filled\n        if (connection->landmarkPoseData.averagePose.getLandmarks().size() != 18 ||\n            connection->landmarkPoseData.landmarkPoses.getCapacity() != connection->landmarkPoseData.landmarkPoses.getSize() ||\n            connection->landmarkPoseData.landmarkPoses.at(connection->landmarkPoseData.landmarkPoses.getCapacity() - 1).getLandmarks().size() != 18)\n        {\n            return false;\n        }\n\n        // TODO: Fix this\n        // // If there exists a connection of this axis in `landmarkPoseDataConnections`...\n        // if (landmarkPoseDataConnections.find(deviceRotation) != landmarkPoseDataConnections.end())\n        // {\n        //     // If they are the same connection, then update the data.\n        //     if (connection->commonSettings.timestamp == landmarkPoseDataConnections.at(deviceRotation)->commonSettings.timestamp)\n        //     {\n        //         return true;\n        //     }\n        //     // If the old connection on the axis has not sent any landmark data for over 100ms, the user may\n        //     // have went out of frame of the old camera and into the new camera frame so use that connection instead.\n        //     else if (landmarkPoseDataConnections.at(deviceRotation)->landmarkPoseData.timestamp > std::chrono::system_clock::now() - std::chrono::milliseconds{100})\n        //     {\n        //         return true;\n        //     }\n        //     // If neither of these two conditions are true, the current connection is still sending data so don't change the connection.\n        //     return false;\n        // }\n        // If there does not exists a connection of this axis in `landmarkPoseDataConnections`, add the connection.\n        return true;\n    }",
        "output": "When a new calibration message is received in the driver, the `onPoseMessageReceived` function in the `ConnectionBase` class is called. This function processes the received message and updates the landmark pose data accordingly.\n\nFirstly, it checks if the received message is the first or last message in a series of messages for a specific landmark. If it is, it clears the corresponding landmark pose data structure (`workingAverageLandmarkPose` or `workingLandmarkPose`).\n\nThen, it extracts the landmarks from the received message and stores them in the appropriate landmark pose data structure based on whether the message is an average pose message or not.\n\nIf the received message is the last message in a series, it generates a `LandmarkPose` object with the current timestamp and the stored landmark poses. This object is then pushed into the `landmarkPoses` queue in the `landmarkPoseData` structure.\n\nFinally, the `landmarkPoseData` structure is updated with the new landmark pose data, including the average pose if applicable, and the timestamp.\n\nThe `checkIfPoseLandmarkDataShouldBeUsed` function in the `ConnectionManager` class is then called to determine if the new landmark pose data should be used or not. This function checks if the new data is filled and if there exists a connection of the same axis in `landmarkPoseDataConnections`. If neither of these conditions are true, the current connection is still sending data so it doesn't change the connection.\n\nIf the new landmark pose data should be used, it is used to update the device rotation and other relevant data in the driver."
    },
    {
        "question": "What happens when a new calibration message is received on mobile?",
        "database_value": "mobile",
        "related_docs": "static void displayCalibrationStartedNotification() {\n    NotificationUI.displayNotification(\n      content:\n          'Calibration starts in ${CalibrationHelper.calibrationPreparationDuration.inSeconds} seconds!',\n      backgroundColor: Colors.amber,\n    );\n  }\n\nstatic void displayCalibrationSuccessNotification() {\n    NotificationUI.displayNotification(\n      content: 'Calibration snapshot complete!',\n      backgroundColor: Colors.green,\n    );\n  }\n\nFuture<void> calibrationNotification() async {\n  final SharedPreferences prefs = await SharedPreferences.getInstance();\n  if (!prefs.containsKey(Global.averageLandmarkMessageSave)) {\n    Global.messengerKey.currentState!.showSnackBar(\n      const SnackBar(\n        content: Text('Please calibrate your pose!'),\n        backgroundColor: Colors.teal,\n        duration: Duration(seconds: 5),\n      ),\n    );\n  }\n}\n\n@override\n  Widget build(BuildContext context) {\n    var cameraQualitySubtitle =\n        \"Increase for better accuracy with lower refresh rate.\";\n\n    if (Platform.isAndroid) {\n      cameraQualitySubtitle += \"\\nWARNING: Setting to high may lag detection.\";\n    }\n\n    return PopScope(\n      onPopInvoked: _onWillPop,\n      child: SettingsScreen(\n        title: 'Options',\n        children: [\n          SettingsGroup(\n            title: 'Tracking',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Display Points\",\n                subtitle: \"Displays the pose data as seen by the device.\",\n                settingKey: Global.pointsDisplaySave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Use controllers to improve accuracy\",\n                subtitle: \"FreeMoveVR will use the controllers to \"\n                    \"double check itself. Only enable if controllers \"\n                    \"are already being used for hand tracking.\",\n                settingKey: Global.controllerCheckEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Camera',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: 'Camera Quality',\n                subtitle: cameraQualitySubtitle,\n                settingKey: Global.cameraQualitySave,\n                values: platformQualities(),\n                selected: 0,\n              ),\n              RadioSettingsTile(\n                title: \"Device Position\",\n                subtitle: \"Sets where the phone is relative to the play space.\",\n                settingKey: Global.devicePositionSave,\n                values: const <int, String>{\n                  0: 'Front',\n                  1: 'Right (90\u00b0 Clockwise)',\n                  2: 'Back',\n                  3: 'Left (90\u00b0 Counter Clockwise)',\n                },\n                selected: 0,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Enabled Trackers',\n            children: <Widget>[\n              SwitchSettingsTile(\n                title: \"Shoulder\",\n                settingKey: Global.shoulderTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Elbow\",\n                settingKey: Global.elbowTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Hip\",\n                settingKey: Global.hipTrackerEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Knees\",\n                settingKey: Global.kneeTrackersEnabledSave,\n                defaultValue: true,\n              ),\n              SwitchSettingsTile(\n                title: \"Feet\",\n                settingKey: Global.footTrackersEnabledSave,\n                defaultValue: true,\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'Calibration',\n            children: <Widget>[\n              DropDownSettingsTile<int>(\n                title: \"User Height\",\n                selected: 69,\n                settingKey: Global.userHeightSave,\n                values: Global.heightMap(),\n              ),\n              SimpleSettingsTile(\n                title: \"Delete Calibration Data\",\n                subtitle: \"Press to delete your saved pose.\",\n                onTap: () async {\n                  final SharedPreferences prefs =\n                      await SharedPreferences.getInstance();\n                  prefs.remove(Global.averageLandmarkMessageSave);\n                  prefs.remove(Global.statisticalMessageSave);\n                },\n              ),\n            ],\n          ),\n          SettingsGroup(\n            title: 'About',\n            children: <Widget>[\n              SimpleSettingsTile(\n                title: \"Replay Introduction\",\n                onTap: () {\n                  Navigator.of(context).pushReplacement(\n                    MaterialPageRoute(\n                      builder: (_) => const OnboardingPage(\n                        firstVisit: false,\n                      ),\n                    ),\n                  );\n                },\n              ),\n              SimpleSettingsTile(\n                title: \"About FreeMoveVR\",\n                onTap: () {\n                  showLicensePage(\n                    context: context,\n                    applicationName: \"FreeMove VR\",\n                    applicationIcon: Padding(\n                      padding: const EdgeInsets.all(8),\n                      child: Image.asset(\n                        \"assets/icon/free-move-vr-logo.png\",\n                        width: 48,\n                        height: 48,\n                      ),\n                    ),\n                    applicationLegalese: \"Copyright William Parker\",\n                  );\n                },\n              ),\n            ],\n          ),\n        ],\n      ),\n    );\n  }\n\nstatic void displayCalibrationFailNotification() {\n    NotificationUI.displayNotification(\n      content:\n          'No poses found, please make sure you are visible to the camera.',\n    );\n  }",
        "output": "When a new calibration message is received on mobile, the `calibrationNotification()` function is called. This function checks if the user has already saved their calibration data by checking for the presence of the `Global.averageLandmarkMessageSave` key in the shared preferences. If the user has not saved their calibration data, a snackbar notification is displayed with the message \"Please calibrate your pose!\" and a teal background color.\n\nThe `displayCalibrationStartedNotification()` function is also called when a new calibration message is received, displaying a notification to the user that the calibration process will start in a certain number of seconds.\n\nIf the user has already saved their calibration data, no notifications are displayed and the calibration process continues as usual.\n\nIf there are no poses found during the calibration process, the `displayCalibrationFailNotification()` function is called, displaying a notification to the user with the message \"No poses found, please make sure you are visible to the camera.\""
    }
]